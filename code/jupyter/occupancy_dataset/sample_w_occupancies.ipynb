{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code\n",
    "from datasets.shapeloaders import CoMPaTSegmentDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "from util.misc import dump_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_POINTS_PER_SHAPE = 2**18\n",
    "OUT_PATH = \"/tmp/some_stuff/\"\n",
    "SAMPLES_PER_DATASET = 8\n",
    "PROCESSED_MODELS = set()\n",
    "\n",
    "\n",
    "def get_datasets(active_class):\n",
    "    compat_dataset = CoMPaTSegmentDataset(\n",
    "        \"/ibex/project/c2273/3DCoMPaT/manifold_part_instances/\",\n",
    "        shape_cls=active_class,\n",
    "        recenter_mesh=True,\n",
    "        process_mesh=True,\n",
    "        scale_to_shapenet=True,\n",
    "        align_to_shapenet=True,\n",
    "        random_transform=False,\n",
    "        force_retransform=False,\n",
    "        remove_small_parts=False,\n",
    "        **{\n",
    "            \"n_points\": N_POINTS_PER_SHAPE,\n",
    "            \"sampling_method\": \"surface+near_surface\",\n",
    "            \"near_surface_noise\": 0.01,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    compat_part_drop_dataset = CoMPaTSegmentDataset(\n",
    "        \"/ibex/project/c2273/3DCoMPaT/manifold_part_instances/\",\n",
    "        shape_cls=active_class,\n",
    "        recenter_mesh=True,\n",
    "        process_mesh=True,\n",
    "        scale_to_shapenet=True,\n",
    "        align_to_shapenet=True,\n",
    "        random_transform=False,\n",
    "        force_retransform=True,\n",
    "        random_part_drop=True,\n",
    "        n_parts_to_drop=1,\n",
    "        remove_small_parts=False,\n",
    "        **{\n",
    "            \"n_points\": N_POINTS_PER_SHAPE,\n",
    "            \"sampling_method\": \"surface+near_surface\",\n",
    "            \"near_surface_noise\": 0.01,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"orig\": compat_dataset,\n",
    "        \"part_drop\": compat_part_drop_dataset,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def is_model_processed(model_id):\n",
    "    \"\"\"\n",
    "    Check if the given model_id exists in the set of processed models.\n",
    "    \"\"\"\n",
    "    global PROCESSED_MODELS\n",
    "    return model_id in PROCESSED_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_dataset_entry(datasets, obj_k, out_path):\n",
    "    global PROCESSED_MODELS\n",
    "    model_id = datasets[\"orig\"].get_model_id(obj_k)\n",
    "\n",
    "    # Check if the model has already been processed\n",
    "    if is_model_processed(model_id):\n",
    "        print(f\"Skipping model {model_id} as it has already been processed\")\n",
    "        return\n",
    "\n",
    "    for dset_name, dataset in datasets.items():\n",
    "        for sample_id in range(SAMPLES_PER_DATASET):\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            all_points, occs, bbs = next(dataset[obj_k])\n",
    "            surface_points, near_surface_points = (\n",
    "                all_points[0],\n",
    "                all_points[1],\n",
    "            )\n",
    "            assert (\n",
    "                torch.sum(occs[: N_POINTS_PER_SHAPE // 2].flatten())\n",
    "                == N_POINTS_PER_SHAPE // 2\n",
    "            )\n",
    "\n",
    "            occs = occs[N_POINTS_PER_SHAPE // 2 :]\n",
    "\n",
    "            sample_code = f\"{model_id}_{dset_name}_{sample_id}\"\n",
    "\n",
    "            # Store the points\n",
    "            np.save(\n",
    "                f\"{out_path}/{sample_code}_surface_points\", surface_points.cpu().numpy()\n",
    "            )\n",
    "            np.save(\n",
    "                f\"{out_path}/{sample_code}_near_surface_points\",\n",
    "                near_surface_points.cpu().numpy(),\n",
    "            )\n",
    "\n",
    "            # Store the occupancy grid\n",
    "            np.save(f\"{out_path}/{sample_code}_occs\", occs.cpu().numpy())\n",
    "\n",
    "            # Store the transformation matrix\n",
    "            np.save(f\"{out_path}/{sample_code}_transformation\", dataset.transform_mat)\n",
    "\n",
    "            # Store the bounding boxes\n",
    "            dump_pickle(bbs, f\"{out_path}/{sample_code}_bbs.pkl\")\n",
    "\n",
    "            if dset_name == \"orig\":\n",
    "                break\n",
    "\n",
    "    # Add the processed model to the set\n",
    "    PROCESSED_MODELS.add(model_id)\n",
    "    print(f\"Processed model {model_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = get_datasets(\"chair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.metadata import COMPAT_MATCHED_CLASSES\n",
    "\n",
    "export_dataset_entry(dsets, 0, OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_colormap_colors(n, colormap_name=\"viridis\", alpha=1.0):\n",
    "    colormap = cm.get_cmap(colormap_name)\n",
    "    colors = [(*colormap(i / (n - 1))[:3], alpha) for i in range(n)]\n",
    "    return colors\n",
    "\n",
    "def visualize_bounding_boxes(\n",
    "    bounding_boxes,\n",
    "    mesh=None,\n",
    "    box_type=\"spheres\",\n",
    "    line_radius=0.005,\n",
    "    colormap=\"viridis\",\n",
    "    alpha=1.0,\n",
    "):\n",
    "    scene = trimesh.Scene()\n",
    "    if mesh is not None:\n",
    "        scene.add_geometry(mesh)\n",
    "    \n",
    "    colors = generate_colormap_colors(len(bounding_boxes), colormap, alpha)\n",
    "    \n",
    "    for bb, color in zip(bounding_boxes, colors):\n",
    "        corners = bb.get_corners()\n",
    "        if box_type == \"spheres\":\n",
    "            for corner in corners:\n",
    "                sphere = trimesh.creation.uv_sphere(radius=line_radius)\n",
    "                sphere.apply_translation(corner)\n",
    "                sphere.visual.face_colors = np.array(color) * 255\n",
    "                scene.add_geometry(sphere)\n",
    "                \n",
    "        edges = bb.get_edges()\n",
    "        for edge in edges:\n",
    "            cylinder = trimesh.creation.cylinder(\n",
    "                radius=line_radius,\n",
    "                segment=edge,\n",
    "            )\n",
    "            cylinder.visual.face_colors = np.array(color) * 255\n",
    "            scene.add_geometry(cylinder)\n",
    "    \n",
    "    return scene\n",
    "\n",
    "def visualize_dataset(out_path):\n",
    "    # Get all surface point files\n",
    "    surface_files = glob.glob(os.path.join(out_path, \"*_surface_points.npy\"))\n",
    "    \n",
    "    for sf in surface_files:\n",
    "        base_name = sf.replace(\"_surface_points.npy\", \"\")\n",
    "        \n",
    "        # Load data\n",
    "        surface_points = np.load(sf)\n",
    "        occs = np.load(f\"{base_name}_occs.npy\")\n",
    "        with open(f\"{base_name}_bbs.pkl\", 'rb') as f:\n",
    "            bbs = pickle.load(f)\n",
    "            \n",
    "        # Visualize surface points\n",
    "        points_scene = visualize_pointcloud([surface_points])\n",
    "        points_scene.show()\n",
    "        \n",
    "        # Visualize occupancy grid as points\n",
    "        occ_positions = np.where(occs > 0.5)\n",
    "        occ_points = np.stack(occ_positions, axis=1)\n",
    "        occ_scene = visualize_pointcloud([occ_points])\n",
    "        occ_scene.show()\n",
    "        \n",
    "        # Visualize bounding boxes\n",
    "        bb_scene = visualize_bounding_boxes(bbs)\n",
    "        bb_scene.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
