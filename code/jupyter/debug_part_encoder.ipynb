{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibex/user/slimhy/PADS/code\n",
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n"
     ]
    }
   ],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code\n",
    "%reload_ext autoreload\n",
    "%set_env CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
    "\"\"\"\n",
    "Extracting features into HDF5 files for each split.\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "def assert_close(tensor1, tensor2, rtol=1e-5, atol=1e-5):\n",
    "    assert torch.allclose(tensor1, tensor2, rtol=rtol, atol=atol), \\\n",
    "        f\"Tensors are not close: \\n{tensor1}\\n{tensor2}\"\n",
    "\n",
    "\n",
    "def test_latent_permutation_invariance(model):\n",
    "    batch_size, num_parts = 1,  24\n",
    "    \n",
    "    latents = torch.rand(batch_size, 512, 8)\n",
    "    part_bbs = torch.rand(batch_size, num_parts, 4, 3)\n",
    "    part_labels = torch.randint(0, 10, (batch_size, num_parts), dtype=torch.long)\n",
    "    batch_mask = torch.ones(batch_size, num_parts).bool()\n",
    "    \n",
    "    original_output, _ = model(latents, part_bbs, part_labels, batch_mask)\n",
    "    \n",
    "    perm = torch.randperm(8)\n",
    "    \n",
    "    part_latents, _ = model(latents[:, :, perm], part_bbs, part_labels, batch_mask)\n",
    "    \n",
    "    try:\n",
    "        assert_close(original_output, part_latents)\n",
    "        print(\"Part latents invariant to latents permutation: PASSED\")\n",
    "    except AssertionError as e:\n",
    "        print(\"Part latents invariant to latents permutation: FAILED\")\n",
    "        print(str(e))\n",
    "        \n",
    "        \n",
    "def test_part_embeddings_equivariance(model):\n",
    "    batch_size, num_parts = 1, 24\n",
    "    \n",
    "    latents = torch.rand(batch_size, 512, 8)\n",
    "    part_bbs = torch.rand(batch_size, num_parts, 4, 3)\n",
    "    part_labels = torch.randint(0, 10, (batch_size, num_parts), dtype=torch.long)\n",
    "    batch_mask = torch.ones(batch_size, num_parts).bool()\n",
    "    \n",
    "    part_latents, part_embeds = model(latents, part_bbs, part_labels, batch_mask)\n",
    "    \n",
    "    perm = torch.randperm(num_parts)\n",
    "    permuted_part_bbs = part_bbs[:, perm, :, :]\n",
    "    permuted_part_labels = part_labels[:, perm]\n",
    "    \n",
    "    permuted_part_latents, permuted_part_embeds = model(\n",
    "        latents,\n",
    "        permuted_part_bbs,\n",
    "        permuted_part_labels,\n",
    "        batch_mask\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        assert_close(part_embeds[:, perm, :], permuted_part_embeds)\n",
    "        print(\"Part embeddings equivariant to parts permutation: PASSED\")\n",
    "    except AssertionError as e:\n",
    "        print(\"Part embeddings equivariant to parts permutation: FAILED\")\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "def test_part_latents_equivariance(model):\n",
    "    batch_size, num_parts = 1, 24\n",
    "    \n",
    "    latents = torch.rand(batch_size, 512, 8)\n",
    "    part_bbs = torch.rand(batch_size, num_parts, 4, 3)\n",
    "    part_labels = torch.randint(0, 10, (batch_size, num_parts), dtype=torch.long)\n",
    "    batch_mask = torch.ones(batch_size, num_parts).bool()\n",
    "    \n",
    "    part_latents, part_embeds = model(latents, part_bbs, part_labels, batch_mask)\n",
    "    \n",
    "    perm = torch.randperm(part_latents.shape[1])\n",
    "    permuted_part_bbs = part_bbs[:, perm, :, :]\n",
    "    permuted_part_labels = part_labels[:, perm]\n",
    "    \n",
    "    permuted_part_latents, permuted_part_embeds = model(\n",
    "        latents,\n",
    "        permuted_part_bbs,\n",
    "        permuted_part_labels,\n",
    "        batch_mask\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        assert_close(part_latents[:, perm, :], permuted_part_latents)\n",
    "        print(\"Part latents equivariant to parts permutation: PASSED\")\n",
    "    except AssertionError as e:\n",
    "        print(\"Part latents equivariant to parts permutation: FAILED\")\n",
    "        print(str(e))\n",
    "        \n",
    "\n",
    "def print_return_shapes(model):\n",
    "    batch_size, num_parts = 1, 24\n",
    "    \n",
    "    latents = torch.rand(batch_size, 512, 8)\n",
    "    part_bbs = torch.rand(batch_size, num_parts, 4, 3)\n",
    "    part_labels = torch.randint(0, 10, (batch_size, num_parts), dtype=torch.long)\n",
    "    batch_mask = torch.ones(batch_size, num_parts).bool()\n",
    "    \n",
    "    part_latents, part_embeds = model(latents, part_bbs, part_labels, batch_mask)\n",
    "    print(\"Part latents shape:\", part_latents.shape)\n",
    "    print(\"Part embeddings shape:\", part_embeds.shape)\n",
    "\n",
    "def test_masked_elements_invariance(model):\n",
    "    batch_size, num_parts = 1, 24\n",
    "    \n",
    "    latents = torch.rand(batch_size, 512, 8)\n",
    "    part_bbs = torch.rand(batch_size, num_parts, 4, 3)\n",
    "    part_labels = torch.randint(0, 10, (batch_size, num_parts), dtype=torch.long)\n",
    "    \n",
    "    # Create a random mask\n",
    "    num_masked = torch.randint(1, num_parts, (1,)).item()  # Random number of masked elements\n",
    "    batch_mask = torch.ones(batch_size, num_parts, dtype=torch.bool)\n",
    "    masked_indices = torch.randperm(num_parts)[:num_masked]\n",
    "    batch_mask[:, masked_indices] = False\n",
    "    \n",
    "    # Get original output\n",
    "    original_part_latents, original_part_embeds = model(latents, part_bbs, part_labels, batch_mask)\n",
    "    \n",
    "    # Modify masked elements in part_bbs and part_labels\n",
    "    modified_part_bbs = part_bbs.clone()\n",
    "    modified_part_labels = part_labels.clone()\n",
    "    modified_part_bbs[:, masked_indices, :, :] = torch.rand_like(modified_part_bbs[:, masked_indices, :, :])\n",
    "    modified_part_labels[:, masked_indices] = torch.randint(0, 10, (batch_size, num_masked), dtype=torch.long)\n",
    "    \n",
    "    # Get output with modified masked elements\n",
    "    modified_part_latents, modified_part_embeds = model(latents, modified_part_bbs, modified_part_labels, batch_mask)\n",
    "    \n",
    "    try:\n",
    "        assert_close(original_part_latents, modified_part_latents)\n",
    "        assert_close(original_part_embeds, modified_part_embeds)\n",
    "        print(f\"Masked elements invariance (with {num_masked} masked elements): PASSED\")\n",
    "    except AssertionError as e:\n",
    "        print(f\"Masked elements invariance (with {num_masked} masked elements): FAILED\")\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part latents shape: torch.Size([1, 8, 128])\n",
      "Part embeddings shape: torch.Size([1, 24, 128])\n",
      "\n",
      "Part latents invariant to latents permutation: PASSED\n",
      "\n",
      "Part embeddings equivariant to parts permutation: PASSED\n",
      "\n",
      "\n",
      "Masked elements invariance (with 19 masked elements): PASSED\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.part_queries import PQM, PQMShallow, PartQueriesEncoder\n",
    "\n",
    "\n",
    "# Initialize your model\n",
    "part_latents_dim = 128\n",
    "pqm = PQMShallow(\n",
    "    dim=512,\n",
    "    latent_dim=part_latents_dim,\n",
    "    heads=8,\n",
    "    dim_head=64,\n",
    "    use_attention_masking=False,\n",
    ")\n",
    "model = PartQueriesEncoder(\n",
    "    pqm=pqm,\n",
    "    dim=part_latents_dim,\n",
    "    input_length=24,\n",
    "    output_length=8,\n",
    ")\n",
    "\n",
    "# Run the tests\n",
    "print_return_shapes(model)\n",
    "print()\n",
    "test_latent_permutation_invariance(model)\n",
    "print()\n",
    "test_part_embeddings_equivariance(model)\n",
    "print()\n",
    "#Â test_part_latents_equivariance(model)\n",
    "print()\n",
    "test_masked_elements_invariance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
