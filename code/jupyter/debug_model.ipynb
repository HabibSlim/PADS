{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibex/user/slimhy/PADS/code\n",
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n"
     ]
    }
   ],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code\n",
    "%set_env CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
    "import torch\n",
    "from models.partvae import PartAwareVAE, PartAwareAE\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "LATENT_DIM = 512\n",
    "N_PARTS = 24\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "def sample_mask():\n",
    "    # Set first n_to_mask parts to be masked in a mask for each sample\n",
    "    n_to_mask = torch.randint(0, N_PARTS, (BATCH_SIZE,))\n",
    "    mask = torch.zeros(BATCH_SIZE, N_PARTS).bool()\n",
    "    for i in range(BATCH_SIZE):\n",
    "        mask[i, :n_to_mask[i]] = True\n",
    "    return mask\n",
    "\n",
    "\n",
    "def init_model(use_vae):\n",
    "    if use_vae:\n",
    "        model_class = PartAwareVAE\n",
    "    else:\n",
    "        model_class = PartAwareAE\n",
    "    pvae = model_class(\n",
    "        dim=512,\n",
    "        latent_dim=128,\n",
    "        heads=8,\n",
    "        dim_head=64,\n",
    "        depth=2,\n",
    "    ).to(device)\n",
    "    pvae = pvae.to(device)\n",
    "    pvae = pvae.eval()\n",
    "    return pvae\n",
    "\n",
    "\n",
    "def create_sample_data():\n",
    "    # Create sample data\n",
    "    l = torch.randn(BATCH_SIZE, LATENT_DIM, 8)\n",
    "    bb = torch.randn(BATCH_SIZE, N_PARTS, 4, 3)\n",
    "    bb_l = torch.randint(0, N_PARTS, (BATCH_SIZE, N_PARTS)).long()\n",
    "    \n",
    "    return l, bb, bb_l, sample_mask()\n",
    "\n",
    "\n",
    "def clone_tuple(sample_data):\n",
    "    return tuple([x.clone() for x in sample_data])\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_deterministic(pvae_model, sample_data):\n",
    "    l, bb, bb_l, mask = sample_data\n",
    "    \n",
    "    # Forward pass with original data\n",
    "    logits1, kl1, part_latents1 = pvae_model(latents=l, part_bbs=bb, part_labels=bb_l, batch_mask=mask, deterministic=True)\n",
    "\n",
    "    logits2, kl2, part_latents2 = pvae_model(latents=l, part_bbs=bb, part_labels=bb_l, batch_mask=mask, deterministic=True)\n",
    "    \n",
    "    print(\"\\nDeterministic inference test\")\n",
    "    print(\"==\"*20)\n",
    "    print(f\"- Logits are equal: {torch.allclose(logits1, logits2)}\")\n",
    "    \n",
    "\n",
    "@torch.no_grad()\n",
    "def test_masked_entries(pvae_model, sample_data):\n",
    "    l, bb, bb_l, mask = sample_data\n",
    "    \n",
    "    # Forward pass with original data\n",
    "    logits1, kl1, part_latents1 = pvae_model(latents=l, part_bbs=bb, part_labels=bb_l, batch_mask=mask, deterministic=True)\n",
    "    \n",
    "    #Â Resample the mask\n",
    "    new_mask = sample_mask().to(device)\n",
    "    logits2, kl2, part_latents2 = pvae_model(latents=l, part_bbs=bb, part_labels=bb_l, batch_mask=new_mask, deterministic=True)\n",
    "    \n",
    "    # Change masked values and verify that the output does NOT change\n",
    "    bb[~new_mask] = 100.\n",
    "    logits3, kl3, part_latents3 = pvae_model(latents=l, part_bbs=bb, part_labels=bb_l, batch_mask=new_mask, deterministic=True)\n",
    "    \n",
    "    # Change masked values and verify that the output does NOT change\n",
    "    bb[new_mask] = 100.\n",
    "    logits4, kl4, part_latents4 = pvae_model(latents=l, part_bbs=bb, part_labels=bb_l, batch_mask=new_mask, deterministic=True)\n",
    "\n",
    "    print(\"\\nMasked entries test\")\n",
    "    print(\"==\"*20)\n",
    "    print(f\"- Resampled mask gives different output: {not torch.allclose(logits1, logits2)}\")\n",
    "    print(f\"- Changing masked entries gives same output: {torch.max(logits2 - logits3)}\")\n",
    "    print(f\"- Changing unmasked entries gives diff. output: {torch.max(logits2 - logits4)}\")\n",
    "\n",
    "\n",
    "def test_permutation_invariance(pvae_model, sample_data):\n",
    "    l, bb, bb_l, _ = [t.to(device) for t in create_sample_data()]\n",
    "    mask = ~((torch.ones(BATCH_SIZE, N_PARTS))*0).bool().to(device)\n",
    "    ctxt_short = torch.randn((BATCH_SIZE, LATENT_DIM, 8)).to(device)\n",
    "\n",
    "    def encode_stuff(pvae, bb, bb_l, mask, ctxt):\n",
    "        _, part_latents, _ = pvae.encode(latents=ctxt, part_bbs=bb, part_labels=bb_l, batch_mask=mask, deterministic=True)\n",
    "        return part_latents\n",
    "\n",
    "    # Forward pass with original data\n",
    "    part_latents_1 = encode_stuff(pvae_model, bb, bb_l, mask, ctxt_short)\n",
    "\n",
    "    rnd_perm = torch.randperm(N_PARTS)\n",
    "    bb_perm = bb[:, rnd_perm, :, :]\n",
    "    bb_l_perm = bb_l[:, rnd_perm]\n",
    "\n",
    "    # Forward pass with permuted data\n",
    "    part_latents_2 = encode_stuff(pvae_model, bb_perm, bb_l_perm, mask, ctxt_short)\n",
    "\n",
    "    # Check if the outputs are the same (up to permutation)\n",
    "    print(\"\\nPermutation invariance test:\")\n",
    "    print(\"==\"*20)\n",
    "    print(f\"- Part latents are invariant: {torch.allclose(part_latents_1, part_latents_2)}\")\n",
    "    print(f\"- Part latents are equivariant: {torch.allclose(part_latents_1[:, rnd_perm, :], part_latents_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set seed to 0\n",
      "\n",
      "Deterministic inference test\n",
      "========================================\n",
      "- Logits are equal: True\n",
      "\n",
      "Masked entries test\n",
      "========================================\n",
      "- Resampled mask gives different output: True\n",
      "- Changing masked entries gives same output: 0.0003500815745000885\n",
      "- Changing unmasked entries gives diff. output: 2.0631369963220867\n",
      "\n",
      "Permutation invariance test:\n",
      "========================================\n",
      "- Part latents are invariant: False\n",
      "- Part latents are equivariant: True\n"
     ]
    }
   ],
   "source": [
    "from util.misc import set_all_seeds\n",
    "set_all_seeds(0)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "# Create sample data\n",
    "sample_data = [t.to(device) for t in create_sample_data()]\n",
    "\n",
    "# Run tests\n",
    "pvae_model = init_model(use_vae=True)\n",
    "test_deterministic(pvae_model, sample_data)\n",
    "test_masked_entries(pvae_model, sample_data)\n",
    "test_permutation_invariance(pvae_model, sample_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
