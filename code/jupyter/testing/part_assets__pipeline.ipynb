{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibex/user/slimhy/PADS/code\n"
     ]
    }
   ],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code\n",
    "\"\"\"\n",
    "Test demo for MLP mapper.\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import models.s2vs as autoencoders\n",
    "import util.misc as misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading autoencoder ckpt/ae_m512.pth\n"
     ]
    }
   ],
   "source": [
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\"Latent Diffusion\", add_help=False)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument(\n",
    "        \"--model\",\n",
    "        default=\"kl_d512_m512_l8_edm\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of model to train\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=32,\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--text_model_name\",\n",
    "        type=str,\n",
    "        help=\"Text model name to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of autoencoder\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae-latent-dim\",\n",
    "        type=int,\n",
    "        default=512*8,\n",
    "        help=\"AE latent dimension\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae_pth\",\n",
    "        required=True,\n",
    "        help=\"Autoencoder checkpoint\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--point_cloud_size\",\n",
    "        default=2048,\n",
    "        type=int,\n",
    "        help=\"input size\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fetch_keys\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_embeds\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--resume\",\n",
    "        default=\"\",\n",
    "        help=\"Resume from checkpoint\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--resume_weights\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Only resume weights, not optimizer state\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--resume_full_weights\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Resume the full model weights with the EDM wrapper\",\n",
    "    )\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument(\n",
    "        \"--device\", default=\"cuda\", help=\"device to use for training / testing\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_workers\", default=60, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--pin_mem\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.\",\n",
    "    )\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "# Set dummy arg string to debug the parser\n",
    "call_string = \"\"\"--ae_pth ckpt/ae_m512.pth \\\n",
    "    --ae kl_d512_m512_l8 \\\n",
    "    --ae-latent-dim 4096 \\\n",
    "    --num_workers 8 \\\n",
    "    --batch_size 2 \\\n",
    "    --device cuda \\\n",
    "    --fetch_keys \\\n",
    "    --use_embeds \\\n",
    "    --seed 0\"\"\"\n",
    "\n",
    "# Parse the arguments\n",
    "args = get_args_parser()\n",
    "args = args.parse_args(call_string.split())\n",
    "args.data_path = \"/ibex/project/c2273/PADS/3DCoMPaT/\"\n",
    "\n",
    "# --------------------\n",
    "device = torch.device(args.device)\n",
    "\n",
    "# Fix the seed for reproducibility\n",
    "seed = args.seed + misc.get_rank()\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "args.fetch_keys = True\n",
    "# --------------------\n",
    "\n",
    "# Instantiate autoencoder\n",
    "ae = autoencoders.__dict__[args.ae]()\n",
    "ae.eval()\n",
    "print(\"Loading autoencoder %s\" % args.ae_pth)\n",
    "ae.load_state_dict(torch.load(args.ae_pth, map_location=\"cpu\")[\"model\"])\n",
    "ae = ae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.metadata import class_to_idx \n",
    "import models.diffusion as diffusion\n",
    "from util import misc\n",
    "import util.s2vs as s2vs\n",
    "\n",
    "\n",
    "def load_ckpt(model_type):\n",
    "    args.model = model_type\n",
    "    args.resume = \"/ibex/user/slimhy/PADS/code/ckpt/dm/kl_d512_m512_l8.pth\"\n",
    "\n",
    "    model = diffusion.__dict__[model_type]()\n",
    "    model.eval()\n",
    "    \n",
    "    misc.load_model(args, model)\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def get_cond(class_name, n_samples=1):\n",
    "    class_id = class_to_idx(class_name, dataset=\"shapenet\")\n",
    "    cond = torch.Tensor([class_id]*n_samples).long().to(device)\n",
    "    return cond\n",
    "\n",
    "\n",
    "def decode_latents(model, latents, grid_density=128, batch_size=128**3):\n",
    "    # Decode the latents\n",
    "    with torch.no_grad():\n",
    "        mesh = s2vs.decode_latents(\n",
    "            ae=model,\n",
    "            latent=latents[0].unsqueeze(0),\n",
    "            grid_density=grid_density,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slimhy/conda/envs/3D2VS_flexicubes/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from datasets.metadata import class_to_hex\n",
    "from datasets.latents import ShapeLatentDataset, ComposedPairedShapesLoader, PairType\n",
    "import util.misc as misc\n",
    "\n",
    "import torch\n",
    "from models.diffusion import EDMPartAssets\n",
    "from models.points.encoders import pointbert_g512_d12_compat\n",
    "from models.part_assets import PartTokenizer\n",
    "\n",
    "pc_encoder = pointbert_g512_d12_compat()\n",
    "passets = PartTokenizer(\n",
    "    pc_encoder=pc_encoder,\n",
    "    bb_input_dim=12,\n",
    "    bb_hidden_dim=64,\n",
    "    bb_output_dim=32,\n",
    "    bb_mlp_depth=3,\n",
    "    visual_feature_dim=128,\n",
    "    out_dim=512,\n",
    ").cuda()\n",
    "model = EDMPartAssets(\n",
    "    part_queries_encoder=passets, n_latents=512, channels=8, depth=24\n",
    ").cuda()\n",
    "\n",
    "\n",
    "# Initialize your dataloader\n",
    "dataset_train = ShapeLatentDataset(\n",
    "    args.data_path,\n",
    "    class_code=class_to_hex(\"chair\"),\n",
    "    split=\"train\",\n",
    "    shuffle_parts=True,\n",
    "    filter_n_ids=8,\n",
    "    get_part_points=True,\n",
    ")\n",
    "\n",
    "loader = ComposedPairedShapesLoader(\n",
    "    dataset_train,\n",
    "    batch_size=16,\n",
    "    pair_types_list=[PairType.NO_ROT_PAIR],\n",
    "    num_workers=4,\n",
    "    seed=0,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "# Get data from loader\n",
    "tuple_a = loader.get_tuple(device=\"cuda\")\n",
    "tuple_a = [x.to(\"cuda\") if type(x) == torch.Tensor else x for x in tuple_a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses.partvae import ScaleInvariantLoss, PartDropLoss\n",
    "from losses.edmloss_part_assets import EDMLossPartAssets\n",
    "\n",
    "\n",
    "def get_losses():\n",
    "    \"\"\"\n",
    "    Instantiate the losses.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        EDMLossPartAssets(),\n",
    "        ScaleInvariantLoss(),\n",
    "        PartDropLoss(),\n",
    "    )\n",
    "    \n",
    "    \n",
    "def forward_pass(\n",
    "    pqdm,\n",
    "    data_tuple,\n",
    "    rec_loss,\n",
    "    scale_inv_loss,\n",
    "    part_drop_loss,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute a single forward pass of the model.\n",
    "    \"\"\"\n",
    "    device = pqdm.device\n",
    "\n",
    "    # Unpack the data tuple\n",
    "    (l_a, bb_a, bb_l_a, part_pts_a, shape_cls_a, _) = data_tuple\n",
    "\n",
    "    # Compute the mask from batch labels\n",
    "    mask_a = (bb_l_a == -1).to(device)  # B x 24\n",
    "    print(mask_a.requires_grad)\n",
    "\n",
    "    l_a = l_a.to(device)  # B x 8 x 512\n",
    "    bb_a = bb_a.to(device)  # B x 24 x 4 x 3\n",
    "    bb_l_a = bb_l_a.to(device)  # B x 24\n",
    "\n",
    "    # L2 loss\n",
    "    rec_loss_a, part_queries_a = rec_loss(\n",
    "        pqdm, l_a, bb_a, bb_l_a, part_pts_a, shape_cls_a, mask_a\n",
    "    )\n",
    "\n",
    "    inv_loss = torch.tensor(0.0).to(device)\n",
    "\n",
    "    return {\n",
    "        \"rec_loss\": rec_loss_a,\n",
    "        \"inv_loss\": inv_loss,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from util.misc import NativeScalerWithGradNormCount as NativeScaler\n",
    "from schedulefree import AdamWScheduleFree\n",
    "\n",
    "rec_loss, scale_inv_loss, part_drop_loss = get_losses()\n",
    "loss_scaler = NativeScaler()\n",
    "optimizer = AdamWScheduleFree(\n",
    "    model.parameters(), lr=1e-3, weight_decay=1e-3\n",
    ")\n",
    "model = model.train()\n",
    "\n",
    "# Computing loss\n",
    "loss = forward_pass(\n",
    "    pqdm=model,\n",
    "    data_tuple=tuple_a,\n",
    "    rec_loss=rec_loss,\n",
    "    scale_inv_loss=scale_inv_loss,\n",
    "    part_drop_loss=part_drop_loss,\n",
    ")\n",
    "\n",
    "# Stop training if loss explodes\n",
    "loss_value = loss[\"rec_loss\"] + loss[\"inv_loss\"]\n",
    "\n",
    "# Backward pass\n",
    "loss_value /= 1.\n",
    "loss_scaler(\n",
    "    loss_value,\n",
    "    optimizer,\n",
    "    clip_grad=5.,\n",
    "    parameters=model.parameters(),\n",
    "    create_graph=False,\n",
    "    update_grad=True,\n",
    ")\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Log the losses\n",
    "loss_update = {\n",
    "    \"train_loss\": float(loss_value),\n",
    "    \"inv_loss\": float(loss[\"inv_loss\"]),\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
