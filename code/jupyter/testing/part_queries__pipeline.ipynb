{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibex/user/slimhy/PADS/code\n"
     ]
    }
   ],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code\n",
    "\"\"\"\n",
    "Test demo for MLP mapper.\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import models.s2vs as autoencoders\n",
    "import util.misc as misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading autoencoder ckpt/ae_m512.pth\n"
     ]
    }
   ],
   "source": [
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\"Latent Diffusion\", add_help=False)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument(\n",
    "        \"--model\",\n",
    "        default=\"kl_d512_m512_l8_edm\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of model to train\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=32,\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--text_model_name\",\n",
    "        type=str,\n",
    "        help=\"Text model name to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of autoencoder\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae-latent-dim\",\n",
    "        type=int,\n",
    "        default=512*8,\n",
    "        help=\"AE latent dimension\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae_pth\",\n",
    "        required=True,\n",
    "        help=\"Autoencoder checkpoint\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--point_cloud_size\",\n",
    "        default=2048,\n",
    "        type=int,\n",
    "        help=\"input size\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fetch_keys\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_embeds\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--resume\",\n",
    "        default=\"\",\n",
    "        help=\"Resume from checkpoint\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--resume_weights\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Only resume weights, not optimizer state\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--resume_full_weights\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Resume the full model weights with the EDM wrapper\",\n",
    "    )\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument(\n",
    "        \"--device\", default=\"cuda\", help=\"device to use for training / testing\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_workers\", default=60, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--pin_mem\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.\",\n",
    "    )\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "# Set dummy arg string to debug the parser\n",
    "call_string = \"\"\"--ae_pth ckpt/ae_m512.pth \\\n",
    "    --ae kl_d512_m512_l8 \\\n",
    "    --ae-latent-dim 4096 \\\n",
    "    --num_workers 8 \\\n",
    "    --batch_size 2 \\\n",
    "    --device cuda \\\n",
    "    --fetch_keys \\\n",
    "    --use_embeds \\\n",
    "    --seed 0\"\"\"\n",
    "\n",
    "# Parse the arguments\n",
    "args = get_args_parser()\n",
    "args = args.parse_args(call_string.split())\n",
    "args.data_path = \"/ibex/project/c2273/PADS/3DCoMPaT/\"\n",
    "\n",
    "# --------------------\n",
    "device = torch.device(args.device)\n",
    "\n",
    "# Fix the seed for reproducibility\n",
    "seed = args.seed + misc.get_rank()\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "args.fetch_keys = True\n",
    "# --------------------\n",
    "\n",
    "# Instantiate autoencoder\n",
    "ae = autoencoders.__dict__[args.ae]()\n",
    "ae.eval()\n",
    "print(\"Loading autoencoder %s\" % args.ae_pth)\n",
    "ae.load_state_dict(torch.load(args.ae_pth, map_location=\"cpu\")[\"model\"])\n",
    "ae = ae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.metadata import class_to_idx \n",
    "import models.diffusion as diffusion\n",
    "from util import misc\n",
    "import util.s2vs as s2vs\n",
    "\n",
    "\n",
    "def load_ckpt(model_type):\n",
    "    args.model = model_type\n",
    "    args.resume = \"/ibex/user/slimhy/PADS/code/ckpt/dm/kl_d512_m512_l8.pth\"\n",
    "\n",
    "    model = diffusion.__dict__[model_type]()\n",
    "    model.eval()\n",
    "    \n",
    "    misc.load_model(args, model)\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def get_cond(class_name, n_samples=1):\n",
    "    class_id = class_to_idx(class_name, dataset=\"shapenet\")\n",
    "    cond = torch.Tensor([class_id]*n_samples).long().to(device)\n",
    "    return cond\n",
    "\n",
    "\n",
    "def decode_latents(model, latents, grid_density=128, batch_size=128**3):\n",
    "    # Decode the latents\n",
    "    with torch.no_grad():\n",
    "        mesh = s2vs.decode_latents(\n",
    "            ae=model,\n",
    "            latent=latents[0].unsqueeze(0),\n",
    "            grid_density=grid_density,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slimhy/conda/envs/3D2VS_flexicubes/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from datasets.metadata import class_to_hex\n",
    "from datasets.latents import ShapeLatentDataset, ComposedPairedShapesLoader, PairType\n",
    "import util.misc as misc\n",
    "\n",
    "\n",
    "# Create your datasets\n",
    "dataset_train = ShapeLatentDataset(\n",
    "    args.data_path,\n",
    "    class_code=class_to_hex(\"chair\"),\n",
    "    split=\"train\",\n",
    "    shuffle_parts=True,\n",
    "    filter_n_ids=8\n",
    ")\n",
    "\n",
    "loader = ComposedPairedShapesLoader(\n",
    "    dataset_train,\n",
    "    batch_size=args.batch_size,\n",
    "    pair_types_list=[PairType.NO_ROT_PAIR],\n",
    "    num_workers=4,\n",
    "    seed=0,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "l_a, bb_a, bb_l_a, cls_label_a, meta_a = loader.get_tuple(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb_l_a min: -1, max: 266\n",
      "Part label embedding num_embeddings: 275\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.part_queries import PQM\n",
    "from models.diffusion import EDMPartQueries\n",
    "\n",
    "# Initialize models\n",
    "pqm = PQM(dim=512, heads=8, dim_head=64)\n",
    "model = EDMPartQueries(part_queries_encoder=pqm, n_latents=512, channels=8, depth=24)\n",
    "model = model.cuda()\n",
    "\n",
    "# Initialize your dataloader\n",
    "dataset_train = ShapeLatentDataset(\n",
    "    args.data_path,\n",
    "    class_code=class_to_hex(\"chair\"),\n",
    "    split=\"train\",\n",
    "    shuffle_parts=True,\n",
    "    filter_n_ids=8\n",
    ")\n",
    "\n",
    "loader = ComposedPairedShapesLoader(\n",
    "    dataset_train,\n",
    "    batch_size=16,\n",
    "    pair_types_list=[PairType.NO_ROT_PAIR],\n",
    "    num_workers=4,\n",
    "    seed=0,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "# Get data from loader\n",
    "l_a, bb_a, bb_l_a, cls_label_a, meta_a = loader.get_tuple(device=\"cuda\")\n",
    "\n",
    "# Debug: Print value ranges\n",
    "print(f\"bb_l_a min: {bb_l_a.min()}, max: {bb_l_a.max()}\")\n",
    "print(f\"Part label embedding num_embeddings: {pqm.part_embed.part_label_embed.num_embeddings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid labels percentage: 38.02%\n",
      "l_a shape: torch.Size([8, 512, 8])\n",
      "bb_a shape: torch.Size([8, 24, 4, 3])\n",
      "bb_l_a shape: torch.Size([8, 24])\n",
      "Success!\n",
      "Output shape: torch.Size([8, 512, 8])\n",
      "Part embeds shape: torch.Size([8, 24, 512])\n"
     ]
    }
   ],
   "source": [
    "# Create mask (use valid part labels as mask)\n",
    "mask_a = (bb_l_a >= 0) & (bb_l_a < pqm.part_embed.part_label_embed.num_embeddings)\n",
    "print(f\"Valid labels percentage: {mask_a.float().mean()*100:.2f}%\")\n",
    "\n",
    "# Print shapes before forward pass\n",
    "print(f\"l_a shape: {l_a.shape}\")\n",
    "print(f\"bb_a shape: {bb_a.shape}\")\n",
    "print(f\"bb_l_a shape: {bb_l_a.shape}\")\n",
    "\n",
    "mask_a = (bb_l_a == -1)\n",
    "\n",
    "# Pack data and run forward pass\n",
    "samples = (l_a, bb_a, bb_l_a, mask_a)\n",
    "sigma = torch.ones(l_a.shape[0], device=\"cuda\")\n",
    "\n",
    "try:\n",
    "    out, part_embeds = model(samples=samples, sigma=sigma)\n",
    "    print(\"Success!\")\n",
    "    print(f\"Output shape: {out.shape}\")\n",
    "    print(f\"Part embeds shape: {part_embeds.shape}\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
