{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/slimhy/Documents/PADS/code\n",
      "Set seed to 0\n",
      "Loading autoencoder ckpt/ae_m512.pth\n"
     ]
    }
   ],
   "source": [
    "%cd /home/slimhy/Documents/PADS/code\n",
    "\"\"\"\n",
    "Extracting features into HDF5 files for each split.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "import util.misc as misc\n",
    "import models.s2vs as ae_mods\n",
    "\n",
    "\n",
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\"Extracting Features\", add_help=False)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=32,\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--text_model_name\",\n",
    "        type=str,\n",
    "        help=\"Text model name to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of autoencoder\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae-latent-dim\",\n",
    "        type=int,\n",
    "        default=512*8,\n",
    "        help=\"AE latent dimension\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae_pth\",\n",
    "        required=True,\n",
    "        help=\"Autoencoder checkpoint\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--point_cloud_size\",\n",
    "        default=2048,\n",
    "        type=int,\n",
    "        help=\"input size\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fetch_keys\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_embeds\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--intensity_loss\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Contrastive edit intensity loss using ground-truth labels.\",\n",
    "    )\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument(\n",
    "        \"--dataset\",\n",
    "        type=str,\n",
    "        choices=[\"graphedits\"],\n",
    "        help=\"dataset name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        type=str,\n",
    "        help=\"dataset path\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_type\",\n",
    "        type=str,\n",
    "        help=\"dataset type\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_edge_level\",\n",
    "        default=None,\n",
    "        type=int,\n",
    "        help=\"maximum edge level to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\", default=\"cuda\", help=\"device to use for training / testing\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_workers\", default=60, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--pin_mem\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.\",\n",
    "    )\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "# Set dummy arg string to debug the parser\n",
    "call_string = \"\"\"--ae_pth ckpt/ae_m512.pth \\\n",
    "    --ae kl_d512_m512_l8 \\\n",
    "    --ae-latent-dim 4096 \\\n",
    "    --batch_size 32 \\\n",
    "    --num_workers 8 \\\n",
    "    --device cuda\"\"\"\n",
    "    \n",
    "\n",
    "# Parse the arguments\n",
    "args = get_args_parser()\n",
    "args = args.parse_args(call_string.split())\n",
    "\n",
    "# --------------------\n",
    "device = torch.device(args.device)\n",
    "\n",
    "# Fix the seed for reproducibility\n",
    "misc.set_all_seeds(args.seed)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# --------------------\n",
    "\n",
    "# Instantiate autoencoder\n",
    "ae = ae_mods.__dict__[args.ae]()\n",
    "ae.eval()\n",
    "print(\"Loading autoencoder %s\" % args.ae_pth)\n",
    "ae.load_state_dict(torch.load(args.ae_pth, map_location=\"cpu\")[\"model\"])\n",
    "ae = ae.to(device)\n",
    "\n",
    "# Compile using torch.compile\n",
    "ae = torch.compile(ae, mode=\"max-autotune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.latents import ShapeLatentDataset, ComposedPairedShapesLoader\n",
    "from datasets.metadata import class_to_hex\n",
    "\n",
    "latents_dir =  \"/home/slimhy/Documents/datasets/PADS/3DCoMPaT\"\n",
    "\n",
    "# Create your dataset\n",
    "dataset = ShapeLatentDataset(latents_dir, shuffle_parts=False, class_code=class_to_hex(\"chair\"))\n",
    "\n",
    "# Create the DataLoader using the sampler\n",
    "dataloader = ComposedPairedShapesLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    pair_types_list=['rand_no_rot,rand_no_rot', 'part_drop,orig'],\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    ") \n",
    "\n",
    "# Use the dataloader in your training loop\n",
    "k_break = 1\n",
    "k = 0\n",
    "for (latents, part_bbs, part_labels, meta_A), (\n",
    "    latent_B,\n",
    "    bb_coords_B,\n",
    "    bb_labels_B,\n",
    "    meta_B, \n",
    ") in dataloader:\n",
    "    k += 1\n",
    "    if k == k_break:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_0, part_bbs_0 = latents[0], part_bbs[0]\n",
    "latent_0, part_bbs_0 = latent_0.to(device), part_bbs_0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import s2vs\n",
    "\n",
    "# Decode latent to mesh using s2vs\n",
    "mesh = s2vs.decode_latents(ae, latent_0.unsqueeze(0), grid_density=256, batch_size=64**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import trimesh\n",
    "\n",
    "def create_trimesh_boxes(bounding_boxes):\n",
    "    meshes = []\n",
    "    for box in bounding_boxes:\n",
    "        # Calculate the center of the bounding box\n",
    "        center = np.mean(box, axis=0)\n",
    "        \n",
    "        # Calculate the dimensions of the bounding box\n",
    "        dimensions = np.ptp(box, axis=0)\n",
    "        \n",
    "        # Create a box primitive using trimesh\n",
    "        mesh = trimesh.creation.box(extents=dimensions)\n",
    "        \n",
    "        # Move the box to the correct position\n",
    "        mesh.apply_translation(center)\n",
    "        \n",
    "        meshes.append(mesh)\n",
    "    \n",
    "    return meshes\n",
    "\n",
    "bounding_boxes = np.array(part_bbs_0.cpu())\n",
    "\n",
    "# Create the list of trimesh meshes\n",
    "trimesh_boxes = create_trimesh_boxes(bounding_boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slimhy/anaconda3/envs/shape2vecset/lib/python3.10/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"int64\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  warnings.warn(\n",
      "/home/slimhy/anaconda3/envs/shape2vecset/lib/python3.10/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"float64\" does not match required type \"float32\". A coerced copy has been created.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e66e7bfac9416d828e69e6ecb0dfa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plot(antialias=3, axes=['x', 'y', 'z'], axes_helper=1.0, axes_helper_colors=[16711680, 65280, 255], backgroundâ€¦"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import k3d\n",
    "\n",
    "# Use k3d colormaps\n",
    "unique_parts = np.array(range(len(trimesh_boxes)))\n",
    "col_map = k3d.helpers.map_colors(unique_parts, k3d.colormaps.basic_color_maps.Rainbow)\n",
    "col_map = [int(c) for c in col_map]\n",
    "\n",
    "# Create the plot\n",
    "plot = k3d.plot()\n",
    "\n",
    "all_bbs = []\n",
    "plot += k3d.mesh(np.array(mesh.vertices.cpu().numpy()), np.array(mesh.faces.cpu().numpy()), color=0xefefef)\n",
    "for k, bb_mesh in enumerate(trimesh_boxes):\n",
    "    # Set color with low alpha\n",
    "    plot += k3d.mesh(bb_mesh.vertices, bb_mesh.faces, color=col_map[k], opacity=0.5)\n",
    "    \n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrackedArray([[ 0.37249579, -0.49483607,  0.13550597],\n",
       "              [ 0.36855525,  0.47969185,  0.15851934],\n",
       "              [-0.11567337, -0.49682651,  0.13620537],\n",
       "              [-0.11961391,  0.4777014 ,  0.15921874],\n",
       "              [ 0.37196872, -0.48669762, -0.20921628],\n",
       "              [ 0.36802819,  0.48783029, -0.18620291],\n",
       "              [-0.11620044, -0.48868807, -0.20851688],\n",
       "              [-0.12014097,  0.48583985, -0.18550351]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh.trimesh_mesh.bounding_box_oriented.vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shape2vecset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
