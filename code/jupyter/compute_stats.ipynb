{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"3DCoMPaT\" to the path\n",
    "import sys\n",
    "sys.path.append(\"jupyter/3DCoMPaT/\")\n",
    "import utils3D.plot as plt_utils\n",
    "from compat3D import ShapeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extracting features into HDF5 files for each split.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import util.misc as misc\n",
    "import models.autoencoders as ae_mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\"Extracting Features\", add_help=False)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=32,\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--text_model_name\",\n",
    "        type=str,\n",
    "        help=\"Text model name to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of autoencoder\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae-latent-dim\",\n",
    "        type=int,\n",
    "        default=512*8,\n",
    "        help=\"AE latent dimension\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae_pth\",\n",
    "        required=True,\n",
    "        help=\"Autoencoder checkpoint\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--point_cloud_size\",\n",
    "        default=2048,\n",
    "        type=int,\n",
    "        help=\"input size\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fetch_keys\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_embeds\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--intensity_loss\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Contrastive edit intensity loss using ground-truth labels.\",\n",
    "    )\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument(\n",
    "        \"--dataset\",\n",
    "        type=str,\n",
    "        choices=[\"graphedits\"],\n",
    "        help=\"dataset name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        type=str,\n",
    "        help=\"dataset path\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_type\",\n",
    "        type=str,\n",
    "        help=\"dataset type\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_edge_level\",\n",
    "        default=None,\n",
    "        type=int,\n",
    "        help=\"maximum edge level to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\", default=\"cuda\", help=\"device to use for training / testing\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_workers\", default=60, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--pin_mem\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.\",\n",
    "    )\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dummy arg string to debug the parser\n",
    "call_string = \"\"\"--ae_pth ckpt/ae_m512.pth \\\n",
    "    --ae kl_d512_m512_l8 \\\n",
    "    --ae-latent-dim 4096 \\\n",
    "    --batch_size 32 \\\n",
    "    --num_workers 8 \\\n",
    "    --device cuda\"\"\"\n",
    "    \n",
    "\n",
    "# Parse the arguments\n",
    "args = get_args_parser()\n",
    "args = args.parse_args(call_string.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "device = torch.device(args.device)\n",
    "\n",
    "# Fix the seed for reproducibility\n",
    "misc.set_all_seeds(args.seed)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# --------------------\n",
    "\n",
    "# Instantiate autoencoder\n",
    "ae = ae_mods.__dict__[args.ae]()\n",
    "ae.eval()\n",
    "print(\"Loading autoencoder %s\" % args.ae_pth)\n",
    "ae.load_state_dict(torch.load(args.ae_pth, map_location=\"cpu\")[\"model\"])\n",
    "ae = ae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mcubes\n",
    "import trimesh\n",
    "\n",
    "\n",
    "GRID_DENSITY = 128\n",
    "def get_grid():\n",
    "    x = np.linspace(-1, 1, GRID_DENSITY+1)\n",
    "    y = np.linspace(-1, 1, GRID_DENSITY+1)\n",
    "    z = np.linspace(-1, 1, GRID_DENSITY+1)\n",
    "    xv, yv, zv = np.meshgrid(x, y, z)\n",
    "    grid = torch.from_numpy(np.stack([xv, yv, zv]).astype(np.float32)).view(3, -1).transpose(0, 1)[None].to(device, non_blocking=True)\n",
    "    return grid\n",
    "\n",
    "SAMPLE_GRID = get_grid()\n",
    "@torch.inference_mode()\n",
    "def decode_latent(latent):\n",
    "    latent = torch.tensor(latent).cuda().reshape(1, 512, 8).type(torch.float32)\n",
    " \n",
    "    logits = ae.decode(latent, SAMPLE_GRID)\n",
    "    logits = logits.detach()\n",
    "\n",
    "    volume = logits.view(GRID_DENSITY+1, GRID_DENSITY+1, GRID_DENSITY+1).permute(1, 0, 2).cpu().numpy()\n",
    "    verts, faces = mcubes.marching_cubes(volume, 0)\n",
    " \n",
    "    gap = 2. / GRID_DENSITY\n",
    "    verts *= gap\n",
    "    verts -= 1\n",
    " \n",
    "    m = trimesh.Trimesh(verts, faces)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pc(point_cloud, use_center_of_bounding_box=True):\n",
    "    \"\"\"\n",
    "    Normalize the point cloud to be in the range [-1, 1] and centered at the origin.\n",
    "    \"\"\"\n",
    "    min_x, max_x = torch.min(point_cloud[:, 0]), torch.max(point_cloud[:, 0])\n",
    "    min_y, max_y = torch.min(point_cloud[:, 1]), torch.max(point_cloud[:, 1])\n",
    "    min_z, max_z = torch.min(point_cloud[:, 2]), torch.max(point_cloud[:, 2])\n",
    "    # center the point cloud\n",
    "    if use_center_of_bounding_box:\n",
    "        center = torch.tensor(\n",
    "            [(min_x + max_x) / 2, (min_y + max_y) / 2, (min_z + max_z) / 2]\n",
    "        )\n",
    "    else:\n",
    "        center = torch.mean(point_cloud, dim=0)\n",
    "    point_cloud = point_cloud - center.to(point_cloud.device)\n",
    "    dist = torch.max(torch.sqrt(torch.sum((point_cloud**2), dim=1)))\n",
    "    point_cloud = point_cloud / dist  # scale the point cloud\n",
    "    return point_cloud * 8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy(path, scale):\n",
    "    data = np.load(path)\n",
    "    surface = data.astype(np.float32)\n",
    "    return surface * scale\n",
    "\n",
    "def flip_pc(pc):\n",
    "    #Â Flip Z and Y axes\n",
    "    pc = pc[:, [0, 2, 1]]\n",
    "    return pc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from shapenet_synsets import SHAPENET_CLASSES\n",
    "\n",
    "ZIP_SRC = \"/ibex/user/slimhy/surfaces.zip\"\n",
    "\n",
    "def shapenet_iterator(shape_cls):\n",
    "    # List all files in the zip file\n",
    "    with zipfile.ZipFile(ZIP_SRC, 'r') as zip_ref:\n",
    "        files = zip_ref.namelist()\n",
    "\n",
    "        for file in files:\n",
    "            if not file.startswith(SHAPENET_CLASSES[shape_cls]): continue\n",
    "            if not file.endswith(\".npz\"): continue\n",
    "            # Read a specific file from the zip file\n",
    "            with zip_ref.open(file) as file:\n",
    "                data = np.load(file)\n",
    "                yield data[\"points\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapenet_synsets import COMPAT_CLASSES\n",
    "\n",
    "METADATA_DIR = \"/ibex/user/slimhy/3DCoMPaT/3DCoMPaT-v2/metadata\"\n",
    "ZIP_PATH = \"/ibex/user/slimhy/3DCoMPaT/3DCoMPaT_ZIP.zip\"\n",
    "N_POINTS = 2**15\n",
    "\n",
    "\n",
    "def compat_iterator(shape_cls):\n",
    "    train_dataset = ShapeLoader(zip_path=ZIP_PATH,\n",
    "                                meta_dir=METADATA_DIR,\n",
    "                                split=\"train\",\n",
    "                                n_points=N_POINTS,\n",
    "                                shuffle=True,\n",
    "                                seed=0,\n",
    "                                filter_class=COMPAT_CLASSES[shape_cls])\n",
    "\n",
    "    for shape_id, shape_label, pointcloud, point_part_labels in train_dataset:\n",
    "        yield pointcloud, point_part_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Iterate over compat classes\n",
    "for compat_class in COMPAT_CLASSES:\n",
    "    #Â Average min/max values\n",
    "    avg_min = torch.zeros(3)\n",
    "    avg_max = torch.zeros(3)\n",
    "    \n",
    "    total_shapes = 0\n",
    "\n",
    "    # Iterate over all the point clouds in the class\n",
    "    for pc, _ in compat_iterator(compat_class):\n",
    "        pc_tensor = flip_pc(pc)\n",
    "        pc_tensor = pc.astype(np.float32)\n",
    "        pc_tensor = torch.tensor(pc_tensor)\n",
    "\n",
    "        # Compute min/max across each dimension\n",
    "        min_, max_ = torch.min(pc_tensor, dim=0)[0], torch.max(pc_tensor, dim=0)[0]\n",
    "        \n",
    "        # If there is a NaN value, skip the shape\n",
    "        if torch.isnan(min_).any() or torch.isnan(max_).any():\n",
    "            continue\n",
    "        \n",
    "        # Update the average min/max values\n",
    "        avg_min += min_\n",
    "        avg_max += max_\n",
    "        \n",
    "        total_shapes += 1\n",
    "        \n",
    "    avg_min /= total_shapes\n",
    "    avg_max /= total_shapes\n",
    "    \n",
    "    print(f\"Average min: {avg_min}, Average max: {avg_max}\")\n",
    "    \n",
    "    # Log to npz file in the \"stats\" folder\n",
    "    np.savez(f\"stats_compat/{compat_class}.npz\", avg_min=avg_min, avg_max=avg_max)\n",
    "    print(\"Saved stats for [%s]. \\n\" % compat_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chair_it_sp = shapenet_iterator(\"chair\")\n",
    "chair_it_cp = compat_iterator(\"chair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chair_tensor = next(chair_it_sp)\n",
    "plt_utils.plot_pointclouds(\n",
    "    [chair_tensor],\n",
    "    size=8,\n",
    "    cmap=\"viridis\",\n",
    "    point_size=2,\n",
    "    semantic_level=\"coarse\",\n",
    "    pic_height=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chair_tensor = next(chair_it_cp)[0]\n",
    "plt_utils.plot_pointclouds(\n",
    "    [flip_pc(np.array(chair_tensor))],\n",
    "    size=8,\n",
    "    cmap=\"viridis\",\n",
    "    point_size=2,\n",
    "    semantic_level=\"coarse\",\n",
    "    pic_height=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapenet_synsets import COMPAT_CLASSES\n",
    "\n",
    "#Â Iterate over compat classes\n",
    "for compat_class in COMPAT_CLASSES:\n",
    "    #Â Average min/max values\n",
    "    avg_min = torch.zeros(3)\n",
    "    avg_max = torch.zeros(3)\n",
    "    \n",
    "    total_shapes = 0\n",
    "\n",
    "    # Iterate over all the point clouds in the class\n",
    "    for pc in shapenet_iterator(compat_class):\n",
    "        pc_tensor = pc.astype(np.float32)\n",
    "        pc_tensor = torch.tensor(pc_tensor)\n",
    "\n",
    "        # Compute min/max across each dimension\n",
    "        min_, max_ = torch.min(pc_tensor, dim=0)[0], torch.max(pc_tensor, dim=0)[0]\n",
    "        \n",
    "        # If there is a NaN value, skip the shape\n",
    "        if torch.isnan(min_).any() or torch.isnan(max_).any():\n",
    "            continue\n",
    "        \n",
    "        # Update the average min/max values\n",
    "        avg_min += min_\n",
    "        avg_max += max_\n",
    "        \n",
    "        total_shapes += 1\n",
    "        \n",
    "    avg_min /= total_shapes\n",
    "    avg_max /= total_shapes\n",
    "    \n",
    "    print(f\"Average min: {avg_min}, Average max: {avg_max}\")\n",
    "    \n",
    "    # Log to npz file in the \"stats\" folder\n",
    "    np.savez(f\"stats_shapenet/{compat_class}.npz\", avg_min=avg_min, avg_max=avg_max)\n",
    "    print(\"Saved stats for [%s]. \\n\" % compat_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shape2vecset",
   "language": "python",
   "name": "shape2vecset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
