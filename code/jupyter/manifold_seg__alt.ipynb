{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code/\n",
    "\"\"\"\n",
    "Extracting features into HDF5 files for each split.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import torch\n",
    "import trimesh\n",
    "\n",
    "import util.misc as misc\n",
    "import util.s2vs as s2vs\n",
    "\n",
    "from datasets.shapeloaders import CoMPaTManifoldDataset, PartNetManifoldDataset, SingleManifoldDataset\n",
    "from util.misc import d_GPU, show_side_by_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.metadata import (\n",
    "    COMPAT_CLASSES,\n",
    "    int_to_hex,\n",
    ")\n",
    "import os\n",
    "from util.misc import CUDAMesh\n",
    "\n",
    "\n",
    "class CoMPaTSegDataset(SingleManifoldDataset):\n",
    "    \"\"\"\n",
    "    Sampling from a 3DCoMPaT manifold mesh dataset with segmentation labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        seg_dir,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seg_dir = seg_dir\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if self.normalize:\n",
    "            print(\n",
    "                \"normalize=True but 3DCoMPaT shapes are already normalized to their bounding boxes.\"\n",
    "            )\n",
    "\n",
    "    def get_mesh(self, idx=None):\n",
    "        \"\"\"\n",
    "        Load the mesh from the given index.\n",
    "        \"\"\"\n",
    "        if idx is None:\n",
    "            idx = self.mesh_idx\n",
    "\n",
    "        if self.mesh is None:\n",
    "            self.mesh = CUDAMesh.load(self.obj_files[idx], to_cuda=self.to_cuda)\n",
    "\n",
    "            # Print an alert if the mesh is not watertight\n",
    "            if not self.mesh.is_watertight:\n",
    "                print(\"Mesh is not watertight! Performing robust conversion...\")\n",
    "                obj_base_name = os.path.basename(self.obj_files[idx])\n",
    "                robust_pcu_to_manifold(self.obj_files[idx], \"/tmp/\" + obj_base_name)\n",
    "                # Try to load and test if watertight\n",
    "                self.mesh = CUDAMesh.load(\"/tmp/\" + obj_base_name, to_cuda=self.to_cuda)\n",
    "                if not self.mesh.is_watertight:\n",
    "                    raise ValueError(\"Watertight conversion failed!\")\n",
    "\n",
    "                # Replace the original mesh with the watertight one\n",
    "                # Write to original file\n",
    "                self.mesh.export(self.obj_files[idx])\n",
    "                print(\"Watertight conversion successful!\")\n",
    "\n",
    "            # Decimate the mesh if it has too many faces\n",
    "            if self.decimate and len(self.mesh.faces) > self.MAX_FACES:\n",
    "                # The ratio is the percentage of faces to REMOVE\n",
    "                ratio = 1 - self.MAX_FACES / len(self.mesh.faces)\n",
    "                self.mesh = decimate_mesh(self.mesh, ratio)\n",
    "\n",
    "        return self.mesh\n",
    "    \n",
    "    def set_seg(self, idx=None):\n",
    "        \"\"\"\n",
    "        Load the segmentation from the given index.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mesh_idx != idx or self.mesh is None:\n",
    "            self.mesh_idx = idx\n",
    "            self.get_mesh(idx)\n",
    "\n",
    "        # Optionally: first sample n_points first\n",
    "        # And simply serve the same points for the rest of the iterations\n",
    "        if self.sample_first:\n",
    "            # Use batch sampling\n",
    "            n_batches = self.n_points // self.MAX_SAMPLE_SIZE\n",
    "            all_points, all_occs = [], []\n",
    "            for k in range(n_batches):\n",
    "                if k % 4 == 0:\n",
    "                    print(\"Sampling batch [%d/%d]\" % (k + 1, n_batches))\n",
    "                points, occs = self.sampling_fn(self.mesh, self.MAX_SAMPLE_SIZE)\n",
    "                all_points += [points]\n",
    "                all_occs += [occs]\n",
    "            print()\n",
    "            points_idx = list(range(len(all_points)))\n",
    "\n",
    "        # Resample the mesh\n",
    "        for _ in range(self.max_it):\n",
    "            if self.sample_first:\n",
    "                rnd_idx = np.random.choice(points_idx)\n",
    "                points = all_points[rnd_idx]\n",
    "                occs = all_occs[rnd_idx]\n",
    "            else:\n",
    "                points, occs = self.sampling_fn(self.mesh, self.n_points)\n",
    "\n",
    "            # Optionally: normalize the point cloud\n",
    "            if self.normalize:\n",
    "                points = normalize_pc(points)\n",
    "            yield points, occs\n",
    "\n",
    "    def init_class_objs(self):\n",
    "        \"\"\"\n",
    "        Set the list of objects for a given class/split.\n",
    "        \"\"\"\n",
    "\n",
    "        def join_all(in_dir, files):\n",
    "            return sorted([os.path.join(in_dir, f) for f in files])\n",
    "\n",
    "        compat_cls_code = int_to_hex(COMPAT_CLASSES[self.shape_cls])\n",
    "        obj_files = os.listdir(self.obj_dir)\n",
    "        #Â obj_files = [os.path.join(self.obj_dir, f) for f in obj_files]\n",
    "        obj_files = [\n",
    "            f for f in obj_files if f.endswith(\".obj\") and compat_cls_code + \"_\" in f\n",
    "        ]\n",
    "\n",
    "        if self.split == \"all\":\n",
    "            self.obj_files = join_all(self.obj_dir, obj_files)\n",
    "            self.seg_files = join_all(self.seg_dir, [f.replace(\".obj\", \".gltf\") for f in obj_files])\n",
    "            return\n",
    "\n",
    "        # Open the split metadata\n",
    "        pwd = os.path.dirname(os.path.realpath(__file__))\n",
    "        split_dict = json.load(open(os.path.join(pwd, \"CoMPaT\", \"split.json\")))\n",
    "\n",
    "        # Filter split meshes\n",
    "        obj_files = [\n",
    "            f\n",
    "            for f in obj_files\n",
    "            if f.split(\".\")[0] in split_dict[self.split]\n",
    "        ]\n",
    "\n",
    "        self.obj_files = join_all(self.obj_dir, obj_files)\n",
    "        self.seg_files = join_all(self.seg_dir, [f.replace(\".obj\", \".gltf\") for f in obj_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import json\n",
    "from datasets.CoMPaT.compat3D import SegmentedMeshLoader\n",
    "from datasets.CoMPaT.utils3D.plot import label_to_RGB, FINE_RGB_RANGE\n",
    "\n",
    "ACTIVE_CLASS = \"chair\"\n",
    "OBJ_DIR  = \"/ibex/project/c2273/3DCoMPaT/obj_manifold/\"\n",
    "SEG_DIR  = \"/ibex/project/c2273/3DCoMPaT/gltf/\"\n",
    "ZIP_PATH = \"/ibex/project/c2273/3DCoMPaT/3DCoMPaT_ZIP.zip\"\n",
    "META_DIR = \"/ibex/project/c2273/3DCoMPaT/3DCoMPaT-v2/metadata\"\n",
    "OBJ_ID = 10\n",
    "\n",
    "\n",
    "# Instantiating manifold dataset\n",
    "manifold_dataset = CoMPaTSegDataset(\n",
    "    OBJ_DIR,\n",
    "    ACTIVE_CLASS,\n",
    "    10000,\n",
    "    seg_dir=SEG_DIR,\n",
    "    normalize=False,\n",
    "    sampling_method=\"surface\",\n",
    "    to_cuda=False\n",
    ")\n",
    "surface_points, _ = next(manifold_dataset[OBJ_ID])\n",
    "manifold_mesh = manifold_dataset.get_mesh(OBJ_ID)\n",
    "\n",
    "\n",
    "# Instantiating segment dataset\n",
    "seg_dataset = SegmentedMeshLoader(\n",
    "    zip_path=ZIP_PATH,\n",
    "    meta_dir=META_DIR,\n",
    "    split=\"train\",\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "model_id = manifold_dataset.obj_files[OBJ_ID].split(\"/\")[-1].split(\".\")[0]\n",
    "mesh_id = seg_dataset.get_model_index(model_id)\n",
    "mesh_map = seg_dataset[mesh_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "def sample_face_points(mesh, num_samples_per_face, random_sampling=True):\n",
    "    \"\"\"\n",
    "    Sample points on the faces of a mesh.\n",
    "    \"\"\"\n",
    "    num_faces = len(mesh.faces)\n",
    "    total_samples = num_faces * num_samples_per_face\n",
    "    \n",
    "    # Get all vertices for each face\n",
    "    face_vertices = mesh.vertices[mesh.faces]\n",
    "    \n",
    "    if random_sampling:\n",
    "        # Generate random barycentric coordinates\n",
    "        r1, r2 = np.random.random((2, total_samples))\n",
    "        r1 = np.sqrt(r1)\n",
    "        a = 1 - r1\n",
    "        b = r1 * (1 - r2)\n",
    "        c = r2 * r1\n",
    "    else:\n",
    "        # TODO: Fix!!\n",
    "        a = np.full(total_samples, 1/3)\n",
    "        b = np.full(total_samples, 1/3)\n",
    "        c = np.full(total_samples, 1/3)\n",
    "\n",
    "    # Reshape barycentric coordinates to match face_vertices shape\n",
    "    barycentric_coords = np.column_stack([a, b, c]).reshape(num_faces, num_samples_per_face, 3)\n",
    "    \n",
    "    # Compute points on triangles\n",
    "    points = (face_vertices[:, np.newaxis, :, :] * barycentric_coords[:, :, :, np.newaxis]).sum(axis=2)\n",
    "    \n",
    "    # Reshape to 2D array\n",
    "    return points.reshape(-1, 3)\n",
    "\n",
    "\n",
    "def sample_face_points_center(mesh):\n",
    "    \"\"\"\n",
    "    Sample points on the center of each face efficiently.\n",
    "    \"\"\"\n",
    "    num_faces = len(mesh.faces)\n",
    "    \n",
    "    # Initialize the output array\n",
    "    points = np.zeros((num_faces, 3))\n",
    "    \n",
    "    for i, face in enumerate(mesh.faces):\n",
    "        # Compute the mean of the face vertices\n",
    "        points[i] = np.mean(mesh.vertices[face], axis=0)\n",
    "    \n",
    "    return points\n",
    "    \n",
    "\n",
    "def find_closest_meshes(mesh_list, pointcloud):\n",
    "    num_samples_per_face = 50\n",
    "    closest_mesh_indices = np.zeros(len(pointcloud), dtype=int)\n",
    "    min_distances = np.full(len(pointcloud), np.inf)\n",
    "\n",
    "    for i, mesh in enumerate(mesh_list):\n",
    "        # Sample points on the surface of the mesh\n",
    "        sampled_points = sample_face_points(mesh, num_samples_per_face, True)\n",
    "\n",
    "        # Create a KD-tree for the current mesh's vertices\n",
    "        tree = cKDTree(sampled_points)\n",
    "        \n",
    "        # Find the distance to the closest vertex for each point in the pointcloud\n",
    "        distances, _ = tree.query(pointcloud)\n",
    "        \n",
    "        # Update closest_mesh_indices where this mesh is closer\n",
    "        closer_points = distances < min_distances\n",
    "        closest_mesh_indices[closer_points] = i\n",
    "        min_distances[closer_points] = distances[closer_points]\n",
    "\n",
    "    return closest_mesh_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "# Silence traittypes warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import k3d\n",
    "\n",
    "# Use k3d colormaps\n",
    "unique_parts = np.array(range(len(mesh_map)))\n",
    "col_map = k3d.helpers.map_colors(unique_parts, k3d.colormaps.basic_color_maps.Rainbow)\n",
    "col_map = {key: col_map[i] for i, key in enumerate(mesh_map)}\n",
    "\n",
    "def get_point_colors(mesh_map, manifold_mesh):\n",
    "    face_samples = sample_face_points_center(manifold_mesh.trimesh_mesh)\n",
    "    col_list = [col_map[mesh_label] for mesh_label in mesh_map]\n",
    "    all_idx = find_closest_meshes(mesh_map.values(), face_samples)\n",
    "    point_colors = [col_list[i] for i in all_idx]\n",
    "    \n",
    "    return col_list, all_idx, point_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import trimesh\n",
    "\n",
    "def hex_to_rgb(hex_color):\n",
    "    # Ensure the hex color is a positive integer\n",
    "    hex_color = abs(hex_color)\n",
    "    \n",
    "    # Extract RGB components\n",
    "    r = (hex_color >> 16) & 255\n",
    "    g = (hex_color >> 8) & 255\n",
    "    b = hex_color & 255\n",
    "\n",
    "    return (r, g, b)\n",
    "\n",
    "\n",
    "def assign_colors(mesh, face_color):\n",
    "    mesh = trimesh.Trimesh(vertices=mesh.vertices, faces=mesh.faces)\n",
    "\n",
    "    # Convert face_colors to RGB\n",
    "    rgb_colors = np.repeat([hex_to_rgb(face_color)], len(mesh.faces), axis=0)\n",
    "\n",
    "    mesh.faces = np.vstack((mesh.faces, np.fliplr(mesh.faces)))\n",
    "\n",
    "    # Assign updated colors to the mesh faces (take into account the duplicated faces)\n",
    "    mesh.visual.face_colors = np.vstack((rgb_colors, rgb_colors))\n",
    "    # Set two-sided rendering\n",
    "    mesh.visual.two_sided = True\n",
    "\n",
    "    return mesh\n",
    "\n",
    "def remove_faces_and_assign_colors(mesh, face_colors, faces_to_remove):\n",
    "    mesh = mesh.copy()\n",
    "\n",
    "    # Convert face_colors to RGB\n",
    "    rgb_colors = np.array([hex_to_rgb(color) for color in face_colors])\n",
    "\n",
    "    # Create a mask for faces to keep\n",
    "    mask = np.ones(len(mesh.faces), dtype=bool)\n",
    "    mask[faces_to_remove] = False\n",
    "\n",
    "    # Remove faces\n",
    "    mesh.update_faces(mask)\n",
    "    mesh.remove_unreferenced_vertices()\n",
    "\n",
    "    # Update face colors\n",
    "    rgb_colors = rgb_colors[mask]\n",
    "\n",
    "    mesh.faces = np.vstack((mesh.faces, np.fliplr(mesh.faces)))\n",
    "\n",
    "    # Assign updated colors to the mesh faces (take into account the duplicated faces)\n",
    "    mesh.visual.face_colors = np.vstack((rgb_colors, rgb_colors))\n",
    "    # Set two-sided rendering\n",
    "    mesh.visual.two_sided = True\n",
    "\n",
    "    return mesh\n",
    "\n",
    "\n",
    "def show_part(my_mesh, mesh_map, part_label):\n",
    "    # get the indices of all faces not belonging to the part\n",
    "    faces_to_hide = np.where(np.array(all_idx) != part_label)[0]\n",
    "\n",
    "    mesh_labels = list(mesh_map.keys())\n",
    "    face_colors = [col_map[mesh_label] for mesh_label in [mesh_labels[i] for i in all_idx]]\n",
    "\n",
    "    # Apply the colors and hide specified faces\n",
    "    my_mesh = remove_faces_and_assign_colors(my_mesh, face_colors, faces_to_hide)\n",
    "\n",
    "    return my_mesh\n",
    "\n",
    "# Get the point colors\n",
    "col_list, all_idx, point_colors = get_point_colors(mesh_map, manifold_mesh)\n",
    "\n",
    "part_id = 5\n",
    "proj_part = show_part(manifold_mesh.trimesh_mesh, mesh_map, part_id)\n",
    "orig_part_label, orig_part = list(mesh_map.items())[part_id]\n",
    "orig_part = assign_colors(orig_part, col_map[orig_part_label])\n",
    "\n",
    "show_side_by_side(proj_part, orig_part)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
