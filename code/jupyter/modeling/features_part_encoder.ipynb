{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibex/user/slimhy/PADS/code\n",
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n"
     ]
    }
   ],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code\n",
    "%reload_ext autoreload\n",
    "%set_env CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
    "\"\"\"\n",
    "Extracting features into HDF5 files for each split.\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from models.points.pointbert_utils import fps\n",
    "from models.points.encoders import pointbert_g512_d12_compat\n",
    "from datasets.metadata import N_COMPAT_CLASSES, N_COMPAT_FINE_PARTS\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "def gen_mock_data(\n",
    "    batch_size=4,\n",
    "    num_parts=24,\n",
    "    num_latents=512,\n",
    "    num_classes=250,\n",
    "    get_part_points=False,\n",
    "    num_points=4096,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    latents = torch.rand(batch_size, num_latents, 8)\n",
    "    part_bbs = torch.rand(batch_size, num_parts, 4, 3)\n",
    "    part_labels = torch.randint(\n",
    "        0, num_classes, (batch_size, num_parts), dtype=torch.long\n",
    "    )\n",
    "    shape_cls = torch.randint(0, 10, (batch_size, 1), dtype=torch.long)\n",
    "    batch_mask = torch.ones(batch_size, num_parts).bool()\n",
    "\n",
    "    if get_part_points:\n",
    "        part_points = torch.rand(batch_size, num_parts, num_points, 3)\n",
    "        data_tup = latents, part_bbs, part_labels, part_points, shape_cls, batch_mask\n",
    "    else:\n",
    "        data_tup = latents, part_bbs, part_labels, shape_cls, batch_mask\n",
    "    return tuple(map(lambda x: x.to(device), data_tup))\n",
    "\n",
    "\n",
    "def is_close(tensor1, tensor2, rtol=1e-5, atol=1e-5):\n",
    "    return torch.allclose(\n",
    "        tensor1, tensor2, rtol=rtol, atol=atol\n",
    "    )\n",
    "    \n",
    "\n",
    "latents, part_bbs, part_labels, part_points, shape_cls, batch_mask = gen_mock_data(get_part_points=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defining a part-neural asset model.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from models.points.pointbert_utils import fps\n",
    "\n",
    "\n",
    "class WeightedAggregation(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super().__init__()\n",
    "        self.weight_layer = nn.Linear(feature_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute weights for each feature vector\n",
    "        weights = self.weight_layer(x)  # B, N_p, 512, 1\n",
    "\n",
    "        # Apply softmax to get a probability distribution\n",
    "        weights = F.softmax(weights, dim=-1)  # B, N_p, 512, 1\n",
    "\n",
    "        # Apply weights to input vectors and sum\n",
    "        weighted_sum = torch.mean(weights * x, dim=2)  # B, N_p, 128\n",
    "\n",
    "        return weighted_sum\n",
    "\n",
    "\n",
    "class BoundingBoxTokenizer(nn.Module):\n",
    "    def __init__(\n",
    "        self, bb_input_dim=12, mlp_hidden_dim=64, mlp_output_dim=32, mlp_depth=3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.mlp = self._build_mlp(\n",
    "            bb_input_dim, mlp_hidden_dim, mlp_output_dim, mlp_depth\n",
    "        )\n",
    "        self.output_dim = mlp_output_dim\n",
    "\n",
    "    def _build_mlp(self, input_dim, hidden_dim, output_dim, depth):\n",
    "        layers = []\n",
    "\n",
    "        # Input layer\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(depth - 2):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, part_bbs):\n",
    "        B, P, _, _ = part_bbs.shape  # B, P, 4, 3\n",
    "\n",
    "        # Flatten the bounding boxes\n",
    "        flattened_bbs = part_bbs.view(B, P, -1)  # B, P, 12\n",
    "\n",
    "        # Process through MLP\n",
    "        pose_tokens = self.mlp(flattened_bbs)  # B, P, mlp_output_dim\n",
    "\n",
    "        return pose_tokens\n",
    "\n",
    "\n",
    "class PartTokenizer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pc_encoder,\n",
    "        bb_input_dim=12,\n",
    "        bb_hidden_dim=64,\n",
    "        bb_output_dim=32,\n",
    "        bb_mlp_depth=3,\n",
    "        visual_feature_dim=128,\n",
    "        out_dim=512,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pc_encoder = pc_encoder\n",
    "        self.bb_tokenizer = BoundingBoxTokenizer(\n",
    "            bb_input_dim=bb_input_dim,\n",
    "            mlp_hidden_dim=bb_hidden_dim,\n",
    "            mlp_output_dim=bb_output_dim,\n",
    "            mlp_depth=bb_mlp_depth,\n",
    "        )\n",
    "        self.visual_aggregator = WeightedAggregation(feature_dim=visual_feature_dim)\n",
    "        self.output_dim = bb_output_dim + visual_feature_dim\n",
    "        self.out_proj = nn.Linear(self.output_dim, out_dim)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        part_bbs,\n",
    "        part_points,\n",
    "        batch_mask,  # 1 if part is invalid, 0 otherwise\n",
    "        shape_cls=None,\n",
    "        num_samples=512,\n",
    "        deterministic=False,\n",
    "    ):\n",
    "        batch_mask = (\n",
    "            ~batch_mask\n",
    "        )  # Invert mask to make 0 if part is invalid, 1 otherwise\n",
    "        B, P = batch_mask.shape\n",
    "\n",
    "        # Apply mask to bounding boxes and get tokens\n",
    "        bb_tokens = self.bb_tokenizer(part_bbs)  # B, P, bb_output_dim\n",
    "        bb_tokens = bb_tokens * batch_mask.unsqueeze(-1)  # Zero out invalid parts\n",
    "\n",
    "        # Process point clouds\n",
    "        N_s = num_samples\n",
    "        resampled = self.subsample_parts(\n",
    "            part_points, num_samples=N_s, deterministic=deterministic\n",
    "        )\n",
    "        _, top_fts = self.pc_encoder(resampled, cls_label=shape_cls)\n",
    "        part_fts = top_fts.reshape(B, P, N_s, -1)\n",
    "\n",
    "        # Zero out invalid parts in point features\n",
    "        print(top_fts.shape)\n",
    "        part_fts = part_fts * batch_mask.unsqueeze(-1).unsqueeze(-1)\n",
    "        print(part_fts.shape)\n",
    "\n",
    "        # Apply weighted aggregation to get visual tokens\n",
    "        visual_tokens = self.visual_aggregator(part_fts)  # B, P, visual_feature_dim\n",
    "        visual_tokens = visual_tokens * batch_mask.unsqueeze(\n",
    "            -1\n",
    "        )  # Zero out invalid parts\n",
    "\n",
    "        # Concatenate bounding box tokens and visual tokens\n",
    "        combined_tokens = torch.cat(\n",
    "            [bb_tokens, visual_tokens], dim=-1\n",
    "        )  # B, P, bb_output_dim + visual_feature_dim\n",
    "\n",
    "        return self.out_proj(combined_tokens), (bb_tokens, visual_tokens)\n",
    "\n",
    "    def load_encoder_checkpoint(self, ckpt_path):\n",
    "        ckpt = torch.load(ckpt_path)\n",
    "        self.pc_encoder.load_state_dict(ckpt)\n",
    "\n",
    "    @staticmethod\n",
    "    @torch.inference_mode()\n",
    "    def subsample_parts(part_points, num_samples=512, deterministic=False):\n",
    "        N_s = num_samples\n",
    "        B, P, N, C = part_points.shape\n",
    "        resampled = torch.zeros((B, P, N_s, C)).to(part_points.device)\n",
    "        if deterministic:\n",
    "            for i, p in enumerate(part_points):\n",
    "                resampled[i] = p[:, :N_s]\n",
    "        else:\n",
    "            for i, p in enumerate(part_points):\n",
    "                resampled[i] = fps(p, N_s)\n",
    "        return resampled.view(B, P * N_s, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 12288, 128])\n",
      "torch.Size([4, 24, 512, 128])\n",
      "torch.Size([4, 24, 512])\n"
     ]
    }
   ],
   "source": [
    "pc_encoder = pointbert_g512_d12_compat()\n",
    "part_tokenizer = PartTokenizer(\n",
    "    pc_encoder=pc_encoder,\n",
    "    bb_input_dim=12,\n",
    "    bb_hidden_dim=64,\n",
    "    bb_output_dim=32,\n",
    "    bb_mlp_depth=3,\n",
    "    visual_feature_dim=128,\n",
    "    out_dim=512,\n",
    ").cuda()\n",
    "\n",
    "ckpt_path = \"/ibex/user/slimhy/PADS/code/ckpt/pointbert.pth\"\n",
    "part_tokenizer.load_encoder_checkpoint(ckpt_path)\n",
    "\n",
    "part_tokens, _ = part_tokenizer(part_bbs, part_points, batch_mask=batch_mask, shape_cls=shape_cls)\n",
    "print(part_tokens.shape)  # B, P, 160 (32 + 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local features are not equivariant\n",
      "Global features are not invariant\n",
      "BoundingBoxTokenizer is permutation equivariant w.r.t. parts shuffling.\n",
      "torch.Size([4, 24, 512, 128])\n",
      "torch.Size([4, 24, 512, 128])\n",
      "torch.Size([4, 24, 512, 128])\n",
      "torch.Size([4, 24, 512, 128])\n",
      "PartTokenizer is permutation equivariant w.r.t. parts shuffling.\n"
     ]
    }
   ],
   "source": [
    "import models.diffusion as dm\n",
    "\n",
    "\n",
    "def test_pc_encoder_permutation_equivariance():\n",
    "    # Initialize encoder\n",
    "    pc_encoder = dm.kl_d512_m512_l8_d24_passets().pqe.pc_encoder.cuda()\n",
    "    \n",
    "    # Create single shape point cloud\n",
    "    points = torch.randn(1, 1024, 3).cuda()\n",
    "    shape_cls = torch.zeros(1).long().cuda()\n",
    "    \n",
    "    # Get original output\n",
    "    local_feat, global_feat = pc_encoder(points, cls_label=shape_cls)\n",
    "    \n",
    "    # Shuffle points with single permutation\n",
    "    perm = torch.randperm(1024)\n",
    "    points_shuffled = points[:, perm]\n",
    "    \n",
    "    # Get output with shuffled points\n",
    "    local_feat_shuffled, global_feat_shuffled = pc_encoder(points_shuffled, cls_label=shape_cls)\n",
    "    \n",
    "    # Check local features are permuted the same way\n",
    "    if not is_close(local_feat[:, perm], local_feat_shuffled):\n",
    "        print(\"Local features are not equivariant\")\n",
    "    \n",
    "    # Check global features don't change\n",
    "    if not is_close(global_feat, global_feat_shuffled):\n",
    "        print(\"Global features are not invariant\")\n",
    "\n",
    "\n",
    "def test_bb_tokenizer_permutation_equivariance():\n",
    "    # Initialize the BoundingBoxTokenizer\n",
    "    bb_tokenizer = BoundingBoxTokenizer(\n",
    "        bb_input_dim=12,\n",
    "        mlp_hidden_dim=64,\n",
    "        mlp_output_dim=32,\n",
    "        mlp_depth=3\n",
    "    ).cuda()\n",
    "\n",
    "    # Create mock data\n",
    "    batch_size, num_parts = 2, 24\n",
    "    part_bbs = torch.randn(batch_size, num_parts, 4, 3).cuda()\n",
    "\n",
    "    # Get original output\n",
    "    original_output = bb_tokenizer(part_bbs)\n",
    "\n",
    "    # Shuffle parts\n",
    "    perm = torch.randperm(num_parts)\n",
    "    shuffled_part_bbs = part_bbs[:, perm]\n",
    "\n",
    "    # Get output with shuffled parts\n",
    "    shuffled_output = bb_tokenizer(shuffled_part_bbs)\n",
    "\n",
    "    # Check if outputs are equivariant (i.e., shuffled in the same way)\n",
    "    assert is_close(original_output[:, perm], shuffled_output), \"Outputs are not equivariant to parts shuffling.\"\n",
    "    print(\"BoundingBoxTokenizer is permutation equivariant w.r.t. parts shuffling.\")\n",
    "\n",
    "\n",
    "def test_part_tokenizer_permutation_equivariance():\n",
    "    # Initialize the PartTokenizer\n",
    "    part_tokenizer = dm.kl_d512_m512_l8_d24_passets().pqe.cuda()\n",
    "\n",
    "    # Create mock data\n",
    "    latents, part_bbs, part_labels, part_points, shape_cls, batch_mask = gen_mock_data(get_part_points=True)\n",
    "    num_parts = part_bbs.shape[1]\n",
    "\n",
    "    # Get original output\n",
    "    original_output, _ = part_tokenizer(part_bbs, part_points, batch_mask=batch_mask, shape_cls=shape_cls)\n",
    "\n",
    "    # Shuffle parts\n",
    "    perm = torch.randperm(num_parts)\n",
    "    shuffled_part_bbs = part_bbs[:, perm]\n",
    "    shuffled_part_points = part_points[:, perm]\n",
    "\n",
    "    # Get output with shuffled parts\n",
    "    shuffled_output, _ = part_tokenizer(shuffled_part_bbs, shuffled_part_points, batch_mask=batch_mask, shape_cls=shape_cls)\n",
    "\n",
    "    # Check if outputs are equivariant (i.e., shuffled in the same way)\n",
    "    if not is_close(original_output[:, perm], shuffled_output):\n",
    "        print(\"Outputs are not equivariant to parts shuffling.\")\n",
    "    else:\n",
    "        print(\"PartTokenizer is permutation equivariant w.r.t. parts shuffling.\")\n",
    "\n",
    "\n",
    "test_pc_encoder_permutation_equivariance()\n",
    "test_bb_tokenizer_permutation_equivariance()\n",
    "test_part_tokenizer_permutation_equivariance()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
