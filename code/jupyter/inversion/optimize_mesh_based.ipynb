{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"3DCoMPaT\" to the path\n",
    "import sys\n",
    "sys.path.append(\"jupyter/3DCoMPaT/\")\n",
    "from compat3D import ShapeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extracting features into HDF5 files for each split.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import util.misc as misc\n",
    "import util.s2vs as s2vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\"Extracting Features\", add_help=False)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=32,\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--text_model_name\",\n",
    "        type=str,\n",
    "        help=\"Text model name to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of autoencoder\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae-latent-dim\",\n",
    "        type=int,\n",
    "        default=512*8,\n",
    "        help=\"AE latent dimension\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae_pth\",\n",
    "        required=True,\n",
    "        help=\"Autoencoder checkpoint\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--point_cloud_size\",\n",
    "        default=2048,\n",
    "        type=int,\n",
    "        help=\"input size\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fetch_keys\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_embeds\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--intensity_loss\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Contrastive edit intensity loss using ground-truth labels.\",\n",
    "    )\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument(\n",
    "        \"--dataset\",\n",
    "        type=str,\n",
    "        choices=[\"graphedits\"],\n",
    "        help=\"dataset name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        type=str,\n",
    "        help=\"dataset path\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_type\",\n",
    "        type=str,\n",
    "        help=\"dataset type\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_edge_level\",\n",
    "        default=None,\n",
    "        type=int,\n",
    "        help=\"maximum edge level to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\", default=\"cuda\", help=\"device to use for training / testing\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_workers\", default=60, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--pin_mem\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.\",\n",
    "    )\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dummy arg string to debug the parser\n",
    "call_string = \"\"\"--ae_pth ckpt/ae_m512.pth \\\n",
    "    --ae kl_d512_m512_l8 \\\n",
    "    --ae-latent-dim 4096 \\\n",
    "    --batch_size 32 \\\n",
    "    --num_workers 8 \\\n",
    "    --device cuda\"\"\"\n",
    "    \n",
    "\n",
    "# Parse the arguments\n",
    "args = get_args_parser()\n",
    "args = args.parse_args(call_string.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device and seed\n",
    "device = torch.device(args.device)\n",
    "misc.set_all_seeds(args.seed)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Instantiate autoencoder\n",
    "ae = s2vs.load_model(args.ae, args.ae_pth, device, torch_compile=True)\n",
    "ae = ae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from metadata import SHAPENET_CLASSES, COMPAT_CLASSES, COMPAT_TRANSFORMS\n",
    "\n",
    "\n",
    "ACTIVE_CLASS = \"chair\"\n",
    "METADATA_DIR = \"/ibex/user/slimhy/3DCoMPaT/3DCoMPaT-v2/metadata\"\n",
    "ZIP_SRC = \"/ibex/user/slimhy/surfaces.zip\"\n",
    "ZIP_PATH = \"/ibex/user/slimhy/3DCoMPaT/3DCoMPaT_ZIP.zip\"\n",
    "N_POINTS = 2**21\n",
    "\n",
    "\n",
    "def shapenet_iterator(shape_cls):\n",
    "    # List all files in the zip file\n",
    "    with zipfile.ZipFile(ZIP_SRC, 'r') as zip_ref:\n",
    "        files = zip_ref.namelist()\n",
    "\n",
    "        for file in files:\n",
    "            if not file.startswith(SHAPENET_CLASSES[shape_cls]): continue\n",
    "            if not file.endswith(\".npz\"): continue\n",
    "            # Read a specific file from the zip file\n",
    "            with zip_ref.open(file) as file:\n",
    "                data = np.load(file)\n",
    "                yield data[\"points\"].astype(np.float32)\n",
    "        \n",
    "\n",
    "def compat_iterator(shape_cls):\n",
    "    train_dataset = ShapeLoader(\n",
    "        zip_path=ZIP_PATH,\n",
    "        meta_dir=METADATA_DIR,\n",
    "        split=\"train\",\n",
    "        n_points=N_POINTS,\n",
    "        shuffle=True,\n",
    "        seed=0,\n",
    "        filter_class=COMPAT_CLASSES[shape_cls]\n",
    "    )\n",
    "\n",
    "    for shape_id, shape_label, pointcloud, point_part_labels in train_dataset:\n",
    "        yield COMPAT_TRANSFORMS[shape_cls](pointcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapeloaders import SingleManifoldDataset\n",
    "\n",
    "OBJ_DIR = \"/ibex/user/slimhy/PADS/data/obj_manifold/\"\n",
    "OBJ_ID = 2\n",
    "\n",
    "# Instantiate the dataset\n",
    "shape_dataset = SingleManifoldDataset(\n",
    "    OBJ_DIR,\n",
    "    ACTIVE_CLASS,\n",
    "    N_POINTS,\n",
    "    normalize=False,\n",
    "    sampling_method=\"volume+near_surface\",\n",
    "    contain_method=\"occnets\",\n",
    "    decimate=True,\n",
    "    sample_first=False\n",
    ")\n",
    "it_shape = shape_dataset[OBJ_ID]\n",
    "\n",
    "# Initialize the latents\n",
    "orig_dataset = SingleManifoldDataset(\n",
    "    OBJ_DIR,\n",
    "    ACTIVE_CLASS,\n",
    "    N_POINTS,\n",
    "    normalize=False,\n",
    "    sampling_method=\"surface\"\n",
    ")\n",
    "surface_points, _ = next(orig_dataset[OBJ_ID])\n",
    "init_latents = s2vs.encode_pc(ae, surface_points).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from schedulefree import AdamWScheduleFree\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def optimize_latents(ae, shape_it, init_latents, max_iter=100, optimizer=None):\n",
    "    \"\"\"\n",
    "    Optimize input latent codes w.r.t. a single object.\n",
    "    \"\"\"\n",
    "    # Activate gradient computation for the latents\n",
    "    latents = init_latents.clone().detach().to(device).requires_grad_(True)\n",
    "    if optimizer is None:\n",
    "        optimizer = torch.optim.Adam\n",
    "    optimizer = optimizer([latents], lr=1e-3)\n",
    "    \n",
    "    # Main optimization loop\n",
    "    for i, (surface_points, occs) in enumerate(shape_it):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Sample points from the shape surface\n",
    "        surface_points = surface_points.unsqueeze(0).to(device)\n",
    "\n",
    "        # Query the autoencoder\n",
    "        logits = s2vs.query_latents(ae, latents, surface_points, use_graph=True).squeeze()\n",
    "        occs = occs.float().to(device)\n",
    "\n",
    "        # Compute BCE loss\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, occs).mean()\n",
    "        \n",
    "        # Add gradient clipping\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iter %d: Loss %.4f\" % (i, loss.item()))\n",
    "        if i >= max_iter:\n",
    "            break\n",
    "\n",
    "    return latents.detach().cpu()\n",
    "\n",
    "optimized_latents = optimize_latents(ae,\n",
    "                                     it_shape,\n",
    "                                     init_latents,\n",
    "                                     max_iter=20,\n",
    "                                     optimizer=AdamWScheduleFree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.metrics import iou_occupancies, chamfer_distance, f_score\n",
    "from util.sampling import sample_surface_tpp\n",
    "from util.contains.inside_mesh import is_inside\n",
    "from util.misc import d_GPU, show_side_by_side, timer_init, timer_end\n",
    "\n",
    "\n",
    "def evaluate_reconstruction(obj_original, rec_mesh, latents, n_queries=2**21, n_queries_chamfer=2**15, query_method=\"occnets\"):\n",
    "    \"\"\"\n",
    "    Compute IoU and Chamfer distance between the original object and the reconstructed mesh.\n",
    "    - IoU: Computed using [n_queries] random points sampled from the 3D space.\n",
    "    - CD: Computed using [n_queries] points sampled from the object surface.\n",
    "    \"\"\"\n",
    "    timer_init(\"surface_sampling\")\n",
    "\n",
    "    # Sample N_POINTS points from obj_original and rec_mesh\n",
    "    pc_original = sample_surface_tpp(obj_original, n_queries_chamfer)\n",
    "    pc_rec = sample_surface_tpp(rec_mesh, n_queries_chamfer)\n",
    "    chamfer = chamfer_distance(pc_original, pc_rec)\n",
    "    f_sc = f_score(gt=pc_original, pred=pc_rec)\n",
    "    \n",
    "    timer_end()\n",
    "    timer_init(\"point_sampling\")\n",
    "\n",
    "    #Â Sample n_queries points from the 3D space\n",
    "    point_queries = torch.rand((1, n_queries, 3)).cuda()\n",
    "    \n",
    "    timer_end()\n",
    "    timer_init(\"predict_occ\")\n",
    "    \n",
    "    # Get predicted occupancies for each point\n",
    "    latents = latents.to(device)\n",
    "    pred_occs = s2vs.predict_occupancies(ae, latents, point_queries, n_queries)\n",
    "\n",
    "    timer_end()\n",
    "    timer_init(\"is_inside\")\n",
    "\n",
    "    # Get ground-truth occupancy for each point\n",
    "    gt_occs = is_inside(obj_original, point_queries, query_method=query_method)\n",
    "\n",
    "    timer_end()\n",
    "    timer_init(\"iou_occ\")\n",
    "\n",
    "    # Compute IoU between predicted and ground-truth occupancies\n",
    "    iou = iou_occupancies(pred_occs, gt_occs)\n",
    "    \n",
    "    timer_end()\n",
    "    \n",
    "    return f_sc.item(), chamfer.item(), iou.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the optimized latents\n",
    "rec_mesh = s2vs.decode_latents(ae, d_GPU(optimized_latents), grid_density=256, batch_size=128**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the optimized latents\n",
    "rec_mesh = s2vs.decode_latents(ae, d_GPU(optimized_latents), grid_density=256, batch_size=128**3, smooth_volume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mesh = shape_dataset.obj\n",
    "evaluate_reconstruction(orig_mesh, rec_mesh, optimized_latents, query_method=\"occnets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the old latents\n",
    "old_latents = init_latents\n",
    "old_rec_mesh = s2vs.decode_latents(ae, d_GPU(old_latents), grid_density=256, batch_size=128**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_rec_mesh = s2vs.decode_latents(ae, d_GPU(old_latents), grid_density=256, batch_size=128**3, smooth_volume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_reconstruction(orig_mesh, old_rec_mesh, old_latents, query_method=\"occnets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_side_by_side(orig_mesh, rec_mesh, old_rec_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mcubes\n",
    "\n",
    "# Create a data volume (30 x 30 x 30)\n",
    "X, Y, Z = np.mgrid[:30, :30, :30]\n",
    "u = (X-15)**2 + (Y-15)**2 + (Z-15)**2 - 8**2\n",
    "\n",
    "# Extract the 0-isosurface\n",
    "vertices, triangles = mcubes.marching_cubes(u, 0)\n",
    "\n",
    "# Export the result to sphere.dae\n",
    "mcubes.export_mesh(vertices, triangles, \"sphere.dae\", \"MySphere\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
