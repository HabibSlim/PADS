{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibex/user/slimhy/PADS/code\n"
     ]
    }
   ],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code/\n",
    "\"\"\"\n",
    "Invert a set of input shapes.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import util.misc as misc\n",
    "import util.s2vs as s2vs\n",
    "\n",
    "from datasets.sampling import sample_surface_tpp\n",
    "from eval.metrics import chamfer_distance, f_score\n",
    "\n",
    "\n",
    "def get_args_parser():\n",
    "    \"\"\"\n",
    "    Parsing input arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\"Extracting Latents\", add_help=False)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU (this is the grid dimension, to be cubed)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of autoencoder\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae_latent_dim\",\n",
    "        type=int,\n",
    "        default=512 * 8,\n",
    "        help=\"AE latent dimension\",\n",
    "    )\n",
    "    parser.add_argument(\"--ae_pth\", required=True, help=\"Autoencoder checkpoint\")\n",
    "\n",
    "    # CUDA parameters\n",
    "    parser.add_argument(\n",
    "        \"--device\", default=\"cuda\", help=\"device to use for training / testing\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_workers\", default=60, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--pin_mem\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.\",\n",
    "    )\n",
    "\n",
    "    # Datasplit parameters\n",
    "    parser.add_argument(\"--obj_dir\", type=str, help=\"Path to object directory\")\n",
    "    parser.add_argument(\n",
    "        \"--opt_point_ratio\",\n",
    "        type=int,\n",
    "        help=\"Ratio of points to sample from the object surface (2^N)\",\n",
    "        default=1,\n",
    "    )\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\n",
    "        \"--lr\",\n",
    "        type=float,\n",
    "        help=\"Learning rate\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_iter\",\n",
    "        type=int,\n",
    "        help=\"Maximum number of iterations for each stage\",\n",
    "    )\n",
    "\n",
    "    # Logging\n",
    "    parser.add_argument(\n",
    "        \"--log_dir\",\n",
    "        type=str,\n",
    "        help=\"Logging directory\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--config_name\",\n",
    "        type=str,\n",
    "        help=\"Name of the active configuration\",\n",
    "    )    \n",
    "    \n",
    "    # Distribution parameters\n",
    "    parser.add_argument(\"--process_id\", type=int, help=\"ID of the current process\")\n",
    "    parser.add_argument(\"--max_process\", type=int, help=\"Total number of processes\")\n",
    "\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "def initialize_latents(args, ae, root_names):\n",
    "    \"\"\"\n",
    "    Get the initial latents for the optimization.\n",
    "    Also load the points and occs for the input shapes.\n",
    "    \"\"\"\n",
    "    device = ae.device\n",
    "    \n",
    "    def load_batch(root_name, suffix):\n",
    "        \"\"\"\n",
    "        Load a batch of points and occs for a root name and suffix.\n",
    "        \"\"\"\n",
    "        stacked_data = []\n",
    "        for root_name in root_names:\n",
    "            path = os.path.join(args.obj_dir, root_name + suffix + \".npy\")\n",
    "            stacked_data += [np.load(path)]\n",
    "        return torch.tensor(np.array(stacked_data), device=device).squeeze(1)\n",
    "\n",
    "    # Make a batch from the points in CPU\n",
    "    points = load_batch(root_names, \"_surface_points\")\n",
    "    near_points = load_batch(root_names, \"_near_surface_points\")\n",
    "    occs = load_batch(root_names, \"_occs\")\n",
    "\n",
    "    # Encode the points\n",
    "    init_latents = s2vs.encode_pc(ae, points, fps_sampling=True).detach()\n",
    "\n",
    "    return init_latents, points, near_points, occs\n",
    "\n",
    "\n",
    "def get_metrics(ae, pc_original, latents, batch_size):\n",
    "    \"\"\"\n",
    "    Get the metrics for an input latent.\n",
    "    \"\"\"\n",
    "    rec_mesh = s2vs.decode_latents(\n",
    "        ae=ae,\n",
    "        latent=misc.d_GPU(latents),\n",
    "        grid_density=512,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    pc_rec = sample_surface_tpp(rec_mesh, pc_original.shape[0])\n",
    "    chamfer = chamfer_distance(pc_original, pc_rec, backend=\"kaolin\")\n",
    "    f_sc = f_score(gt=pc_original, pred=pc_rec)\n",
    "    return rec_mesh, chamfer, f_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set seed to 0\n",
      "Loading autoencoder [ckpt/ae_m512.pth].\n"
     ]
    }
   ],
   "source": [
    "# Set dummy arg string to debug the parser\n",
    "call_string = \"\"\"--ae_pth ckpt/ae_m512.pth \\\n",
    "    --ae kl_d512_m512_l8 \\\n",
    "    --ae_latent_dim 4096 \\\n",
    "    --batch_size 128 \\\n",
    "    --num_workers 8 \\\n",
    "    --device cuda\n",
    "    --obj_dir /ibex/project/c2273/3DCoMPaT/packaged \\\n",
    "    --process_id 0\n",
    "    --max_process 1\n",
    "    \"\"\"\n",
    "\n",
    "# Parse the arguments\n",
    "args = get_args_parser()\n",
    "args = args.parse_args(call_string.split())\n",
    "\n",
    "# Set device and seed\n",
    "device = torch.device(args.device)\n",
    "misc.set_all_seeds(args.seed)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Instantiate autoencoder\n",
    "ae = s2vs.load_model(args.ae, args.ae_pth, device, torch_compile=True)\n",
    "ae = ae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.metadata import class_to_hex\n",
    "def get_root_name(f, no_rot):\n",
    "    f = f.replace(\"_near_surface\", \"\")\n",
    "    f = f.replace(\"_surface\", \"\")\n",
    "    r = f.split(\"_\")[-1]\n",
    "    if no_rot:\n",
    "        if \"_all_aug_\" in f or \"_rand_rot_\" in f:\n",
    "            return None\n",
    "    return f.replace(\"_\" + r, \"\")\n",
    "\n",
    "\n",
    "def get_all_files(path, class_name=None, no_rot=False):\n",
    "    \"\"\"\n",
    "    List and filter augmented shapes from the input directory.\n",
    "    \"\"\"\n",
    "    root_names = os.listdir(path)\n",
    "    root_names = [get_root_name(f, no_rot=no_rot) for f in root_names]\n",
    "    root_names = [f for f in root_names if f is not None]\n",
    "\n",
    "    if class_name is not None:\n",
    "        class_hex = class_to_hex(class_name) + \"_\"\n",
    "        root_names = [f for f in root_names if f.startswith(class_hex)]\n",
    "\n",
    "    return root_names\n",
    "\n",
    "\n",
    "def batch_list(root_names, batch_size):\n",
    "    \"\"\"\n",
    "    Batch the root names.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        root_names[i : i + batch_size] for i in range(0, len(root_names), batch_size)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_latents(out_dir, root_batch, latents):\n",
    "    \"\"\"\n",
    "    Save the latents to a file.\n",
    "    \"\"\"\n",
    "    for i, root in enumerate(root_batch):\n",
    "        path = os.path.join(out_dir, root + \".npy\")\n",
    "        np.save(path, latents[i].cpu().numpy())\n",
    "        \n",
    "IN_PATH = \"/ibex/project/c2273/3DCoMPaT/packaged\"\n",
    "OUT_PATH = \"/ibex/project/c2273/3DCoMPaT/latents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set seed to 0\n",
      "Loading autoencoder [ckpt/ae_m512.pth].\n"
     ]
    }
   ],
   "source": [
    "# Set device and seed\n",
    "device = torch.device(args.device)\n",
    "misc.set_all_seeds(args.seed)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Instantiate autoencoder\n",
    "ae = s2vs.load_model(args.ae, args.ae_pth, device, torch_compile=True)\n",
    "ae = ae.eval()\n",
    "\n",
    "all_metrics = {}\n",
    "root_names = get_all_files(args.obj_dir)\n",
    "root_names = batch_list(root_names, args.batch_size)\n",
    "for root_batch in root_names:\n",
    "    # Initialize the latents, define the ground truth mesh\n",
    "    init_latents, points, near_points, occs = initialize_latents(args, ae, root_batch)\n",
    "    \n",
    "    # Save the initial latents\n",
    "    init_latents = init_latents.clone().detach()\n",
    "\n",
    "    #Â save_latents(OUT_PATH, root_batch, init_latents)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
