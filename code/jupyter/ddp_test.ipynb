{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibex/user/slimhy/PADS/code\n",
      "Set seed to 0\n",
      "Loading autoencoder ckpt/ae_m512.pth\n"
     ]
    }
   ],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code\n",
    "\"\"\"\n",
    "Extracting features into HDF5 files for each split.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "import util.misc as misc\n",
    "import models.s2vs as ae_mods\n",
    "\n",
    "\n",
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\"Extracting Features\", add_help=False)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=32,\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU\"\n",
    "        \" (effective batch size is batch_size * accum_iter * # gpus\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--text_model_name\",\n",
    "        type=str,\n",
    "        help=\"Text model name to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of autoencoder\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae-latent-dim\",\n",
    "        type=int,\n",
    "        default=512*8,\n",
    "        help=\"AE latent dimension\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae_pth\",\n",
    "        required=True,\n",
    "        help=\"Autoencoder checkpoint\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--point_cloud_size\",\n",
    "        default=2048,\n",
    "        type=int,\n",
    "        help=\"input size\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fetch_keys\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_embeds\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--intensity_loss\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Contrastive edit intensity loss using ground-truth labels.\",\n",
    "    )\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument(\n",
    "        \"--dataset\",\n",
    "        type=str,\n",
    "        choices=[\"graphedits\"],\n",
    "        help=\"dataset name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        type=str,\n",
    "        help=\"dataset path\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_type\",\n",
    "        type=str,\n",
    "        help=\"dataset type\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_edge_level\",\n",
    "        default=None,\n",
    "        type=int,\n",
    "        help=\"maximum edge level to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\", default=\"cuda\", help=\"device to use for training / testing\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_workers\", default=60, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--pin_mem\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Pin CPU memory in DataLoader for more efficient \"\n",
    "        \"(sometimes) transfer to GPU.\",\n",
    "    )\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "# Set dummy arg string to debug the parser\n",
    "call_string = \"\"\"--ae_pth ckpt/ae_m512.pth \\\n",
    "    --ae kl_d512_m512_l8 \\\n",
    "    --ae-latent-dim 4096 \\\n",
    "    --data_path /ibex/project/c2273/PADS/3DCoMPaT \\\n",
    "    --batch_size 32 \\\n",
    "    --num_workers 8 \\\n",
    "    --device cuda\"\"\"\n",
    "    \n",
    "\n",
    "# Parse the arguments\n",
    "args = get_args_parser()\n",
    "args = args.parse_args(call_string.split())\n",
    "\n",
    "# --------------------\n",
    "device = torch.device(args.device)\n",
    "\n",
    "# Fix the seed for reproducibility\n",
    "misc.set_all_seeds(args.seed)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# --------------------\n",
    "\n",
    "# Instantiate autoencoder\n",
    "ae = ae_mods.__dict__[args.ae]()\n",
    "ae.eval()\n",
    "print(\"Loading autoencoder %s\" % args.ae_pth)\n",
    "ae.load_state_dict(torch.load(args.ae_pth, map_location=\"cpu\")[\"model\"])\n",
    "ae = ae.to(device)\n",
    "\n",
    "# Compile using torch.compile\n",
    "ae = torch.compile(ae, mode=\"max-autotune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size :: 64 pair_types :: ['rand_no_rot,rand_no_rot', 'part_drop,orig'] num_workers :: 32 use_distributed :: True num_replicas :: 2 rank :: 0 seed :: 0 shuffle :: True pin_memory :: False drop_last :: True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slimhy/conda/envs/3D2VS_flexicubes/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from datasets.latents import ShapeLatentDataset, ComposedPairedShapesLoader\n",
    "\n",
    "class PairType():\n",
    "    NO_ROT_PAIR = \"rand_no_rot,rand_no_rot\"\n",
    "    PART_DROP = \"part_drop,orig\"\n",
    "\n",
    "# Create your datasets\n",
    "dataset_train = ShapeLatentDataset(args.data_path, split=\"train\", shuffle_parts=True)\n",
    "\n",
    "# batch_size :: 64\n",
    "# pair_types :: ['rand_no_rot,rand_no_rot', 'part_drop,orig']\n",
    "# num_workers :: 32\n",
    "# use_distributed :: True\n",
    "# num_replicas :: 2\n",
    "# rank :: 0 seed :: 0 shuffle :: True pin_memory :: False drop_last :: True\n",
    "\n",
    "\n",
    "# Create the DataLoader using the sampler\n",
    "ddp_loader_0 = ComposedPairedShapesLoader(\n",
    "    dataset_train,\n",
    "    batch_size=64,\n",
    "    pair_types_list=['rand_no_rot,rand_no_rot', 'part_drop,orig'],\n",
    "    num_workers=32,\n",
    "    use_distributed=True,\n",
    "    num_replicas=2,\n",
    "    rank=0,\n",
    "    seed=0,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ") \n",
    "ddp_loader_1 = ComposedPairedShapesLoader(\n",
    "    dataset_train,\n",
    "    batch_size=64,\n",
    "    pair_types_list=['rand_no_rot,rand_no_rot', 'part_drop,orig'],\n",
    "    num_workers=32,\n",
    "    use_distributed=True,\n",
    "    num_replicas=2,\n",
    "    rank=1,\n",
    "    seed=0,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ") \n",
    "seq_loader = ComposedPairedShapesLoader(\n",
    "    dataset_train,\n",
    "    batch_size=args.batch_size,\n",
    "    pair_types_list=[PairType.PART_DROP, PairType.NO_ROT_PAIR, PairType.PART_DROP],\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    use_distributed=False\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0c_06f_rand_no_rot_2 0c_06f_rand_no_rot_5\n",
      "18_122_rand_no_rot_4 18_122_rand_no_rot_6\n",
      "ayaaaa\n",
      "25_0e7_part_drop_6 25_0e7_orig_0\n"
     ]
    }
   ],
   "source": [
    "ddp_loader_0.set_epoch(10)\n",
    "ddp_loader_1.set_epoch(10)\n",
    "\n",
    "# Use the dataloader in your training loop\n",
    "for pair_types, (l_a, bb_a, bb_l_a, meta_a), (l_b, bb_b, bb_l_b, meta_b) in ddp_loader_0:\n",
    "    print(meta_a[0], meta_b[0])\n",
    "    break\n",
    "\n",
    "# Use the dataloader in your training loop\n",
    "for pair_types, (l_a, bb_a, bb_l_a, meta_a), (l_b, bb_b, bb_l_b, meta_b) in ddp_loader_1:\n",
    "    print(meta_a[0], meta_b[0])\n",
    "    break\n",
    "\n",
    "# Use the dataloader in your training loop\n",
    "for pair_types, (l_a, bb_a, bb_l_a, meta_a), (l_b, bb_b, bb_l_b, meta_b) in seq_loader:\n",
    "    print(meta_a[0], meta_b[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
