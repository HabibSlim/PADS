{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibex/user/slimhy/PADS/code\n",
      "Set seed to 0\n",
      "Loading autoencoder ckpt/ae_m512.pth\n"
     ]
    }
   ],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code\n",
    "\"\"\"\n",
    "Extracting features into HDF5 files for each split.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "import util.misc as misc\n",
    "import models.s2vs as ae_mods\n",
    "\n",
    "\n",
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\"Extracting Features\", add_help=False)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=32,\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU\"\n",
    "        \" (effective batch size is batch_size * accum_iter * # gpus\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--text_model_name\",\n",
    "        type=str,\n",
    "        help=\"Text model name to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of autoencoder\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae-latent-dim\",\n",
    "        type=int,\n",
    "        default=512*8,\n",
    "        help=\"AE latent dimension\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae_pth\",\n",
    "        required=True,\n",
    "        help=\"Autoencoder checkpoint\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--point_cloud_size\",\n",
    "        default=2048,\n",
    "        type=int,\n",
    "        help=\"input size\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fetch_keys\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_embeds\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--intensity_loss\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Contrastive edit intensity loss using ground-truth labels.\",\n",
    "    )\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument(\n",
    "        \"--dataset\",\n",
    "        type=str,\n",
    "        choices=[\"graphedits\"],\n",
    "        help=\"dataset name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        type=str,\n",
    "        help=\"dataset path\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_type\",\n",
    "        type=str,\n",
    "        help=\"dataset type\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_edge_level\",\n",
    "        default=None,\n",
    "        type=int,\n",
    "        help=\"maximum edge level to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\", default=\"cuda\", help=\"device to use for training / testing\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_workers\", default=60, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--pin_mem\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Pin CPU memory in DataLoader for more efficient \"\n",
    "        \"(sometimes) transfer to GPU.\",\n",
    "    )\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "# Set dummy arg string to debug the parser\n",
    "call_string = \"\"\"--ae_pth ckpt/ae_m512.pth \\\n",
    "    --ae kl_d512_m512_l8 \\\n",
    "    --ae-latent-dim 4096 \\\n",
    "    --data_path /ibex/project/c2273/PADS/3DCoMPaT \\\n",
    "    --batch_size 32 \\\n",
    "    --num_workers 8 \\\n",
    "    --device cuda\"\"\"\n",
    "    \n",
    "\n",
    "# Parse the arguments\n",
    "args = get_args_parser()\n",
    "args = args.parse_args(call_string.split())\n",
    "\n",
    "# --------------------\n",
    "device = torch.device(args.device)\n",
    "\n",
    "# Fix the seed for reproducibility\n",
    "misc.set_all_seeds(args.seed)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# --------------------\n",
    "\n",
    "# Instantiate autoencoder\n",
    "ae = ae_mods.__dict__[args.ae]()\n",
    "ae.eval()\n",
    "print(\"Loading autoencoder %s\" % args.ae_pth)\n",
    "ae.load_state_dict(torch.load(args.ae_pth, map_location=\"cpu\")[\"model\"])\n",
    "ae = ae.to(device)\n",
    "\n",
    "# Compile using torch.compile\n",
    "ae = torch.compile(ae, mode=\"max-autotune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.latents import ShapeLatentDataset, ComposedPairedShapesLoader\n",
    "\n",
    "class PairType():\n",
    "    NO_ROT_PAIR = \"rand_no_rot,rand_no_rot\"\n",
    "    PART_DROP = \"part_drop,orig\"\n",
    "\n",
    "# Create your datasets\n",
    "dataset_train = ShapeLatentDataset(args.data_path, split=\"train\", shuffle_parts=True)\n",
    "\n",
    "N_REPLICAS = 4\n",
    "\n",
    "all_loaders = []\n",
    "for rank in range(N_REPLICAS):\n",
    "    loader = ComposedPairedShapesLoader(\n",
    "        dataset_train,\n",
    "        batch_size=64,\n",
    "        pair_types_list=['rand_no_rot,rand_no_rot', 'part_drop,orig'],\n",
    "        num_workers=4,\n",
    "        use_distributed=True,\n",
    "        num_replicas=N_REPLICAS,\n",
    "        rank=rank,\n",
    "        seed=0,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    all_loaders.append(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0166f1749efb4844aed8cc4c3b14bbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slimhy/conda/envs/3D2VS_flexicubes/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "all_samples = []\n",
    "for epoch in tqdm(range(0, 10)):\n",
    "    for ddp_loader in all_loaders:\n",
    "        ddp_loader.set_epoch(epoch)\n",
    "        data_seen = False\n",
    "        data_count = 0\n",
    "        for pair_types, (l_a, bb_a, bb_l_a, meta_a), (l_b, bb_b, bb_l_b, meta_b) in ddp_loader:\n",
    "            data_count += 1\n",
    "            data_seen = True\n",
    "        assert data_seen, \"No data seen!\"\n",
    "        all_samples += [data_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader using the sampler\n",
    "# ddp_loader_0 = ComposedPairedShapesLoader(\n",
    "#     dataset_train,\n",
    "#     batch_size=64,\n",
    "#     pair_types_list=['rand_no_rot,rand_no_rot', 'part_drop,orig'],\n",
    "#     num_workers=4,\n",
    "#     use_distributed=True,\n",
    "#     num_replicas=2,\n",
    "#     rank=0,\n",
    "#     seed=0,\n",
    "#     shuffle=True,\n",
    "#     drop_last=True,\n",
    "# ) \n",
    "# ddp_loader_1 = ComposedPairedShapesLoader(\n",
    "#     dataset_train,\n",
    "#     batch_size=64,\n",
    "#     pair_types_list=['rand_no_rot,rand_no_rot', 'part_drop,orig'],\n",
    "#     num_workers=4,\n",
    "#     use_distributed=True,\n",
    "#     num_replicas=2,\n",
    "#     rank=1,\n",
    "#     seed=0,\n",
    "#     shuffle=True,\n",
    "#     drop_last=True,\n",
    "# ) \n",
    "# seq_loader = ComposedPairedShapesLoader(\n",
    "#     dataset_train,\n",
    "#     batch_size=64,\n",
    "#     pair_types_list=['rand_no_rot,rand_no_rot', 'part_drop,orig'],\n",
    "#     num_workers=4,\n",
    "#     shuffle=True,\n",
    "#     use_distributed=False,\n",
    "#     drop_last=True,\n",
    "# ) \n",
    "# for epoch in tqdm(range(0, 800)):\n",
    "#     ddp_loader_0.set_epoch(epoch)\n",
    "#     ddp_loader_1.set_epoch(epoch)\n",
    "# \n",
    "#     # Use the dataloader in your training loop\n",
    "#     seen_models_a = set()\n",
    "#     seen_batches_a = 0\n",
    "#     for pair_types, (l_a, bb_a, bb_l_a, meta_a), (l_b, bb_b, bb_l_b, meta_b) in ddp_loader_0:\n",
    "#         seen_batches_a += 1\n",
    "#         seen_models_a |= set(list(meta_a))\n",
    "#         seen_models_a |= set(list(meta_b))\n",
    "# \n",
    "#     # Use the dataloader in your training loop\n",
    "#     seen_models_b = set()\n",
    "#     seen_batches_b = 0\n",
    "#     for pair_types, (l_a, bb_a, bb_l_a, meta_a), (l_b, bb_b, bb_l_b, meta_b) in ddp_loader_1:\n",
    "#         seen_batches_b += 1\n",
    "#         seen_models_b |= set(list(meta_a))\n",
    "#         seen_models_b |= set(list(meta_b))\n",
    "# \n",
    "#     # Use the dataloader in your training loop\n",
    "#     seen_models_seq = set()\n",
    "#     seen_batches_seq = 0\n",
    "#     for pair_types, (l_a, bb_a, bb_l_a, meta_a), (l_b, bb_b, bb_l_b, meta_b) in seq_loader:\n",
    "#         seen_batches_seq += 1\n",
    "#         seen_models_seq |= set(list(meta_a))\n",
    "#         seen_models_seq |= set(list(meta_b))\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
