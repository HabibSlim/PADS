{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/sw/rl9g/cuda/12.2/rl9_binary'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class airplane\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extract points from the CoMPaT dataset with part bounding boxes and occupancy grids.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/ibex/user/slimhy/PADS/code\")\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets.shapeloaders import CoMPaTSegmentDataset\n",
    "from util.misc import dump_pickle\n",
    "from datasets.metadata import COMPAT_MATCHED_CLASSES\n",
    "\n",
    "\n",
    "N_POINTS_PER_SHAPE = 2**18\n",
    "OUT_PATH = \"/ibex/project/c2273/3DCoMPaT/packaged\"\n",
    "SAMPLES_PER_DATASET = 8\n",
    "PROCESSED_MODELS = set()\n",
    "SAMPLING_PARAMS = {\n",
    "    \"n_points\": N_POINTS_PER_SHAPE,\n",
    "    \"sampling_method\": \"surface+near_surface\",\n",
    "    \"near_surface_noise\": 0.01,\n",
    "}\n",
    "\n",
    "\n",
    "def get_datasets(active_class):\n",
    "    compat_dataset = CoMPaTSegmentDataset(\n",
    "        \"/ibex/project/c2273/3DCoMPaT/manifold_part_instances/\",\n",
    "        shape_cls=active_class,\n",
    "        recenter_mesh=True,\n",
    "        process_mesh=True,\n",
    "        scale_to_shapenet=True,\n",
    "        align_to_shapenet=True,\n",
    "        random_transform=False,\n",
    "        force_retransform=False,\n",
    "        remove_small_parts=False,\n",
    "        **SAMPLING_PARAMS,\n",
    "    )\n",
    "\n",
    "    compat_part_drop_dataset = CoMPaTSegmentDataset(\n",
    "        \"/ibex/project/c2273/3DCoMPaT/manifold_part_instances/\",\n",
    "        shape_cls=active_class,\n",
    "        recenter_mesh=True,\n",
    "        process_mesh=True,\n",
    "        scale_to_shapenet=True,\n",
    "        align_to_shapenet=True,\n",
    "        random_transform=False,\n",
    "        force_retransform=True,\n",
    "        random_part_drop=True,\n",
    "        n_parts_to_drop=1,\n",
    "        remove_small_parts=False,\n",
    "        **SAMPLING_PARAMS,\n",
    "    )\n",
    "\n",
    "    compat_random_aug_rotation_dataset = CoMPaTSegmentDataset(\n",
    "        \"/ibex/project/c2273/3DCoMPaT/manifold_part_instances/\",\n",
    "        shape_cls=active_class,\n",
    "        recenter_mesh=True,\n",
    "        process_mesh=True,\n",
    "        scale_to_shapenet=True,\n",
    "        align_to_shapenet=True,\n",
    "        random_transform=True,\n",
    "        force_retransform=True,\n",
    "        random_rotation=True,\n",
    "        **SAMPLING_PARAMS,\n",
    "    )\n",
    "\n",
    "    compat_random_aug_no_rotation_dataset = CoMPaTSegmentDataset(\n",
    "        \"/ibex/project/c2273/3DCoMPaT/manifold_part_instances/\",\n",
    "        shape_cls=active_class,\n",
    "        recenter_mesh=True,\n",
    "        process_mesh=True,\n",
    "        scale_to_shapenet=True,\n",
    "        align_to_shapenet=True,\n",
    "        random_transform=True,\n",
    "        force_retransform=True,\n",
    "        random_rotation=False,\n",
    "        **SAMPLING_PARAMS,\n",
    "    )\n",
    "\n",
    "    compat_random_all_aug_dataset = CoMPaTSegmentDataset(\n",
    "        \"/ibex/project/c2273/3DCoMPaT/manifold_part_instances/\",\n",
    "        shape_cls=active_class,\n",
    "        recenter_mesh=True,\n",
    "        process_mesh=True,\n",
    "        scale_to_shapenet=True,\n",
    "        align_to_shapenet=True,\n",
    "        random_transform=True,\n",
    "        force_retransform=True,\n",
    "        random_rotation=True,\n",
    "        random_part_drop=True,\n",
    "        n_parts_to_drop=1,\n",
    "        **SAMPLING_PARAMS,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"orig\": compat_dataset,\n",
    "        \"part_drop\": compat_part_drop_dataset,\n",
    "        \"rand_rot\": compat_random_aug_rotation_dataset,\n",
    "        \"rand_no_rot\": compat_random_aug_no_rotation_dataset,\n",
    "        \"all_aug\": compat_random_all_aug_dataset,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_points(dataset, obj_k=0):\n",
    "    surface_points, occs, bbs = next(dataset[obj_k])\n",
    "    return surface_points, occs, bbs\n",
    "\n",
    "\n",
    "def initialize_processed_models(out_path):\n",
    "    \"\"\"\n",
    "    Initialize the set of processed model IDs.\n",
    "    \"\"\"\n",
    "    global PROCESSED_MODELS\n",
    "    all_files = os.listdir(out_path)\n",
    "    PROCESSED_MODELS = set(filename[:6] for filename in all_files)\n",
    "\n",
    "\n",
    "def is_model_processed(model_id):\n",
    "    \"\"\"\n",
    "    Check if the given model_id exists in the set of processed models.\n",
    "    \"\"\"\n",
    "    global PROCESSED_MODELS\n",
    "    return model_id in PROCESSED_MODELS\n",
    "\n",
    "\n",
    "def export_dataset_entry(datasets, obj_k, out_path):\n",
    "    global PROCESSED_MODELS\n",
    "    model_id = datasets[\"orig\"].get_model_id(obj_k)\n",
    "\n",
    "    # Check if the model has already been processed\n",
    "    if is_model_processed(model_id):\n",
    "        print(f\"Skipping model {model_id} as it has already been processed\")\n",
    "        return\n",
    "\n",
    "    for aug_id, dataset in datasets.items():\n",
    "        for sample_id in range(SAMPLES_PER_DATASET):\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            all_points, occs, bbs = get_points(dataset, obj_k=obj_k)\n",
    "            surface_points, near_surface_points = (\n",
    "                all_points[0],\n",
    "                all_points[1],\n",
    "            )\n",
    "            assert (\n",
    "                torch.sum(occs[: N_POINTS_PER_SHAPE // 2].flatten())\n",
    "                == N_POINTS_PER_SHAPE // 2\n",
    "            )\n",
    "\n",
    "            occs = occs[N_POINTS_PER_SHAPE // 2 :]\n",
    "            sample_code = f\"{model_id}_{aug_id}_{sample_id}\"\n",
    "            \n",
    "            # Store the points\n",
    "            np.save(\n",
    "                f\"{out_path}/{sample_code}_surface_points\", surface_points.cpu().numpy()\n",
    "            )\n",
    "            np.save(\n",
    "                f\"{out_path}/{sample_code}_near_surface_points\",\n",
    "                near_surface_points.cpu().numpy(),\n",
    "            )\n",
    "\n",
    "            # Store the occupancy grid\n",
    "            np.save(f\"{out_path}/{sample_code}_occs\", occs.cpu().numpy())\n",
    "\n",
    "            # Store the transformation matrix\n",
    "            np.save(f\"{out_path}/{sample_code}_transformation\", dataset.transform_mat)\n",
    "\n",
    "            # Store the bounding boxes\n",
    "            dump_pickle(bbs, f\"{out_path}/{sample_code}_bbs.pkl\")\n",
    "\n",
    "            if aug_id == \"orig\":\n",
    "                break\n",
    "\n",
    "    # Add the processed model to the set\n",
    "    PROCESSED_MODELS.add(model_id)\n",
    "    print(f\"Processed model {model_id}\")\n",
    "\n",
    "\n",
    "def main(process_id, max_process):\n",
    "    for active_class in COMPAT_MATCHED_CLASSES:\n",
    "        print(f\"Processing class {active_class}\")\n",
    "\n",
    "        # Get all datasets\n",
    "        all_datasets = get_datasets(active_class)\n",
    "        return all_datasets\n",
    "        \n",
    "        # Get the number of objects in the dataset\n",
    "        num_objects = len(all_datasets[\"orig\"])\n",
    "\n",
    "        # Determine the number of processes to use for this class\n",
    "        processes_for_class = min(max_process, num_objects)\n",
    "\n",
    "        # If the current process_id is greater than or equal to the number of objects,\n",
    "        # this process doesn't need to do anything for this class\n",
    "        if process_id >= processes_for_class:\n",
    "            print(f\"Process {process_id} skipping class {active_class}\")\n",
    "            continue\n",
    "\n",
    "        # Calculate the slice for this process\n",
    "        base_slice_size = num_objects // processes_for_class\n",
    "        remainder = num_objects % processes_for_class\n",
    "\n",
    "        # Distribute the remainder among the first 'remainder' processes\n",
    "        start_idx = process_id * base_slice_size + min(process_id, remainder)\n",
    "        end_idx = start_idx + base_slice_size + (1 if process_id < remainder else 0)\n",
    "\n",
    "        to_process = range(start_idx, end_idx)\n",
    "\n",
    "        print(f\"Process {process_id} processing range: {to_process}\")\n",
    "\n",
    "        # Iterate over all objects in all datasets jointly\n",
    "        for k in to_process:\n",
    "            export_dataset_entry(all_datasets, k, OUT_PATH)\n",
    "            print(f\"Processed object {k + 1}/{num_objects}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the set of processed models\n",
    "    initialize_processed_models(OUT_PATH)\n",
    "\n",
    "    all_datasets = main(0, 1)\n",
    "\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function combine_samplings at 0x154449901750>, sampling_fns=[<function sample_surface_simple at 0x154449901630>, functools.partial(<function sample_near_surface at 0x1544499016c0>, noise_std=0.01, contain_method='occnets')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_datasets['orig'].sampling_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7968"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "global PROCESSED_MODELS\n",
    "all_files = os.listdir(\"/ibex/project/c2273/3DCoMPaT/packaged/\")\n",
    "PROCESSED_MODELS = set(filename[:6] for filename in all_files)\n",
    "\n",
    "len(PROCESSED_MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260254"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([f for f in all_files if \"_near_surface_points\" in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.471809895833333"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_count = 260254\n",
    "batch_size = 128\n",
    "batch_process_time = 120\n",
    "n_gpus = 8\n",
    "\n",
    "\n",
    "total_time = shape_count * batch_process_time / batch_size / n_gpus / 3600\n",
    "\n",
    "total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
