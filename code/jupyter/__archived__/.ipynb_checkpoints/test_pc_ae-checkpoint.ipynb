{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jitting Chamfer 3D\n",
      "Loaded JIT 3D CUDA chamfer distance\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import pprint\n",
    "import warnings\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from models.mlp import MLP\n",
    "from models.point_net import PointNet\n",
    "from models.pointcloud_autoencoder import PointcloudAutoencoder\n",
    "\n",
    "\n",
    "def describe_pc_ae(args):\n",
    "    # Make an AE.\n",
    "    if args.encoder_net == \"pointnet\":\n",
    "        ae_encoder = PointNet(init_feat_dim=3, conv_dims=args.encoder_conv_layers)\n",
    "        encoder_latent_dim = args.encoder_conv_layers[-1]\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    if args.decoder_net == \"mlp\":\n",
    "        ae_decoder = MLP(\n",
    "            in_feat_dims=encoder_latent_dim,\n",
    "            out_channels=args.decoder_fc_neurons + [args.n_pc_points * 3],\n",
    "            b_norm=False,\n",
    "        )\n",
    "\n",
    "    model = PointcloudAutoencoder(ae_encoder, ae_decoder)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_state_dicts(checkpoint_file, map_location=None, **kwargs):\n",
    "    \"\"\" Load torch items from saved state_dictionaries\"\"\"\n",
    "    if map_location is None:\n",
    "        checkpoint = torch.load(checkpoint_file)\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint_file, map_location=map_location)\n",
    "\n",
    "    for key, value in kwargs.items():\n",
    "        value.load_state_dict(checkpoint[key])\n",
    "\n",
    "    epoch = checkpoint.get('epoch')\n",
    "    if epoch:\n",
    "        return epoch\n",
    "\n",
    "\n",
    "def read_saved_args(config_file, override_or_add_args=None, verbose=False):\n",
    "    \"\"\"\n",
    "    :param config_file: json file containing arguments\n",
    "    :param override_args: dict e.g., {'gpu': '0'} will set the resulting arg.gpu to be 0\n",
    "    :param verbose:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    parser = ArgumentParser()\n",
    "    args = parser.parse_args([])\n",
    "    with open(config_file, \"r\") as f_in:\n",
    "        args.__dict__ = json.load(f_in)\n",
    "\n",
    "    if override_or_add_args is not None:\n",
    "        for key, val in override_or_add_args.items():\n",
    "            args.__setattr__(key, val)\n",
    "\n",
    "    if verbose:\n",
    "        args_string = pprint.pformat(vars(args))\n",
    "        print(args_string)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def load_pretrained_pc_ae(model_file):\n",
    "    config_file = osp.join(osp.dirname(model_file), \"config.json.txt\")\n",
    "    pc_ae_args = read_saved_args(config_file)\n",
    "    pc_ae = describe_pc_ae(pc_ae_args)\n",
    "\n",
    "    if osp.join(pc_ae_args.log_dir, \"best_model.pt\") != osp.abspath(model_file):\n",
    "        warnings.warn(\n",
    "            \"The saved best_model.pt in the corresponding log_dir is not equal to the one requested.\"\n",
    "        )\n",
    "\n",
    "    best_epoch = load_state_dicts(model_file, model=pc_ae)\n",
    "    print(f\"Pretrained PC-AE is loaded at epoch {best_epoch}.\")\n",
    "    return pc_ae, pc_ae_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained PC-AE is loaded at epoch 186.\n"
     ]
    }
   ],
   "source": [
    "pretrained_shape_generator = '/home/slimhy/Documents/changeit3d/data/pretrained/pc_autoencoders/pointnet/rs_2022/points_4096/all_classes/scaled_to_align_rendering/08-07-2022-22-23-42/best_model.pt'\n",
    "gpu_id = 0\n",
    "\n",
    "device = torch.device(\"cuda:\" + str(gpu_id))\n",
    "pc_ae, pc_ae_args = load_pretrained_pc_ae(pretrained_shape_generator)\n",
    "pc_ae = pc_ae.to(device)\n",
    "pc_ae = pc_ae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "pc_dir = \"/home/slimhy/Documents/datasets/ShapeWalk_RND/release/pc/\"\n",
    "pc_files = glob.glob(os.path.join(pc_dir, \"*.npy\"))\n",
    "\n",
    "# Sample 16 pointclouds\n",
    "pc_files = np.random.choice(pc_files, 16)\n",
    "\n",
    "# Load them into a tensor of size 16 x N x 3\n",
    "pc_batch = torch.stack([torch.from_numpy(np.load(f)) for f in pc_files], dim=0).float().to(device)\n",
    "\n",
    "# Sample 16 x 4096 x 3 from 16 x N x 3\n",
    "pc_batch = pc_batch[:, :4096, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the batch\n",
    "rec, _, avg_cd = pc_ae.reconstruct(loader=[{\"pointcloud\": pc_batch}], device=device, loss_rule='chamfer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
