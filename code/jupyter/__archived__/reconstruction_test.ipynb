{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import trimesh\n",
    "import k3d\n",
    "\n",
    "import util.misc as misc\n",
    "import models.s2vs as ae_mods\n",
    "from datasets.latents import ShapeLatentDataset, ComposedPairedShapesLoader\n",
    "from models.partvae import PartAwareVAE\n",
    "from util import s2vs\n",
    "\n",
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\"Autoencoder Visualization\", add_help=False)\n",
    "    parser.add_argument(\"--ae_pth\", required=True, help=\"Autoencoder checkpoint\")\n",
    "    parser.add_argument(\"--ae\", type=str, default=\"kl_d512_m512_l8\", help=\"Name of autoencoder\")\n",
    "    parser.add_argument(\"--ae-latent-dim\", type=int, default=4096, help=\"AE latent dimension\")\n",
    "    parser.add_argument(\"--batch_size\", default=32, type=int, help=\"Batch size\")\n",
    "    parser.add_argument(\"--num_workers\", default=8, type=int, help=\"Number of workers for data loading\")\n",
    "    parser.add_argument(\"--device\", default=\"cuda\", help=\"Device to use for computation\")\n",
    "    parser.add_argument(\"--seed\", default=0, type=int, help=\"Random seed\")\n",
    "    parser.add_argument(\"--pin_mem\", action=\"store_true\", help=\"Pin CPU memory in DataLoader\")\n",
    "    return parser\n",
    "\n",
    "def obb_to_corners(box_array):\n",
    "    center, right, up, forward = [np.array(box_array[i]) for i in range(4)]\n",
    "    corners = np.array([\n",
    "        [-1, -1, -1], [ 1, -1, -1], [ 1,  1, -1], [-1,  1, -1],\n",
    "        [-1, -1,  1], [ 1, -1,  1], [ 1,  1,  1], [-1,  1,  1]\n",
    "    ])\n",
    "    transform = np.column_stack((right, up, forward))\n",
    "    return np.dot(corners, transform.T) + center\n",
    "\n",
    "def create_trimesh_boxes(bounding_boxes):\n",
    "    return [\n",
    "        trimesh.util.concatenate([\n",
    "            trimesh.primitives.Sphere(radius=0.01).apply_translation(corner)\n",
    "            for corner in obb_to_corners(box)\n",
    "        ])\n",
    "        for box in bounding_boxes if not np.all(box == 0)\n",
    "    ]\n",
    "\n",
    "def load_checkpoint(model, checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    return model\n",
    "\n",
    "def visualize_decoded_mesh(decoded_mesh, bounding_boxes):\n",
    "    trimesh_boxes = create_trimesh_boxes(bounding_boxes)\n",
    "    col_map = k3d.helpers.map_colors(np.arange(len(trimesh_boxes)), k3d.colormaps.basic_color_maps.Rainbow)\n",
    "    \n",
    "    plot = k3d.plot()\n",
    "    plot += k3d.mesh(decoded_mesh.vertices, decoded_mesh.faces, color=0x0000ff, opacity=0.5)\n",
    "    for k, bb_mesh in enumerate(trimesh_boxes):\n",
    "        plot += k3d.mesh(bb_mesh.vertices, bb_mesh.faces, color=int(col_map[k]), opacity=0.5)\n",
    "    return plot\n",
    "\n",
    "# Set dummy arg string to debug the parser\n",
    "call_string = \"\"\"--ae_pth ckpt/ae_m512.pth \\\n",
    "    --ae kl_d512_m512_l8 \\\n",
    "    --ae-latent-dim 4096 \\\n",
    "    --batch_size 32 \\\n",
    "    --num_workers 8 \\\n",
    "    --device cuda \\\n",
    "    --seed 0 \\\n",
    "    --pin_mem\"\"\"\n",
    "\n",
    "args = get_args_parser().parse_args(call_string.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(args.device)\n",
    "misc.set_all_seeds(args.seed)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Initialize and load autoencoder\n",
    "ae = ae_mods.__dict__[args.ae]()\n",
    "ae.load_state_dict(torch.load(args.ae_pth, map_location=\"cpu\")[\"model\"])\n",
    "ae = torch.compile(ae.eval().to(device), mode=\"max-autotune\")\n",
    "\n",
    "# Initialize PartAwareVAE\n",
    "model = PartAwareVAE(\n",
    "    dim=512,\n",
    "    latent_dim=128, # Replace with args.part_latents_dim if available\n",
    "    heads=8,\n",
    "    dim_head=64,\n",
    "    depth=12, # Replace with args.layer_depth if available\n",
    ").to(device)\n",
    "model = load_checkpoint(\n",
    "    model,\n",
    "    '/ibex/user/slimhy/PADS/output/partvae/partvae_partvae__kl_1e5__rec_08__inv_02__schedulefree/checkpoint-50.pth'\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset_val = ShapeLatentDataset(\n",
    "    \"/ibex/project/c2273/PADS/3DCoMPaT/\",\n",
    "    split=\"test\",\n",
    "    shuffle_parts=False\n",
    ")\n",
    "pair_types = ['part_drop,orig']\n",
    "data_loader_val = ComposedPairedShapesLoader(\n",
    "    dataset_val,\n",
    "    batch_size=args.batch_size,\n",
    "    pair_types_list=pair_types,\n",
    "    num_workers=args.num_workers,\n",
    "    seed=args.seed,\n",
    "    shuffle=False,\n",
    "    pin_memory=args.pin_mem,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "# Get a single sample\n",
    "for data_tuple in data_loader_val:\n",
    "    pair_types, (l_a, bb_a, bb_l_a, _), _ = data_tuple\n",
    "    break\n",
    "\n",
    "# Process the sample\n",
    "l_a, bb_a, bb_l_a = l_a.to(device), bb_a.to(device), bb_l_a.to(device)\n",
    "mask_a = (bb_l_a != -1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_k = 5\n",
    "\n",
    "# Decode using the autoencoder\n",
    "with torch.no_grad():\n",
    "    if hasattr(model, 'is_vae') and model.is_vae:\n",
    "        logits_a, kl_a, part_latents_a = model(\n",
    "            latents=l_a, part_bbs=bb_a, part_labels=bb_l_a, batch_mask=mask_a)\n",
    "    else:\n",
    "        logits_a, part_latents_a = model(\n",
    "            latents=l_a, part_bbs=bb_a, part_labels=bb_l_a, batch_mask=mask_a)\n",
    "    logits_in = logits_a[obj_k].unsqueeze(0)\n",
    "    mesh = s2vs.decode_latents(ae, logits_in, grid_density=256, batch_size=64**3)\n",
    "\n",
    "print(\"Input latents shape:\", l_a.shape)\n",
    "print(\"Decoded latents shape:\", logits_a.shape)\n",
    "print(\"Part latents shape:\", part_latents_a.shape)\n",
    "\n",
    "# Visualize the decoded mesh with bounding boxes\n",
    "bounding_boxes = np.array(bb_a[obj_k].cpu())\n",
    "mesh = s2vs.decode_latents(ae, logits_in, grid_density=256, batch_size=64**3)\n",
    "plot = visualize_decoded_mesh(mesh.trimesh_mesh, bounding_boxes)\n",
    "plot.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
