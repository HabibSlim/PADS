{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code/\n",
    "\"\"\"\n",
    "Extracting features into HDF5 files for each split.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import torch\n",
    "import trimesh\n",
    "\n",
    "import util.misc as misc\n",
    "import util.s2vs as s2vs\n",
    "\n",
    "from datasets.shapeloaders import CoMPaTManifoldDataset, ShapeNetDataset\n",
    "from datasets.metadata import SHAPENET_NAME_TO_SYNSET, SHAPENET_NAME_TO_SYNSET_INDEX\n",
    "from util.misc import d_GPU, show_side_by_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\"Extracting Features\", add_help=False)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=32,\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--text_model_name\",\n",
    "        type=str,\n",
    "        help=\"Text model name to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of autoencoder\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae-latent-dim\",\n",
    "        type=int,\n",
    "        default=512*8,\n",
    "        help=\"AE latent dimension\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae_pth\",\n",
    "        required=True,\n",
    "        help=\"Autoencoder checkpoint\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--point_cloud_size\",\n",
    "        default=2048,\n",
    "        type=int,\n",
    "        help=\"input size\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fetch_keys\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_embeds\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--intensity_loss\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Contrastive edit intensity loss using ground-truth labels.\",\n",
    "    )\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument(\n",
    "        \"--dataset\",\n",
    "        type=str,\n",
    "        choices=[\"graphedits\"],\n",
    "        help=\"dataset name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        type=str,\n",
    "        help=\"dataset path\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_type\",\n",
    "        type=str,\n",
    "        help=\"dataset type\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_edge_level\",\n",
    "        default=None,\n",
    "        type=int,\n",
    "        help=\"maximum edge level to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\", default=\"cuda\", help=\"device to use for training / testing\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_workers\", default=60, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--pin_mem\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.\",\n",
    "    )\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dummy arg string to debug the parser\n",
    "call_string = \"\"\"--ae_pth ckpt/ae_m512.pth \\\n",
    "    --ae kl_d512_m512_l8 \\\n",
    "    --ae-latent-dim 4096 \\\n",
    "    --batch_size 32 \\\n",
    "    --num_workers 8 \\\n",
    "    --device cuda\"\"\"\n",
    "    \n",
    "\n",
    "# Parse the arguments\n",
    "args = get_args_parser()\n",
    "args = args.parse_args(call_string.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device and seed\n",
    "device = torch.device(args.device)\n",
    "misc.set_all_seeds(args.seed)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Instantiate autoencoder\n",
    "ae = s2vs.load_model(args.ae, args.ae_pth, device, torch_compile=True)\n",
    "ae = ae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVE_CLASS = \"lamp\"\n",
    "N_POINTS = 2**21\n",
    "MAX_POINTS = 2**21 # Maximum number of points for a single batch on a A100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from datasets.metadata import (\n",
    "    get_compat_transform,\n",
    "    get_shapenet_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJ_DIR = \"/ibex/project/c2273/ShapeNet/\"\n",
    "OBJ_ID = 7\n",
    "\n",
    "# Initialize the latents\n",
    "orig_dataset = ShapeNetDataset(\n",
    "    dataset_folder=OBJ_DIR,\n",
    "    shape_cls=SHAPENET_NAME_TO_SYNSET[ACTIVE_CLASS],\n",
    "    pc_size=ae.num_inputs,\n",
    "    replica=1,\n",
    ")\n",
    "surface_points, _ = orig_dataset[OBJ_ID]\n",
    "surface_points = surface_points.to(device)\n",
    "init_latents = s2vs.encode_pc(ae, surface_points).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJ_DIR = \"/ibex/user/slimhy/PADS/data/obj_manifold/\"\n",
    "\n",
    "def flip_front_to_right(pc):\n",
    "    \"\"\"\n",
    "    Rotate 90Â° around Y axis (from front-facing to right-facing).\n",
    "    \"\"\"\n",
    "    full_transform = torch.tensor(\n",
    "        [[0.0, 0.0, -1.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0]],\n",
    "        dtype=torch.float32,\n",
    "        device=pc.device,\n",
    "    )\n",
    "    return torch.matmul(pc.squeeze(), full_transform).unsqueeze(0)\n",
    "\n",
    "# Initialize the latents\n",
    "alt_dataset = CoMPaTManifoldDataset(\n",
    "    OBJ_DIR,\n",
    "    ACTIVE_CLASS,\n",
    "    ae.num_inputs,\n",
    "    normalize=False,\n",
    "    sampling_method=\"surface\",\n",
    "    scale_to_shapenet=False,\n",
    ")\n",
    "surface_points_alt, _ = next(alt_dataset[OBJ_ID])\n",
    "surface_points_alt = get_compat_transform(ACTIVE_CLASS)(surface_points_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_mesh(mesh):\n",
    "    \"\"\"\n",
    "    Center the mesh.\n",
    "    \"\"\"\n",
    "    mesh.vertices -= mesh.centroid\n",
    "    return mesh\n",
    "    \n",
    "# Load shape\n",
    "def get_gen(class_name):\n",
    "    class_id = SHAPENET_NAME_TO_SYNSET_INDEX[class_name]\n",
    "    shape_path = \"/ibex/user/slimhy/3DShape2VecSet/class_cond_obj/kl_d512_m512_l8_d24_edm/\"\n",
    "    return center_mesh(trimesh.load(shape_path + \"%02d-00000.obj\" % class_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_latents = s2vs.encode_pc(ae, surface_points)\n",
    "surface_points = surface_points.to(device)\n",
    "surface_points_alt = get_shapenet_transform(ACTIVE_CLASS)(surface_points_alt)\n",
    "rec_mesh = s2vs.decode_latents(ae, d_GPU(init_latents), grid_density=256, batch_size=128**3)\n",
    "\n",
    "# Decode the optimized latents\n",
    "if surface_points_alt is not None:\n",
    "    init_latents = s2vs.encode_pc(ae, surface_points_alt)\n",
    "    rec_mesh_compat = s2vs.decode_latents(ae, d_GPU(init_latents), grid_density=256, batch_size=128**3)\n",
    "else:\n",
    "    rec_mesh_compat = trimesh.Trimesh(vertices=[], faces=[])\n",
    "\n",
    "shapenet_gen = get_gen(ACTIVE_CLASS)\n",
    "show_side_by_side(rec_mesh, shapenet_gen, rec_mesh_compat, flip_front_to_back=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stuff(surface_points):\n",
    "    # Get pc bounding box following each axis\n",
    "    min_x = surface_points[:, :, 0].min()\n",
    "    max_x = surface_points[:, :, 0].max()\n",
    "    min_y = surface_points[:, :, 1].min()\n",
    "    max_y = surface_points[:, :, 1].max()\n",
    "    min_z = surface_points[:, :, 2].min()\n",
    "    max_z = surface_points[:, :, 2].max()\n",
    "\n",
    "    print(min_x.item(), max_x.item())\n",
    "    print(min_y.item(), max_y.item())\n",
    "    print(min_z.item(), max_z.item())\n",
    "\n",
    "    # Compute extents\n",
    "    extents = [d.item() for d in [max_x - min_x, max_y - min_y, max_z - min_z]]\n",
    "    print(extents)\n",
    "\n",
    "\n",
    "get_stuff(surface_points_alt)\n",
    "print()\n",
    "get_stuff(surface_points)\n",
    "print()\n",
    "# sample from shapenet_gen, add extra dim 0\n",
    "sampled_points = np.array(shapenet_gen.sample(N_POINTS))[np.newaxis, :, :]\n",
    "get_stuff(sampled_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /ibex/user/slimhy/3DShape2VecSet/\n",
    "# ! python sample_class_cond.py \\\n",
    "#     --ae kl_d512_m512_l8 \\\n",
    "#     --ae-pth output/ae/kl_d512_m512_l8/checkpoint-199.pth \\\n",
    "#     --dm kl_d512_m512_l8_d24_edm \\\n",
    "#     --dm-pth output/class_cond_dm/kl_d512_m512_l8_d24_edm/checkpoint-499.pth\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
