{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code/\n",
    "\"\"\"\n",
    "Invert a set of input shapes.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import torch\n",
    "import trimesh\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import util.misc as misc\n",
    "import util.s2vs as s2vs\n",
    "\n",
    "from datasets.sampling import sample_surface_tpp\n",
    "from eval.metrics import chamfer_distance, f_score\n",
    "\n",
    "\n",
    "def get_args_parser():\n",
    "    \"\"\"\n",
    "    Parsing input arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\"Extracting Latents\", add_help=False)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU (this is the grid dimension, to be cubed)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of autoencoder\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae_latent_dim\",\n",
    "        type=int,\n",
    "        default=512 * 8,\n",
    "        help=\"AE latent dimension\",\n",
    "    )\n",
    "    parser.add_argument(\"--ae_pth\", required=True, help=\"Autoencoder checkpoint\")\n",
    "\n",
    "    # CUDA parameters\n",
    "    parser.add_argument(\n",
    "        \"--device\", default=\"cuda\", help=\"device to use for training / testing\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_workers\", default=60, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--pin_mem\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.\",\n",
    "    )\n",
    "\n",
    "    # Datasplit parameters\n",
    "    parser.add_argument(\"--obj_dir\", type=str, help=\"Path to object directory\")\n",
    "    parser.add_argument(\n",
    "        \"--opt_point_ratio\",\n",
    "        type=int,\n",
    "        help=\"Ratio of points to sample from the object surface (2^N)\",\n",
    "        default=1,\n",
    "    )\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\n",
    "        \"--lr\",\n",
    "        type=float,\n",
    "        help=\"Learning rate\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_iter\",\n",
    "        type=int,\n",
    "        help=\"Maximum number of iterations for each stage\",\n",
    "    )\n",
    "\n",
    "    # Logging\n",
    "    parser.add_argument(\n",
    "        \"--log_dir\",\n",
    "        type=str,\n",
    "        help=\"Logging directory\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--config_name\",\n",
    "        type=str,\n",
    "        help=\"Name of the active configuration\",\n",
    "    )\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "def initialize_latents(args, ae, root_names):\n",
    "    \"\"\"\n",
    "    Get the initial latents for the optimization.\n",
    "    Also load the points and occs for the input shapes.\n",
    "    \"\"\"\n",
    "    device = ae.device\n",
    "    \n",
    "    def load_batch(root_name, suffix):\n",
    "        \"\"\"\n",
    "        Load a batch of points and occs for a root name and suffix.\n",
    "        \"\"\"\n",
    "        stacked_data = []\n",
    "        for root_name in root_names:\n",
    "            path = os.path.join(args.obj_dir, root_name + suffix + \".npy\")\n",
    "            stacked_data += [np.load(path)]\n",
    "        return torch.tensor(np.array(stacked_data), device=device).squeeze(1)\n",
    "\n",
    "    # Make a batch from the points in CPU\n",
    "    points = load_batch(root_names, \"_surface_points\")\n",
    "    near_points = load_batch(root_names, \"_near_surface_points\")\n",
    "    occs = load_batch(root_names, \"_occs\")\n",
    "\n",
    "    # Encode the points\n",
    "    init_latents = s2vs.encode_pc(ae, points, fps_sampling=True).detach()\n",
    "\n",
    "    return init_latents, points, near_points, occs\n",
    "\n",
    "\n",
    "def get_metrics(ae, pc_original, latents, batch_size):\n",
    "    \"\"\"\n",
    "    Get the metrics for an input latent.\n",
    "    \"\"\"\n",
    "    rec_mesh = s2vs.decode_latents(\n",
    "        ae=ae,\n",
    "        latent=misc.d_GPU(latents),\n",
    "        grid_density=512,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    pc_rec = sample_surface_tpp(rec_mesh, pc_original.shape[0])\n",
    "    chamfer = chamfer_distance(pc_original, pc_rec, backend=\"kaolin\")\n",
    "    f_sc = f_score(gt=pc_original, pred=pc_rec)\n",
    "    return rec_mesh, chamfer, f_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dummy arg string to debug the parser\n",
    "call_string = \"\"\"--ae_pth ckpt/ae_m512.pth \\\n",
    "    --ae kl_d512_m512_l8 \\\n",
    "    --ae_latent_dim 4096 \\\n",
    "    --batch_size 16 \\\n",
    "    --num_workers 8 \\\n",
    "    --device cuda\n",
    "    --obj_dir /ibex/project/c2273/3DCoMPaT/packaged \\\n",
    "    --lr 1e-2 \\\n",
    "    --max_iter 100\n",
    "    \"\"\"\n",
    "\n",
    "# Parse the arguments\n",
    "args = get_args_parser()\n",
    "args = args.parse_args(call_string.split())\n",
    "\n",
    "# Set device and seed\n",
    "device = torch.device(args.device)\n",
    "misc.set_all_seeds(args.seed)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Instantiate autoencoder\n",
    "ae = s2vs.load_model(args.ae, args.ae_pth, device, torch_compile=True)\n",
    "ae = ae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.metadata import class_to_hex\n",
    "\n",
    "\n",
    "def get_root_name(f, no_rot):\n",
    "    \"\"\"\n",
    "    Get the root name of a file.\n",
    "    \"\"\"\n",
    "    f = f.replace(\"_near_surface\", \"\")\n",
    "    f = f.replace(\"_surface\", \"\")\n",
    "    r = f.split(\"_\")[-1]\n",
    "    if no_rot:\n",
    "        if \"_all_aug_\" in f or \"_rand_rot_\" in f:\n",
    "            return None\n",
    "    return f.replace(\"_\" + r, \"\")\n",
    "\n",
    "\n",
    "def get_all_files(path, class_name=None, no_rot=False):\n",
    "    \"\"\"\n",
    "    List and filter augmented shapes from the input directory.\n",
    "    \"\"\"\n",
    "    root_names = os.listdir(path)\n",
    "    root_names = [get_root_name(f, no_rot=no_rot) for f in root_names]\n",
    "    root_names = [f for f in root_names if f is not None]\n",
    "    \n",
    "    if class_name is not None:\n",
    "        class_hex = class_to_hex(class_name) + \"_\"\n",
    "        root_names = [f for f in root_names if f.startswith(class_hex)]\n",
    "\n",
    "    # Batch the root names\n",
    "    return [root_names[i : i + args.batch_size] for i in range(0, len(root_names), args.batch_size)]\n",
    "\n",
    "\n",
    "def show_orig_mesh(root_name):\n",
    "    \"\"\"\n",
    "    Show the original mesh.\n",
    "    \"\"\"\n",
    "    from datasets.metadata import flip_front_to_back\n",
    "    flip_transform_4x4 = np.eye(4)\n",
    "    flip_transform_4x4[:3, :3] = flip_front_to_back\n",
    "    path = os.path.join(\"/ibex/project/c2273/3DCoMPaT/obj_manifold\", root_name[:6] + \".obj\")\n",
    "    mesh = trimesh.load(path)\n",
    "    return mesh.apply_transform(flip_transform_4x4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from schedulefree import AdamWScheduleFree\n",
    "import torch.nn.functional as F\n",
    "from models.s2vs import fps_subsample\n",
    "\n",
    "\n",
    "\n",
    "def resample_points(points, occs, opt_point_ratio):\n",
    "    \"\"\"\n",
    "    Iterator to resample points and occs to have n_points at every iteration.\n",
    "    \"\"\"\n",
    "    ratio = 1. / opt_point_ratio\n",
    "\n",
    "    while True:\n",
    "        B, N, D = points.shape\n",
    "        points, idx = fps_subsample(points, ratio, return_idx=True)\n",
    "        occs = occs.flatten()\n",
    "        occs = occs[idx].view(B, -1)\n",
    "        yield points, occs\n",
    "\n",
    "\n",
    "def optimize_latents(\n",
    "    ae,\n",
    "    near_surface_points,\n",
    "    occs,\n",
    "    init_latents,\n",
    "    *,\n",
    "    opt_point_ratio=1,\n",
    "    accumulation_steps=1,\n",
    "    max_iter=100,\n",
    "    optimizer=AdamWScheduleFree,\n",
    "    lr=1e-3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Optimize input latent codes w.r.t. a single object with optional gradient accumulation.\n",
    "    \"\"\"\n",
    "    latents = init_latents.clone().detach().to(ae.device).requires_grad_(True)\n",
    "    optimizer = optimizer([latents], lr=lr)\n",
    "\n",
    "    # Main optimization loop\n",
    "    iter_count = 0\n",
    "    \n",
    "    # Initialize the shape iterator\n",
    "    shape_it = resample_points(points, occs, opt_point_ratio)\n",
    "\n",
    "    while iter_count < max_iter:\n",
    "        optimizer.zero_grad()\n",
    "        accumulated_loss = 0\n",
    "\n",
    "        for k in range(accumulation_steps):\n",
    "            near_surface_points, occs = next(shape_it)\n",
    "            near_surface_points = near_surface_points.to(ae.device)\n",
    "            logits = s2vs.query_latents(\n",
    "                ae, latents, near_surface_points, use_graph=True\n",
    "            ).squeeze(-1)\n",
    "            occs = occs.float().to(ae.device)\n",
    "\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, occs).mean()\n",
    "            accumulated_loss += loss.item()\n",
    "\n",
    "            # Accumulate gradients without stepping the optimizer\n",
    "            loss.backward()\n",
    "\n",
    "        # Step the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        iter_count += 1\n",
    "\n",
    "    return latents.detach().cpu()\n",
    "\n",
    "\n",
    "# Set device and seed\n",
    "device = torch.device(args.device)\n",
    "misc.set_all_seeds(args.seed)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Instantiate autoencoder\n",
    "ae = s2vs.load_model(args.ae, args.ae_pth, device, torch_compile=True)\n",
    "ae = ae.eval()\n",
    "\n",
    "all_metrics = {}\n",
    "root_names = get_all_files(args.obj_dir, class_name=\"table\")\n",
    "for root_batch in root_names:\n",
    "    # Initialize the latents, define the ground truth mesh\n",
    "    init_latents, points, near_points, occs = initialize_latents(args, ae, root_batch)\n",
    "    \n",
    "    # Save the initial latents\n",
    "    init_latents_save = init_latents.clone().detach()\n",
    "\n",
    "    # Optimize the latents\n",
    "    optimized_latents = optimize_latents(\n",
    "        ae=ae,\n",
    "        near_surface_points=near_points,\n",
    "        occs=occs,\n",
    "        init_latents=init_latents,\n",
    "        opt_point_ratio=4,\n",
    "        accumulation_steps=1,\n",
    "        max_iter=args.max_iter,\n",
    "        optimizer=AdamWScheduleFree,\n",
    "        lr=1e-3,\n",
    "    )\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_metrics = []\n",
    "for k in range(optimized_latents.shape[0]):\n",
    "    optimized_metrics.append(get_metrics(\n",
    "        ae=ae,\n",
    "        pc_original=points[k].unsqueeze(0),\n",
    "        latents=optimized_latents[k].unsqueeze(0),\n",
    "        batch_size=128**3\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_metrics = []\n",
    "for k in range(optimized_latents.shape[0]):\n",
    "    init_metrics.append(get_metrics(\n",
    "        ae=ae,\n",
    "        pc_original=points[k].unsqueeze(0),\n",
    "        latents=init_latents[k].unsqueeze(0),\n",
    "        batch_size=128**3\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.mesh import show_side_by_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_all(k):\n",
    "    return show_side_by_side(optimized_metrics[k][0], init_metrics[k][0], show_orig_mesh(root_batch[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_all(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_all(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
