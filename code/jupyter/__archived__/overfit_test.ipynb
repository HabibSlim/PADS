{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibex/user/slimhy/PADS/code\n",
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
      "Set seed to 0\n"
     ]
    }
   ],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code\n",
    "%reload_ext autoreload\n",
    "%set_env CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
    "\"\"\"\n",
    "Extracting features into HDF5 files for each split.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "import util.misc as misc\n",
    "import models.s2vs as ae_mods\n",
    "\n",
    "\n",
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\"Extracting Features\", add_help=False)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=32,\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU\"\n",
    "        \" (effective batch size is batch_size * accum_iter * # gpus\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--text_model_name\",\n",
    "        type=str,\n",
    "        help=\"Text model name to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of autoencoder\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae-latent-dim\",\n",
    "        type=int,\n",
    "        default=512*8,\n",
    "        help=\"AE latent dimension\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae_pth\",\n",
    "        required=True,\n",
    "        help=\"Autoencoder checkpoint\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--point_cloud_size\",\n",
    "        default=2048,\n",
    "        type=int,\n",
    "        help=\"input size\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fetch_keys\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_embeds\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--intensity_loss\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Contrastive edit intensity loss using ground-truth labels.\",\n",
    "    )\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument(\n",
    "        \"--dataset\",\n",
    "        type=str,\n",
    "        choices=[\"graphedits\"],\n",
    "        help=\"dataset name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        type=str,\n",
    "        help=\"dataset path\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_type\",\n",
    "        type=str,\n",
    "        help=\"dataset type\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_edge_level\",\n",
    "        default=None,\n",
    "        type=int,\n",
    "        help=\"maximum edge level to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\", default=\"cuda\", help=\"device to use for training / testing\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_workers\", default=60, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--pin_mem\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Pin CPU memory in DataLoader for more efficient \"\n",
    "        \"(sometimes) transfer to GPU.\",\n",
    "    )\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "# Set dummy arg string to debug the parser\n",
    "call_string = \"\"\"--ae_pth ckpt/ae_m512.pth \\\n",
    "    --ae kl_d512_m512_l8 \\\n",
    "    --ae-latent-dim 4096 \\\n",
    "    --data_path /ibex/project/c2273/PADS/3DCoMPaT \\\n",
    "    --batch_size 32 \\\n",
    "    --num_workers 8 \\\n",
    "    --device cuda\"\"\"\n",
    "    \n",
    "\n",
    "# Parse the arguments\n",
    "args = get_args_parser()\n",
    "args = args.parse_args(call_string.split())\n",
    "\n",
    "# --------------------\n",
    "device = torch.device(args.device)\n",
    "misc.set_all_seeds(args.seed)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# --------------------\n",
    "\n",
    "# Initialize and load autoencoder\n",
    "ae = ae_mods.__dict__[args.ae]()\n",
    "ae.load_state_dict(torch.load(args.ae_pth, map_location=\"cpu\")[\"model\"])\n",
    "ae = torch.compile(ae.eval().to(device), mode=\"max-autotune\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.latents import ShapeLatentDataset, ComposedPairedShapesLoader\n",
    "\n",
    "class PairType():\n",
    "    NO_ROT_PAIR = \"rand_no_rot,rand_no_rot\"\n",
    "    PART_DROP = \"part_drop,orig\"\n",
    "\n",
    "# Create your datasets\n",
    "dataset_train = ShapeLatentDataset(args.data_path, split=\"train\", shuffle_parts=True, filter_n_ids=2)\n",
    "dataset_val = ShapeLatentDataset(args.data_path, split=\"test\", shuffle_parts=False, filter_n_ids=2)\n",
    "\n",
    "# Create the DataLoader using the sampler\n",
    "data_loader_train = ComposedPairedShapesLoader(\n",
    "    dataset_train,\n",
    "    batch_size=4,\n",
    "    pair_types_list=[PairType.NO_ROT_PAIR],\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    use_distributed=False\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from models.modules import (\n",
    "    Attention,\n",
    "    DiagonalGaussianDistribution,\n",
    "    GEGLU,\n",
    "    PreNorm,\n",
    "    StackedAttentionBlocks\n",
    ")\n",
    "from models.partqueries import PartEmbed\n",
    "\n",
    "\n",
    "class PartQueriesGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generating a set of part-aware latents\n",
    "    from a set of part bounding boxes and part labels: \"part queries\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim=512,\n",
    "        latent_dim=128,\n",
    "        max_parts=24,\n",
    "        heads=8,\n",
    "        in_heads=1,\n",
    "        dim_head=64,\n",
    "        depth=2,\n",
    "        weight_tie_layers=False,\n",
    "        use_attention_masking=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.max_parts = max_parts\n",
    "        self.use_attention_masking = use_attention_masking\n",
    "\n",
    "        # Part Embeddings\n",
    "        self.part_embed = PartEmbed(dim)\n",
    "        self.embed_proj = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim, dim),\n",
    "        )\n",
    "\n",
    "        # Input Cross-Attention Block\n",
    "        self.in_encode = PreNorm(\n",
    "            dim, Attention(dim, dim, heads=in_heads, dim_head=dim), context_dim=dim\n",
    "        )\n",
    "        \n",
    "        # Replace repeat with learnable projection\n",
    "        self.latent_proj = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim, dim),\n",
    "        )\n",
    "\n",
    "        # Stacked Attention Layers\n",
    "        self.encoder_layers = nn.Identity()\n",
    "        if depth > 0:\n",
    "            self.encoder_layers = StackedAttentionBlocks(\n",
    "                dim, depth, heads, dim_head, weight_tie_layers\n",
    "            )\n",
    "\n",
    "        # Compress latents to latent dimension\n",
    "        self.compress_latents = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim, latent_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, latents, part_bbs, part_labels, batch_mask):\n",
    "        \"\"\"\n",
    "        :param latents:     B x 512 x 8\n",
    "        :param part_bbs:    B x 24 x 4 x 3\n",
    "        :param part_labels: B x 24\n",
    "        :param batch_mask:  B x 24\n",
    "        \"\"\"\n",
    "        # Embed part labels and bounding boxes\n",
    "        part_embeds, labels_embed, bb_embeds = self.part_embed(\n",
    "            part_bbs, part_labels, batch_mask\n",
    "        )\n",
    "        \n",
    "        # Apply learnable projection instead of repeat\n",
    "        latents_kv = latents.transpose(1, 2).repeat(1, 3, 1) # B x 24 x 512\n",
    "        latents_kv = self.latent_proj(latents_kv)\n",
    "        \n",
    "        # Concatenate part embeddings with latents\n",
    "        part_embeds = self.embed_proj(part_embeds) # B x 24 x 512\n",
    "\n",
    "        # Encode part embeddings\n",
    "        mask = batch_mask if self.use_attention_masking else None\n",
    "        x = self.in_encode(part_embeds, context=latents_kv, mask=mask) # B x 24 x 512\n",
    "        x = self.encoder_layers(x)               # B x 24 x 512\n",
    "        part_latents = self.compress_latents(x)  # B x 24 x 512\n",
    "        return part_latents, part_embeds\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "\n",
    "class PartAwareAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim=512,\n",
    "        latent_dim=128,\n",
    "        max_parts=24,\n",
    "        heads=8,\n",
    "        in_heads=1,\n",
    "        dim_head=64,\n",
    "        depth=2,\n",
    "        weight_tie_layers=False,\n",
    "        use_attention_masking=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.is_vae = False\n",
    "        self.dim = dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.use_attention_masking = use_attention_masking\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = PartQueriesGenerator(\n",
    "            dim=dim,\n",
    "            latent_dim=latent_dim,\n",
    "            max_parts=max_parts,\n",
    "            heads=heads,\n",
    "            in_heads=in_heads,\n",
    "            dim_head=dim_head,\n",
    "            depth=depth,\n",
    "            weight_tie_layers=weight_tie_layers,\n",
    "            use_attention_masking=use_attention_masking,\n",
    "        )\n",
    "        \n",
    "        # Decoder components\n",
    "        self.in_decode = PreNorm(\n",
    "            dim, Attention(dim, dim, heads=in_heads, dim_head=dim), context_dim=dim\n",
    "        )\n",
    "        \n",
    "        self.decode_proj = nn.Linear(dim * 2, dim)\n",
    "        self.out_proj = nn.Linear(24, 8)\n",
    "\n",
    "        # Stacked Attention Layers for decoder\n",
    "        self.decoder_layers = StackedAttentionBlocks(\n",
    "            dim, depth, heads, dim_head, weight_tie_layers\n",
    "        )\n",
    "\n",
    "        # Expand latents\n",
    "        self.expand_latents = nn.Sequential(\n",
    "            nn.Linear(latent_dim, dim),\n",
    "            GEGLU(),\n",
    "            nn.Linear(dim // 2, dim),\n",
    "        )\n",
    "\n",
    "    def decode(self, part_latents, bb_embeds, batch_mask):\n",
    "        x = self.expand_latents(part_latents)\n",
    "        mask = batch_mask if self.use_attention_masking else None\n",
    "        x = torch.cat([x, bb_embeds], dim=-1)\n",
    "        x = self.decode_proj(x)\n",
    "        x = self.in_decode(x, mask=mask) #, context=bb_embeds\n",
    "        x = self.decoder_layers(x)\n",
    "        x = self.out_proj(x.transpose(1, 2))\n",
    "        return x\n",
    "\n",
    "    def forward(self, latents, part_bbs, part_labels, batch_mask):\n",
    "        part_latents, bb_embeds = self.encoder(\n",
    "            latents, part_bbs, part_labels, batch_mask\n",
    "        )\n",
    "        logits = self.decode(part_latents, bb_embeds, batch_mask)\n",
    "\n",
    "        return logits, part_latents\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "\n",
    "class PartAwareVAE(PartAwareAE):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.is_vae = True\n",
    "        self.mean_fc = nn.Linear(self.latent_dim, self.latent_dim)\n",
    "        self.logvar_fc = nn.Linear(self.latent_dim, self.latent_dim)\n",
    "\n",
    "    def encode(self, latents, part_bbs, part_labels, batch_mask, deterministic=False):\n",
    "        part_latents, bb_embeds = self.encoder(\n",
    "            latents, part_bbs, part_labels, batch_mask\n",
    "        )\n",
    "\n",
    "        mean = self.mean_fc(part_latents)\n",
    "        logvar = self.logvar_fc(part_latents)\n",
    "\n",
    "        posterior = DiagonalGaussianDistribution(\n",
    "            mean, logvar, deterministic=deterministic, no_reduction=True\n",
    "        )\n",
    "        part_latents = posterior.sample()\n",
    "        kl = posterior.kl()\n",
    "\n",
    "        return kl, part_latents, bb_embeds\n",
    "\n",
    "    def forward(self, latents, part_bbs, part_labels, batch_mask, deterministic=False):\n",
    "        kl, part_latents, bb_embeds = self.encode(\n",
    "            latents, part_bbs, part_labels, batch_mask, deterministic=deterministic\n",
    "        )\n",
    "        logits = self.decode(part_latents, bb_embeds, batch_mask).squeeze(-1)\n",
    "\n",
    "        return logits, kl, part_latents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part latents shape: torch.Size([1, 512, 8])\n",
      "Part embeddings shape: torch.Size([1, 24, 128])\n",
      "\n",
      "Reconstruction invariant to latents permutation: PASSED\n",
      "\n",
      "Part latents equivariant to parts permutation: PASSED\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "def assert_close(tensor1, tensor2, rtol=1e-5, atol=1e-5):\n",
    "    assert torch.allclose(tensor1, tensor2, rtol=rtol, atol=atol), \\\n",
    "        f\"Tensors are not close: \\n{tensor1}\\n{tensor2}\"\n",
    "\n",
    "\n",
    "def test_latent_permutation_invariance(model):\n",
    "    batch_size, num_parts = 1,  24\n",
    "    \n",
    "    latents = torch.rand(batch_size, 512, 8)\n",
    "    part_bbs = torch.rand(batch_size, num_parts, 4, 3)\n",
    "    part_labels = torch.randint(0, 10, (batch_size, num_parts), dtype=torch.long)\n",
    "    batch_mask = torch.ones(batch_size, num_parts).bool()\n",
    "    \n",
    "    l_0, p_l_0 = model(latents, part_bbs, part_labels, batch_mask)\n",
    "    \n",
    "    perm = torch.randperm(8)\n",
    "    \n",
    "    l_1, p_l_1 = model(latents[:, :, perm], part_bbs, part_labels, batch_mask)\n",
    "    \n",
    "    try:\n",
    "        assert_close(l_0, l_1)\n",
    "        print(\"Reconstruction invariant to latents permutation: PASSED\")\n",
    "    except AssertionError as e:\n",
    "        print(\"Reconstruction invariant to latents permutation: FAILED\")\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "def test_part_latents_equivariance(model):\n",
    "    batch_size, num_parts = 1, 24\n",
    "    \n",
    "    latents = torch.rand(batch_size, 512, 8)\n",
    "    part_bbs = torch.rand(batch_size, num_parts, 4, 3)\n",
    "    part_labels = torch.randint(0, 10, (batch_size, num_parts), dtype=torch.long)\n",
    "    batch_mask = torch.ones(batch_size, num_parts).bool()\n",
    "    \n",
    "    l_0, p_l_0 = model(latents, part_bbs, part_labels, batch_mask)\n",
    "    \n",
    "    perm = torch.randperm(num_parts)\n",
    "    permuted_part_bbs = part_bbs[:, perm, :, :]\n",
    "    permuted_part_labels = part_labels[:, perm]\n",
    "    \n",
    "    l_1, p_l_1 = model(\n",
    "        latents,\n",
    "        permuted_part_bbs,\n",
    "        permuted_part_labels,\n",
    "        batch_mask\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        assert_close(p_l_0[:, perm, :], p_l_1)\n",
    "        print(\"Part latents equivariant to parts permutation: PASSED\")\n",
    "    except AssertionError as e:\n",
    "        print(\"Part latents equivariant to parts permutation: FAILED\")\n",
    "        print(str(e))\n",
    "        \n",
    "        \n",
    "def print_return_shapes(model):\n",
    "    batch_size, num_parts = 1, 24\n",
    "    \n",
    "    latents = torch.rand(batch_size, 512, 8)\n",
    "    part_bbs = torch.rand(batch_size, num_parts, 4, 3)\n",
    "    part_labels = torch.randint(0, 10, (batch_size, num_parts), dtype=torch.long)\n",
    "    batch_mask = torch.ones(batch_size, num_parts).bool()\n",
    "    \n",
    "    part_latents, part_embeds = model(latents, part_bbs, part_labels, batch_mask)\n",
    "    print(\"Part latents shape:\", part_latents.shape)\n",
    "    print(\"Part embeddings shape:\", part_embeds.shape)\n",
    "\n",
    "\n",
    "# Initialize your model\n",
    "model = PartAwareAE(\n",
    "    dim=512,\n",
    "    latent_dim=128,\n",
    "    max_parts=24,\n",
    "    heads=8,\n",
    "    in_heads=1,\n",
    "    dim_head=64,\n",
    "    depth=2,\n",
    "    use_attention_masking=True,\n",
    ")\n",
    "\n",
    "# Run the tests\n",
    "print_return_shapes(model)\n",
    "print()\n",
    "test_latent_permutation_invariance(model)\n",
    "print()\n",
    "test_part_latents_equivariance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [   0/5000]  eta: 0:34:32  train_loss: 1.0466 (1.0466)  kl_reg: 4.1607 (4.1607)  rec_loss: 1.0055 (1.0055)  inv_loss: 2.0317 (2.0317)  time: 0.4144  data: 0.0000  max mem: 1221\n",
      "  [ 100/5000]  eta: 0:10:35  train_loss: 0.4993 (0.6539)  kl_reg: 0.1299 (0.2921)  rec_loss: 0.4793 (0.6326)  inv_loss: 1.9591 (1.9747)  time: 0.1425  data: 0.0000  max mem: 1221\n",
      "  [ 200/5000]  eta: 0:10:47  train_loss: 0.3136 (0.5149)  kl_reg: 0.0866 (0.1929)  rec_loss: 0.2938 (0.4943)  inv_loss: 1.9285 (1.9589)  time: 0.1406  data: 0.0000  max mem: 1221\n",
      "  [ 300/5000]  eta: 0:10:43  train_loss: 0.2042 (0.4256)  kl_reg: 0.0800 (0.1631)  rec_loss: 0.1898 (0.4062)  inv_loss: 1.3665 (1.8593)  time: 0.1414  data: 0.0000  max mem: 1221\n",
      "  [ 400/5000]  eta: 0:10:34  train_loss: 0.1299 (0.3584)  kl_reg: 0.0343 (0.1353)  rec_loss: 0.1162 (0.3404)  inv_loss: 1.3608 (1.7339)  time: 0.1414  data: 0.0000  max mem: 1221\n",
      "  [ 500/5000]  eta: 0:10:20  train_loss: 0.1017 (0.3090)  kl_reg: 0.0290 (0.1145)  rec_loss: 0.0878 (0.2918)  inv_loss: 1.3618 (1.6596)  time: 0.1347  data: 0.0000  max mem: 1221\n",
      "  [ 600/5000]  eta: 0:10:06  train_loss: 0.0845 (0.2728)  kl_reg: 0.0236 (0.0998)  rec_loss: 0.0708 (0.2562)  inv_loss: 1.3599 (1.6099)  time: 0.1363  data: 0.0000  max mem: 1221\n",
      "  [ 700/5000]  eta: 0:09:52  train_loss: 0.1118 (0.2462)  kl_reg: 0.0267 (0.0891)  rec_loss: 0.0982 (0.2300)  inv_loss: 1.3688 (1.5803)  time: 0.1378  data: 0.0000  max mem: 1221\n",
      "  [ 800/5000]  eta: 0:09:39  train_loss: 0.0783 (0.2270)  kl_reg: 0.0264 (0.0812)  rec_loss: 0.0646 (0.2111)  inv_loss: 1.3719 (1.5573)  time: 0.1381  data: 0.0000  max mem: 1221\n",
      "  [ 900/5000]  eta: 0:09:26  train_loss: 0.0616 (0.2094)  kl_reg: 0.0207 (0.0748)  rec_loss: 0.0479 (0.1937)  inv_loss: 1.3668 (1.5366)  time: 0.1393  data: 0.0000  max mem: 1221\n",
      "  [1000/5000]  eta: 0:09:12  train_loss: 0.0478 (0.1944)  kl_reg: 0.0262 (0.0701)  rec_loss: 0.0341 (0.1788)  inv_loss: 1.3559 (1.5191)  time: 0.1405  data: 0.0000  max mem: 1221\n",
      "  [1100/5000]  eta: 0:09:00  train_loss: 0.0380 (0.1805)  kl_reg: 0.0222 (0.0659)  rec_loss: 0.0243 (0.1651)  inv_loss: 1.3557 (1.5045)  time: 0.1477  data: 0.0000  max mem: 1221\n",
      "  [1200/5000]  eta: 0:08:45  train_loss: 0.0305 (0.1682)  kl_reg: 0.0210 (0.0622)  rec_loss: 0.0169 (0.1530)  inv_loss: 1.3569 (1.4924)  time: 0.1373  data: 0.0000  max mem: 1221\n",
      "  [1300/5000]  eta: 0:08:31  train_loss: 0.0257 (0.1574)  kl_reg: 0.0196 (0.0590)  rec_loss: 0.0122 (0.1423)  inv_loss: 1.3575 (1.4821)  time: 0.1386  data: 0.0000  max mem: 1221\n",
      "  [1400/5000]  eta: 0:08:16  train_loss: 0.0218 (0.1478)  kl_reg: 0.0175 (0.0561)  rec_loss: 0.0081 (0.1328)  inv_loss: 1.3622 (1.4732)  time: 0.1237  data: 0.0000  max mem: 1221\n",
      "  [1500/5000]  eta: 0:08:02  train_loss: 0.0187 (0.1393)  kl_reg: 0.0167 (0.0535)  rec_loss: 0.0052 (0.1244)  inv_loss: 1.3528 (1.4654)  time: 0.1388  data: 0.0000  max mem: 1221\n",
      "  [1600/5000]  eta: 0:07:49  train_loss: 0.0154 (0.1317)  kl_reg: 0.0170 (0.0513)  rec_loss: 0.0016 (0.1168)  inv_loss: 1.3666 (1.4590)  time: 0.1391  data: 0.0000  max mem: 1221\n",
      "  [1700/5000]  eta: 0:07:35  train_loss: 0.0146 (0.1248)  kl_reg: 0.0165 (0.0493)  rec_loss: 0.0010 (0.1100)  inv_loss: 1.3639 (1.4532)  time: 0.1360  data: 0.0000  max mem: 1221\n",
      "  [1800/5000]  eta: 0:07:21  train_loss: 0.0144 (0.1187)  kl_reg: 0.0159 (0.0475)  rec_loss: 0.0007 (0.1040)  inv_loss: 1.3593 (1.4480)  time: 0.1414  data: 0.0000  max mem: 1221\n",
      "  [1900/5000]  eta: 0:07:07  train_loss: 0.0143 (0.1132)  kl_reg: 0.0159 (0.0458)  rec_loss: 0.0006 (0.0985)  inv_loss: 1.3609 (1.4434)  time: 0.1410  data: 0.0000  max mem: 1221\n",
      "  [2000/5000]  eta: 0:06:54  train_loss: 0.0142 (0.1083)  kl_reg: 0.0161 (0.0444)  rec_loss: 0.0005 (0.0937)  inv_loss: 1.3568 (1.4392)  time: 0.1373  data: 0.0000  max mem: 1221\n",
      "  [2100/5000]  eta: 0:06:40  train_loss: 0.0141 (0.1038)  kl_reg: 0.0159 (0.0430)  rec_loss: 0.0004 (0.0892)  inv_loss: 1.3587 (1.4354)  time: 0.1396  data: 0.0000  max mem: 1221\n",
      "  [2200/5000]  eta: 0:06:26  train_loss: 0.0142 (0.0997)  kl_reg: 0.0141 (0.0418)  rec_loss: 0.0006 (0.0852)  inv_loss: 1.3648 (1.4320)  time: 0.1352  data: 0.0000  max mem: 1221\n",
      "  [2300/5000]  eta: 0:06:13  train_loss: 0.0140 (0.0960)  kl_reg: 0.0162 (0.0407)  rec_loss: 0.0003 (0.0815)  inv_loss: 1.3610 (1.4289)  time: 0.1454  data: 0.0000  max mem: 1221\n",
      "  [2400/5000]  eta: 0:06:00  train_loss: 0.0147 (0.0932)  kl_reg: 0.0167 (0.0397)  rec_loss: 0.0009 (0.0787)  inv_loss: 1.3627 (1.4261)  time: 0.1436  data: 0.0000  max mem: 1221\n",
      "  [2500/5000]  eta: 0:05:46  train_loss: 0.0155 (0.0909)  kl_reg: 0.0170 (0.0390)  rec_loss: 0.0018 (0.0764)  inv_loss: 1.3578 (1.4235)  time: 0.1395  data: 0.0000  max mem: 1221\n",
      "  [2600/5000]  eta: 0:05:31  train_loss: 0.0144 (0.0879)  kl_reg: 0.0159 (0.0381)  rec_loss: 0.0007 (0.0735)  inv_loss: 1.3581 (1.4210)  time: 0.1238  data: 0.0000  max mem: 1221\n",
      "  [2700/5000]  eta: 0:05:17  train_loss: 0.0142 (0.0852)  kl_reg: 0.0159 (0.0373)  rec_loss: 0.0005 (0.0708)  inv_loss: 1.3549 (1.4187)  time: 0.1390  data: 0.0000  max mem: 1221\n",
      "  [2800/5000]  eta: 0:05:03  train_loss: 0.0145 (0.0827)  kl_reg: 0.0153 (0.0365)  rec_loss: 0.0009 (0.0683)  inv_loss: 1.3559 (1.4167)  time: 0.1369  data: 0.0000  max mem: 1221\n",
      "  [2900/5000]  eta: 0:04:49  train_loss: 0.0148 (0.0803)  kl_reg: 0.0155 (0.0358)  rec_loss: 0.0011 (0.0660)  inv_loss: 1.3605 (1.4147)  time: 0.1383  data: 0.0000  max mem: 1221\n",
      "  [3000/5000]  eta: 0:04:36  train_loss: 0.0141 (0.0781)  kl_reg: 0.0160 (0.0352)  rec_loss: 0.0004 (0.0638)  inv_loss: 1.3592 (1.4129)  time: 0.1399  data: 0.0000  max mem: 1221\n",
      "  [3100/5000]  eta: 0:04:22  train_loss: 0.0141 (0.0761)  kl_reg: 0.0160 (0.0346)  rec_loss: 0.0004 (0.0618)  inv_loss: 1.3595 (1.4111)  time: 0.1422  data: 0.0000  max mem: 1221\n",
      "  [3200/5000]  eta: 0:04:08  train_loss: 0.0142 (0.0742)  kl_reg: 0.0156 (0.0340)  rec_loss: 0.0005 (0.0599)  inv_loss: 1.3568 (1.4095)  time: 0.1384  data: 0.0000  max mem: 1221\n",
      "  [3300/5000]  eta: 0:03:54  train_loss: 0.0143 (0.0723)  kl_reg: 0.0158 (0.0334)  rec_loss: 0.0005 (0.0581)  inv_loss: 1.3589 (1.4080)  time: 0.1389  data: 0.0000  max mem: 1221\n",
      "  [3400/5000]  eta: 0:03:41  train_loss: 0.0140 (0.0706)  kl_reg: 0.0157 (0.0329)  rec_loss: 0.0003 (0.0564)  inv_loss: 1.3597 (1.4065)  time: 0.1385  data: 0.0000  max mem: 1221\n",
      "  [3500/5000]  eta: 0:03:27  train_loss: 0.0140 (0.0690)  kl_reg: 0.0153 (0.0324)  rec_loss: 0.0003 (0.0548)  inv_loss: 1.3593 (1.4052)  time: 0.1408  data: 0.0000  max mem: 1221\n",
      "  [3600/5000]  eta: 0:03:13  train_loss: 0.0140 (0.0675)  kl_reg: 0.0155 (0.0319)  rec_loss: 0.0004 (0.0533)  inv_loss: 1.3602 (1.4040)  time: 0.1424  data: 0.0000  max mem: 1221\n",
      "  [3700/5000]  eta: 0:02:59  train_loss: 0.0140 (0.0660)  kl_reg: 0.0156 (0.0315)  rec_loss: 0.0003 (0.0519)  inv_loss: 1.3637 (1.4027)  time: 0.1381  data: 0.0000  max mem: 1221\n",
      "  [3800/5000]  eta: 0:02:45  train_loss: 0.0141 (0.0647)  kl_reg: 0.0152 (0.0311)  rec_loss: 0.0004 (0.0505)  inv_loss: 1.3613 (1.4016)  time: 0.1338  data: 0.0000  max mem: 1221\n",
      "  [3900/5000]  eta: 0:02:32  train_loss: 0.0140 (0.0634)  kl_reg: 0.0155 (0.0307)  rec_loss: 0.0004 (0.0492)  inv_loss: 1.3567 (1.4006)  time: 0.1364  data: 0.0000  max mem: 1221\n",
      "  [4000/5000]  eta: 0:02:18  train_loss: 0.0141 (0.0621)  kl_reg: 0.0156 (0.0303)  rec_loss: 0.0004 (0.0480)  inv_loss: 1.3659 (1.3996)  time: 0.1367  data: 0.0000  max mem: 1221\n",
      "  [4100/5000]  eta: 0:02:04  train_loss: 0.0140 (0.0610)  kl_reg: 0.0154 (0.0299)  rec_loss: 0.0003 (0.0468)  inv_loss: 1.3588 (1.3986)  time: 0.1375  data: 0.0000  max mem: 1221\n",
      "  [4200/5000]  eta: 0:01:50  train_loss: 0.0141 (0.0599)  kl_reg: 0.0153 (0.0296)  rec_loss: 0.0003 (0.0457)  inv_loss: 1.3614 (1.3977)  time: 0.1360  data: 0.0000  max mem: 1221\n",
      "  [4300/5000]  eta: 0:01:36  train_loss: 0.0140 (0.0588)  kl_reg: 0.0154 (0.0293)  rec_loss: 0.0003 (0.0447)  inv_loss: 1.3646 (1.3968)  time: 0.1375  data: 0.0000  max mem: 1221\n",
      "  [4400/5000]  eta: 0:01:22  train_loss: 0.0145 (0.0578)  kl_reg: 0.0154 (0.0289)  rec_loss: 0.0008 (0.0437)  inv_loss: 1.3587 (1.3960)  time: 0.1343  data: 0.0000  max mem: 1221\n",
      "  [4500/5000]  eta: 0:01:08  train_loss: 0.0140 (0.0569)  kl_reg: 0.0150 (0.0286)  rec_loss: 0.0003 (0.0428)  inv_loss: 1.3608 (1.3952)  time: 0.1381  data: 0.0000  max mem: 1221\n",
      "  [4600/5000]  eta: 0:00:55  train_loss: 0.0139 (0.0559)  kl_reg: 0.0152 (0.0284)  rec_loss: 0.0002 (0.0419)  inv_loss: 1.3639 (1.3944)  time: 0.1340  data: 0.0000  max mem: 1221\n",
      "  [4700/5000]  eta: 0:00:41  train_loss: 0.0139 (0.0550)  kl_reg: 0.0150 (0.0281)  rec_loss: 0.0002 (0.0410)  inv_loss: 1.3564 (1.3937)  time: 0.1356  data: 0.0000  max mem: 1221\n",
      "  [4800/5000]  eta: 0:00:27  train_loss: 0.0140 (0.0542)  kl_reg: 0.0150 (0.0278)  rec_loss: 0.0003 (0.0401)  inv_loss: 1.3615 (1.3930)  time: 0.1331  data: 0.0000  max mem: 1221\n",
      "  [4900/5000]  eta: 0:00:13  train_loss: 0.0140 (0.0534)  kl_reg: 0.0150 (0.0275)  rec_loss: 0.0003 (0.0393)  inv_loss: 1.3639 (1.3923)  time: 0.1335  data: 0.0000  max mem: 1221\n",
      "  [4999/5000]  eta: 0:00:00  train_loss: 0.0140 (0.0526)  kl_reg: 0.0151 (0.0273)  rec_loss: 0.0003 (0.0385)  inv_loss: 1.3623 (1.3917)  time: 0.1314  data: 0.0000  max mem: 1221\n",
      " Total time: 0:11:28 (0.1377 s / it)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from losses.partvae import KLRecLoss, RecLoss, ScaleInvariantLoss, PartDropLoss\n",
    "from schedulefree import AdamWScheduleFree\n",
    "\n",
    "\n",
    "def get_losses():\n",
    "    \"\"\"\n",
    "    Instantiate the losses.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        RecLoss(),\n",
    "        KLRecLoss(),\n",
    "        ScaleInvariantLoss(),\n",
    "        PartDropLoss(),\n",
    "    )\n",
    "\n",
    "\n",
    "def forward_pass(\n",
    "    pvae,\n",
    "    data_tuple,\n",
    "    rec_loss,\n",
    "    kl_rec_loss,\n",
    "    scale_inv_loss,\n",
    "    part_drop_loss,\n",
    "    pair_types,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute a single forward pass of the model.\n",
    "    \"\"\"\n",
    "    # Unpack the data tuple\n",
    "    pair_types, (l_a, bb_a, bb_l_a, meta_a), (l_b, bb_b, bb_l_b, meta_b) = data_tuple\n",
    "    device = pvae.device\n",
    "\n",
    "    # Compute the mask from batch labels\n",
    "    mask_a = (bb_l_a != -1).to(device)  # B x 24\n",
    "    mask_b = (bb_l_b != -1).to(device)  # B x 24\n",
    "\n",
    "    l_a, l_b = l_a.to(device), l_b.to(device)  # B x 8 x 512\n",
    "    # l_a = l_a.transpose(1, 2)  # B x 512 x 8\n",
    "    # l_b = l_b.transpose(1, 2)  # B x 512 x 8\n",
    "    bb_a, bb_b = bb_a.to(device), bb_b.to(device)  # B x 24 x 4 x 3\n",
    "    bb_l_a, bb_l_b = bb_l_a.to(device), bb_l_b.to(device)  # B x 24\n",
    "\n",
    "    # Optionally compute the KL Reg loss\n",
    "    if pvae.is_vae:\n",
    "        logits_a, kl_a, part_latents_a = pvae(\n",
    "            latents=l_a, part_bbs=bb_a, part_labels=bb_l_a, batch_mask=mask_a\n",
    "        )\n",
    "        logits_b, kl_b, part_latents_b = pvae(\n",
    "            latents=l_b, part_bbs=bb_b, part_labels=bb_l_b, batch_mask=mask_b\n",
    "        )\n",
    "\n",
    "        # KL Reg loss\n",
    "        kl_reg = kl_rec_loss(kl_a, mask=mask_a) + kl_rec_loss(kl_b, mask=mask_b)\n",
    "        kl_reg /= 2.0\n",
    "    else:\n",
    "        logits_a, part_latents_a = pvae(\n",
    "            latents=l_a, part_bbs=bb_a, part_labels=bb_l_a, batch_mask=mask_a\n",
    "        )\n",
    "        logits_b, part_latents_b = pvae(\n",
    "            latents=l_b, part_bbs=bb_b, part_labels=bb_l_b, batch_mask=mask_b\n",
    "        )\n",
    "        kl_reg = torch.tensor(0.0).to(device)\n",
    "\n",
    "    # L2 loss\n",
    "    rec_loss = F.mse_loss(logits_a, l_a) + F.mse_loss(logits_b, l_b)\n",
    "    # rec_loss = rec_loss(logits_a, l_a, transpose=True) + rec_loss(logits_b, l_b, transpose=True)\n",
    "    rec_loss /= 2.0\n",
    "\n",
    "    # if pair_types == PairType.NO_ROT_PAIR:\n",
    "    #     inv_loss = scale_inv_loss(part_latents_a, part_latents_b, mask_a)\n",
    "    # elif pair_types == PairType.PART_DROP:\n",
    "    #     inv_loss = part_drop_loss(\n",
    "    #         part_latents_a, part_latents_b, bb_a, bb_b, mask_a, mask_b\n",
    "    #     )\n",
    "        \n",
    "    # Add part latents magnitude loss\n",
    "    inv_loss = F.mse_loss(part_latents_b, torch.zeros_like(part_latents_b))\n",
    "    inv_loss += F.mse_loss(part_latents_a, torch.zeros_like(part_latents_a))\n",
    "\n",
    "    return {\n",
    "        \"kl_reg\": kl_reg,\n",
    "        \"rec_loss\": rec_loss,\n",
    "        \"inv_loss\": inv_loss,\n",
    "        \"last_sample\": (logits_a, l_a, bb_a, bb_l_a, mask_a),\n",
    "    }\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "pvae = PartAwareVAE(\n",
    "    dim=512,\n",
    "    latent_dim=512,\n",
    "    heads=8,\n",
    "    dim_head=64,\n",
    "    depth=4,\n",
    ").to(device)\n",
    "pvae = pvae.to(device)\n",
    "pvae.train(True)\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = AdamWScheduleFree(\n",
    "    pvae.parameters(), lr=1e-4, weight_decay=1e-5\n",
    ")\n",
    "optimizer.zero_grad()\n",
    "\n",
    "rec_loss, kl_loss, scale_inv_loss, part_drop_loss = get_losses()\n",
    "\n",
    "metric_logger = misc.MetricLogger(delimiter=\"  \")\n",
    "\n",
    "for epoch in metric_logger.log_every(\n",
    "    list(range(5000)), 100\n",
    "):\n",
    "    data_seen = False\n",
    "    for data_tuple in data_loader_train:\n",
    "        data_seen = True\n",
    "        # Computing loss\n",
    "        loss = forward_pass(\n",
    "            pvae=pvae,\n",
    "            data_tuple=data_tuple,\n",
    "            rec_loss=rec_loss,\n",
    "            kl_rec_loss=kl_loss,\n",
    "            scale_inv_loss=scale_inv_loss,\n",
    "            part_drop_loss=part_drop_loss,\n",
    "            pair_types=PairType.PART_DROP,\n",
    "        )\n",
    "        total_loss = (\n",
    "            0.005 * loss[\"kl_reg\"]\n",
    "            + 1. * loss[\"rec_loss\"]\n",
    "            + 0.01 * loss[\"inv_loss\"]\n",
    "        )\n",
    "        data_seen = True\n",
    "        \n",
    "        accum_iter = 1\n",
    "\n",
    "        # Backward pass\n",
    "        total_loss /= accum_iter\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # Clip the gradients\n",
    "        nn.utils.clip_grad_norm_(pvae.parameters(), 5.)\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Log the losses\n",
    "        loss_update = {\n",
    "            \"train_loss\": float(total_loss.item()),\n",
    "            \"kl_reg\": float(loss[\"kl_reg\"].item()),\n",
    "            \"rec_loss\": float(loss[\"rec_loss\"].item()),\n",
    "            \"inv_loss\": float(loss[\"inv_loss\"].item()),\n",
    "        }\n",
    "        metric_logger.update(**loss_update)\n",
    "    assert data_seen, \"No data seen in the training loop.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import trimesh\n",
    "import k3d\n",
    "from util import s2vs\n",
    "\n",
    "\n",
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\"Autoencoder Visualization\", add_help=False)\n",
    "    parser.add_argument(\"--ae_pth\", required=True, help=\"Autoencoder checkpoint\")\n",
    "    parser.add_argument(\"--ae\", type=str, default=\"kl_d512_m512_l8\", help=\"Name of autoencoder\")\n",
    "    parser.add_argument(\"--ae-latent-dim\", type=int, default=4096, help=\"AE latent dimension\")\n",
    "    parser.add_argument(\"--batch_size\", default=32, type=int, help=\"Batch size\")\n",
    "    parser.add_argument(\"--num_workers\", default=8, type=int, help=\"Number of workers for data loading\")\n",
    "    parser.add_argument(\"--device\", default=\"cuda\", help=\"Device to use for computation\")\n",
    "    parser.add_argument(\"--seed\", default=0, type=int, help=\"Random seed\")\n",
    "    parser.add_argument(\"--pin_mem\", action=\"store_true\", help=\"Pin CPU memory in DataLoader\")\n",
    "    return parser\n",
    "\n",
    "def obb_to_corners(box_array):\n",
    "    center, right, up, forward = [np.array(box_array[i]) for i in range(4)]\n",
    "    corners = np.array([\n",
    "        [-1, -1, -1], [ 1, -1, -1], [ 1,  1, -1], [-1,  1, -1],\n",
    "        [-1, -1,  1], [ 1, -1,  1], [ 1,  1,  1], [-1,  1,  1]\n",
    "    ])\n",
    "    transform = np.column_stack((right, up, forward))\n",
    "    return np.dot(corners, transform.T) + center\n",
    "\n",
    "def create_trimesh_boxes(bounding_boxes):\n",
    "    return [\n",
    "        trimesh.util.concatenate([\n",
    "            trimesh.primitives.Sphere(radius=0.01).apply_translation(corner)\n",
    "            for corner in obb_to_corners(box)\n",
    "        ])\n",
    "        for box in bounding_boxes if not np.all(box == 0)\n",
    "    ]\n",
    "\n",
    "def load_checkpoint(model, checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    return model\n",
    "\n",
    "def visualize_decoded_mesh(decoded_mesh, bounding_boxes):\n",
    "    trimesh_boxes = create_trimesh_boxes(bounding_boxes)\n",
    "    col_map = k3d.helpers.map_colors(np.arange(len(trimesh_boxes)), k3d.colormaps.basic_color_maps.Rainbow)\n",
    "    \n",
    "    plot = k3d.plot()\n",
    "    plot += k3d.mesh(decoded_mesh.vertices, decoded_mesh.faces, color=0x0000ff, opacity=0.5)\n",
    "    for k, bb_mesh in enumerate(trimesh_boxes):\n",
    "        plot += k3d.mesh(bb_mesh.vertices, bb_mesh.faces, color=int(col_map[k]), opacity=0.5)\n",
    "    return plot\n",
    "\n",
    "def show_mesh(ae, logits_a, bb_a):\n",
    "    assert logits_a.shape[0] == 1, \"Can only visualize a single shape at a time\"\n",
    "    mesh = s2vs.decode_latents(ae, logits_a.to(ae.device), grid_density=128, batch_size=64**3)\n",
    "    bounding_boxes = np.array(bb_a[0].cpu())\n",
    "    plot = visualize_decoded_mesh(mesh.trimesh_mesh, bounding_boxes)\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[1;32m      2\u001b[0m     logits_a, l_a, bb_a, bb_l_a, mask_a \u001b[38;5;241m=\u001b[39m loss[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m     logits_a, _ \u001b[38;5;241m=\u001b[39m pvae(\n\u001b[1;32m      4\u001b[0m         latents\u001b[38;5;241m=\u001b[39ml_a, part_bbs\u001b[38;5;241m=\u001b[39mbb_a, part_labels\u001b[38;5;241m=\u001b[39mbb_l_a, batch_mask\u001b[38;5;241m=\u001b[39mmask_a\n\u001b[1;32m      5\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    logits_a, l_a, bb_a, bb_l_a, mask_a = loss[\"last_sample\"]\n",
    "    logits_a, _ = pvae(\n",
    "        latents=l_a, part_bbs=bb_a, part_labels=bb_l_a, batch_mask=mask_a\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_mesh(ae, logits_a[0].unsqueeze(0), bb_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
