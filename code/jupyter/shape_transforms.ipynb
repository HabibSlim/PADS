{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibex/user/slimhy/PADS/code\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'show_side_by_side' from 'util.misc' (/ibex/user/slimhy/PADS/code/util/misc.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtrimesh\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m d_GPU, show_side_by_side, CUDAMesh\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'show_side_by_side' from 'util.misc' (/ibex/user/slimhy/PADS/code/util/misc.py)"
     ]
    }
   ],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code/\n",
    "#Â %env CUDA_LAUNCH_BLOCKING=1\n",
    "\"\"\"\n",
    "Extracting features into HDF5 files for each split.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "from datasets.shapeloaders import CoMPaTSegmentDataset, ShapeNetDataset\n",
    "from datasets.metadata import (\n",
    "    SHAPENET_NAME_TO_SYNSET_INDEX,\n",
    "    SHAPENET_NAME_TO_SYNSET\n",
    ")\n",
    "\n",
    "import util.misc as misc\n",
    "import util.s2vs as s2vs\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from util.misc import d_GPU, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\"Extracting Features\", add_help=False)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=32,\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--text_model_name\",\n",
    "        type=str,\n",
    "        help=\"Text model name to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of autoencoder\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae-latent-dim\",\n",
    "        type=int,\n",
    "        default=512*8,\n",
    "        help=\"AE latent dimension\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae_pth\",\n",
    "        required=True,\n",
    "        help=\"Autoencoder checkpoint\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--point_cloud_size\",\n",
    "        default=2048,\n",
    "        type=int,\n",
    "        help=\"input size\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fetch_keys\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_embeds\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--intensity_loss\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Contrastive edit intensity loss using ground-truth labels.\",\n",
    "    )\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument(\n",
    "        \"--dataset\",\n",
    "        type=str,\n",
    "        choices=[\"graphedits\"],\n",
    "        help=\"dataset name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        type=str,\n",
    "        help=\"dataset path\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_type\",\n",
    "        type=str,\n",
    "        help=\"dataset type\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_edge_level\",\n",
    "        default=None,\n",
    "        type=int,\n",
    "        help=\"maximum edge level to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\", default=\"cuda\", help=\"device to use for training / testing\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_workers\", default=60, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--pin_mem\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.\",\n",
    "    )\n",
    "\n",
    "    return parser\n",
    "\n",
    "# Set dummy arg string to debug the parser\n",
    "call_string = \"\"\"--ae_pth ckpt/ae_m512.pth \\\n",
    "    --ae kl_d512_m512_l8 \\\n",
    "    --ae-latent-dim 4096 \\\n",
    "    --batch_size 32 \\\n",
    "    --num_workers 8 \\\n",
    "    --device cuda\"\"\"\n",
    "    \n",
    "\n",
    "# Parse the arguments\n",
    "args = get_args_parser()\n",
    "args = args.parse_args(call_string.split())\n",
    "\n",
    "# Set device and seed\n",
    "device = torch.device(args.device)\n",
    "misc.set_all_seeds(args.seed)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Instantiate autoencoder\n",
    "ae = s2vs.load_model(args.ae, args.ae_pth, device, torch_compile=True)\n",
    "ae = ae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rec_mesh(ae, points, device):\n",
    "    points = points.to(device)\n",
    "    init_latents = s2vs.encode_pc(ae, points)\n",
    "    return s2vs.decode_latents(ae, d_GPU(init_latents), grid_density=256, batch_size=128**3)\n",
    "\n",
    "def get_datasets(active_class):\n",
    "    shapenet_dataset = ShapeNetDataset(\n",
    "        dataset_folder=\"/ibex/project/c2273/ShapeNet/\",\n",
    "        shape_cls=SHAPENET_NAME_TO_SYNSET[active_class],\n",
    "        pc_size=2048,\n",
    "    )\n",
    "\n",
    "    compat_dataset = CoMPaTSegmentDataset(\n",
    "        \"/ibex/project/c2273/3DCoMPaT/manifold_part_instances/\",\n",
    "        active_class,\n",
    "        2048,\n",
    "        sampling_method=\"surface\",\n",
    "        recenter_mesh=True,\n",
    "        process_mesh=True,\n",
    "        scale_to_shapenet=True,\n",
    "        align_to_shapenet=True,\n",
    "        random_transform=True,\n",
    "        force_retransform=True,\n",
    "    )\n",
    "\n",
    "    compat_transformed_dataset = CoMPaTSegmentDataset(\n",
    "        \"/ibex/project/c2273/3DCoMPaT/manifold_part_instances/\",\n",
    "        active_class,\n",
    "        2048,\n",
    "        sampling_method=\"surface\",\n",
    "        recenter_mesh=True,\n",
    "        process_mesh=True,\n",
    "        scale_to_shapenet=True,\n",
    "        align_to_shapenet=True,\n",
    "        random_transform=False,\n",
    "        force_retransform=True,\n",
    "        random_part_drop=True,\n",
    "        n_parts_to_drop=1,\n",
    "        remove_small_parts=True,\n",
    "        min_part_volume=0.005**3\n",
    "    )\n",
    "    \n",
    "    return shapenet_dataset, compat_dataset, compat_transformed_dataset\n",
    "\n",
    "\n",
    "def get_points(dataset, transform=None, is_compat=False, is_seg=False, obj_k=0):\n",
    "    if is_compat:\n",
    "        if is_seg:\n",
    "            surface_points, _, bbs = next(dataset[obj_k])\n",
    "            return surface_points, bbs\n",
    "        else:\n",
    "            surface_points, _ = next(dataset[obj_k])\n",
    "        return surface_points\n",
    "    else:\n",
    "        surface_points, _ = dataset[obj_k]\n",
    "        return transform(surface_points)\n",
    "\n",
    "\n",
    "def center_mesh(mesh):\n",
    "    \"\"\"\n",
    "    Center the mesh.\n",
    "    \"\"\"\n",
    "    # Recenter the trimesh mesh\n",
    "    center = mesh.bounding_box.centroid\n",
    "    translation_mat = trimesh.transformations.translation_matrix(-center)\n",
    "\n",
    "    # Apply the transformation\n",
    "    return mesh.apply_transform(translation_mat)\n",
    "\n",
    "# Load shape\n",
    "def get_gen(class_name):\n",
    "    class_id = SHAPENET_NAME_TO_SYNSET_INDEX[class_name]\n",
    "    shape_path = \"/ibex/user/slimhy/3DShape2VecSet/class_cond_obj/kl_d512_m512_l8_d24_edm/\"\n",
    "    return center_mesh(trimesh.load(shape_path + \"%02d-00000.obj\" % class_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESH_ID = 5\n",
    "ACTIVE_CLASS = \"chair\"\n",
    "shapenet_dataset, compat_dataset, compat_transformed_dataset = get_datasets(ACTIVE_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compat_points, bbs = get_points(compat_dataset, is_compat=True, is_seg=True, obj_k=MESH_ID)\n",
    "compat_transformed_points, bbs = get_points(compat_transformed_dataset, is_compat=True, is_seg=True, obj_k=MESH_ID)\n",
    "\n",
    "compat_mesh = get_rec_mesh(ae, compat_points, device)\n",
    "compat_transformed_mesh = get_rec_mesh(ae, compat_transformed_points, device)\n",
    "\n",
    "show_side_by_side(compat_mesh, compat_transformed_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import k3d\n",
    "\n",
    "def plot_mesh_bbs(mesh, bbs):\n",
    "    # Use k3d colormaps\n",
    "    unique_parts = np.array(range(len(bbs)))\n",
    "    col_map = k3d.helpers.map_colors(unique_parts, k3d.colormaps.basic_color_maps.Rainbow)\n",
    "    col_map = [int(c) for c in col_map]\n",
    "\n",
    "    # Create the plot\n",
    "    plot = k3d.plot()\n",
    "\n",
    "    plot += k3d.mesh(np.array(mesh.vertices.cpu().numpy()), np.array(mesh.faces.cpu().numpy()), color=0xefefef)\n",
    "    plot += k3d.mesh(mesh.trimesh_mesh.bounding_box_oriented.vertices, mesh.trimesh_mesh.bounding_box_oriented.faces, color=0xefefef, opacity=0.1)\n",
    "    for k, bb in enumerate(bbs):\n",
    "        #Â if k != 0: continue\n",
    "        bb_mesh = bb[1]\n",
    "        # Set color with low alpha\n",
    "        plot += k3d.mesh(bb_mesh.vertices, bb_mesh.faces, color=col_map[k], opacity=0.5)\n",
    "        \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh_bbs(compat_transformed_mesh, bbs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
