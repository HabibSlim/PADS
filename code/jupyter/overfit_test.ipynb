{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibex/user/slimhy/PADS/code\n",
      "Set seed to 0\n",
      "Loading autoencoder ckpt/ae_m512.pth\n"
     ]
    }
   ],
   "source": [
    "%cd /ibex/user/slimhy/PADS/code\n",
    "%reload_ext autoreload\n",
    "\"\"\"\n",
    "Extracting features into HDF5 files for each split.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "import util.misc as misc\n",
    "import models.s2vs as ae_mods\n",
    "\n",
    "\n",
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\"Extracting Features\", add_help=False)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=32,\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU\"\n",
    "        \" (effective batch size is batch_size * accum_iter * # gpus\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--text_model_name\",\n",
    "        type=str,\n",
    "        help=\"Text model name to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of autoencoder\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae-latent-dim\",\n",
    "        type=int,\n",
    "        default=512*8,\n",
    "        help=\"AE latent dimension\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae_pth\",\n",
    "        required=True,\n",
    "        help=\"Autoencoder checkpoint\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--point_cloud_size\",\n",
    "        default=2048,\n",
    "        type=int,\n",
    "        help=\"input size\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fetch_keys\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_embeds\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--intensity_loss\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Contrastive edit intensity loss using ground-truth labels.\",\n",
    "    )\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument(\n",
    "        \"--dataset\",\n",
    "        type=str,\n",
    "        choices=[\"graphedits\"],\n",
    "        help=\"dataset name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        type=str,\n",
    "        help=\"dataset path\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_type\",\n",
    "        type=str,\n",
    "        help=\"dataset type\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_edge_level\",\n",
    "        default=None,\n",
    "        type=int,\n",
    "        help=\"maximum edge level to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\", default=\"cuda\", help=\"device to use for training / testing\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_workers\", default=60, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--pin_mem\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Pin CPU memory in DataLoader for more efficient \"\n",
    "        \"(sometimes) transfer to GPU.\",\n",
    "    )\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "# Set dummy arg string to debug the parser\n",
    "call_string = \"\"\"--ae_pth ckpt/ae_m512.pth \\\n",
    "    --ae kl_d512_m512_l8 \\\n",
    "    --ae-latent-dim 4096 \\\n",
    "    --data_path /ibex/project/c2273/PADS/3DCoMPaT \\\n",
    "    --batch_size 32 \\\n",
    "    --num_workers 8 \\\n",
    "    --device cuda\"\"\"\n",
    "    \n",
    "\n",
    "# Parse the arguments\n",
    "args = get_args_parser()\n",
    "args = args.parse_args(call_string.split())\n",
    "\n",
    "# --------------------\n",
    "device = torch.device(args.device)\n",
    "\n",
    "# Fix the seed for reproducibility\n",
    "misc.set_all_seeds(args.seed)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# --------------------\n",
    "\n",
    "# Instantiate autoencoder\n",
    "ae = ae_mods.__dict__[args.ae]()\n",
    "ae.eval()\n",
    "print(\"Loading autoencoder %s\" % args.ae_pth)\n",
    "ae.load_state_dict(torch.load(args.ae_pth, map_location=\"cpu\")[\"model\"])\n",
    "ae = ae.to(device)\n",
    "\n",
    "# Compile using torch.compile\n",
    "ae = torch.compile(ae, mode=\"max-autotune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.latents import ShapeLatentDataset, ComposedPairedShapesLoader\n",
    "\n",
    "class PairType():\n",
    "    NO_ROT_PAIR = \"rand_no_rot,rand_no_rot\"\n",
    "    PART_DROP = \"part_drop,orig\"\n",
    "\n",
    "# Create your datasets\n",
    "dataset_train = ShapeLatentDataset(args.data_path, split=\"train\", shuffle_parts=True, filter_n_ids=1)\n",
    "dataset_val = ShapeLatentDataset(args.data_path, split=\"test\", shuffle_parts=False, filter_n_ids=1)\n",
    "\n",
    "# Create the DataLoader using the sampler\n",
    "data_loader_train = ComposedPairedShapesLoader(\n",
    "    dataset_train,\n",
    "    batch_size=2,\n",
    "    pair_types_list=[PairType.PART_DROP, PairType.NO_ROT_PAIR],\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    use_distributed=False\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses.partvae import KLRecLoss, ScaleInvariantLoss, PartDropLoss\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def forward_pass(\n",
    "    pvae,\n",
    "    data_tuple,\n",
    "    kl_rec_loss,\n",
    "    scale_inv_loss,\n",
    "    part_drop_loss,\n",
    "    pair_types,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute a single forward pass of the model.\n",
    "    \"\"\"\n",
    "    # Unpack the data tuple\n",
    "    pair_types, (l_a, bb_a, bb_l_a, meta_a), (l_b, bb_b, bb_l_b, meta_b) = data_tuple\n",
    "    device = pvae.device\n",
    "\n",
    "    # Compute the mask from batch labels\n",
    "    mask_a = (bb_l_a != -1).to(device)  # B x 24\n",
    "    mask_b = (bb_l_b != -1).to(device)  # B x 24\n",
    "\n",
    "    l_a, l_b = l_a.to(device), l_b.to(device)  # B x 24 x 512\n",
    "    bb_a, bb_b = bb_a.to(device), bb_b.to(device)  # B x 24 x 4 x 3\n",
    "    bb_l_a, bb_l_b = bb_l_a.to(device), bb_l_b.to(device)  # B x 24\n",
    "    \n",
    "    print(l_a.shape)\n",
    "\n",
    "    # Optionally compute the KL Reg loss\n",
    "    if pvae.is_vae:\n",
    "        logits_a, kl_a, part_latents_a = pvae(\n",
    "            latents=l_a, part_bbs=bb_a, part_labels=bb_l_a, batch_mask=mask_a\n",
    "        )\n",
    "        logits_b, kl_b, part_latents_b = pvae(\n",
    "            latents=l_b, part_bbs=bb_b, part_labels=bb_l_b, batch_mask=mask_b\n",
    "        )\n",
    "\n",
    "        # KL Reg loss\n",
    "        kl_reg = kl_rec_loss(kl_a, mask=mask_a) + kl_rec_loss(kl_b, mask=mask_b)\n",
    "        kl_reg /= 2.0\n",
    "    else:\n",
    "        logits_a, part_latents_a = pvae(\n",
    "            latents=l_a, part_bbs=bb_a, part_labels=bb_l_a, batch_mask=mask_a\n",
    "        )\n",
    "        logits_b, part_latents_b = pvae(\n",
    "            latents=l_b, part_bbs=bb_b, part_labels=bb_l_b, batch_mask=mask_b\n",
    "        )\n",
    "        kl_reg = torch.tensor(0.0).to(device)\n",
    "\n",
    "    # L2 loss\n",
    "    rec_loss = F.mse_loss(logits_a, l_a) + F.mse_loss(logits_b, l_b)\n",
    "    rec_loss /= 2.0\n",
    "\n",
    "    if pair_types == PairType.NO_ROT_PAIR:\n",
    "        inv_loss = scale_inv_loss(part_latents_a, part_latents_b, mask_a)\n",
    "    elif pair_types == PairType.PART_DROP:\n",
    "        inv_loss = part_drop_loss(\n",
    "            part_latents_a, part_latents_b, bb_a, bb_b, mask_a, mask_b\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"kl_reg\": kl_reg,\n",
    "        \"rec_loss\": rec_loss,\n",
    "        \"inv_loss\": inv_loss,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "  [  0/300]  eta: 0:02:47  train_loss: 0.7355 (0.7537)  kl_reg: 0.0000 (0.0000)  rec_loss: 0.9194 (0.9421)  inv_loss: 0.0008 (0.0015)  time: 0.5593  data: 0.0000  max mem: 596\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "  [ 10/300]  eta: 0:00:21  train_loss: 0.7595 (0.7525)  kl_reg: 0.0000 (0.0000)  rec_loss: 0.9493 (0.9406)  inv_loss: 0.0017 (0.0019)  time: 0.0734  data: 0.0000  max mem: 596\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "  [ 20/300]  eta: 0:00:13  train_loss: 0.7595 (0.7516)  kl_reg: 0.0000 (0.0000)  rec_loss: 0.9493 (0.9395)  inv_loss: 0.0020 (0.0020)  time: 0.0237  data: 0.0000  max mem: 596\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "  [ 30/300]  eta: 0:00:11  train_loss: 0.7595 (0.7543)  kl_reg: 0.0000 (0.0000)  rec_loss: 0.9493 (0.9429)  inv_loss: 0.0022 (0.0019)  time: 0.0250  data: 0.0000  max mem: 596\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "  [ 40/300]  eta: 0:00:09  train_loss: 0.7595 (0.7559)  kl_reg: 0.0000 (0.0000)  rec_loss: 0.9493 (0.9449)  inv_loss: 0.0020 (0.0020)  time: 0.0261  data: 0.0000  max mem: 596\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "  [ 50/300]  eta: 0:00:08  train_loss: 0.7566 (0.7542)  kl_reg: 0.0000 (0.0000)  rec_loss: 0.9458 (0.9428)  inv_loss: 0.0018 (0.0020)  time: 0.0235  data: 0.0000  max mem: 596\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "  [ 60/300]  eta: 0:00:08  train_loss: 0.7411 (0.7519)  kl_reg: 0.0000 (0.0000)  rec_loss: 0.9264 (0.9399)  inv_loss: 0.0017 (0.0019)  time: 0.0247  data: 0.0000  max mem: 596\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "  [ 70/300]  eta: 0:00:07  train_loss: 0.7548 (0.7522)  kl_reg: 0.0000 (0.0000)  rec_loss: 0.9435 (0.9403)  inv_loss: 0.0015 (0.0019)  time: 0.0259  data: 0.0000  max mem: 596\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "  [ 80/300]  eta: 0:00:06  train_loss: 0.7595 (0.7520)  kl_reg: 0.0000 (0.0000)  rec_loss: 0.9493 (0.9400)  inv_loss: 0.0015 (0.0019)  time: 0.0234  data: 0.0000  max mem: 596\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "  [ 90/300]  eta: 0:00:06  train_loss: 0.7595 (0.7518)  kl_reg: 0.0000 (0.0000)  rec_loss: 0.9493 (0.9398)  inv_loss: 0.0018 (0.0019)  time: 0.0246  data: 0.0000  max mem: 596\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "  [100/300]  eta: 0:00:06  train_loss: 0.7574 (0.7510)  kl_reg: 0.0000 (0.0000)  rec_loss: 0.9468 (0.9388)  inv_loss: 0.0018 (0.0019)  time: 0.0258  data: 0.0000  max mem: 596\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "torch.Size([1, 512, 8])\n",
      "  [110/300]  eta: 0:00:05  train_loss: 0.7588 (0.7517)  kl_reg: 0.0000 (0.0000)  rec_loss: 0.9485 (0.9397)  inv_loss: 0.0017 (0.0019)  time: 0.0233  data: 0.0000  max mem: 596\n",
      "torch.Size([1, 512, 8])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 45\u001b[0m\n\u001b[1;32m     41\u001b[0m kl_loss, scale_inv_loss, part_drop_loss \u001b[38;5;241m=\u001b[39m get_losses()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_step, data_tuple \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader_train):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Computing loss\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpvae\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpvae\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkl_rec_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkl_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale_inv_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale_inv_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpart_drop_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpart_drop_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpair_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPairType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPART_DROP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;241m0.005\u001b[39m \u001b[38;5;241m*\u001b[39m loss[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkl_reg\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m loss[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrec_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.\u001b[39m \u001b[38;5;241m*\u001b[39m loss[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minv_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 43\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(pvae, data_tuple, kl_rec_loss, scale_inv_loss, part_drop_loss, pair_types)\u001b[0m\n\u001b[1;32m     41\u001b[0m     kl_reg \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     logits_a, part_latents_a \u001b[38;5;241m=\u001b[39m \u001b[43mpvae\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart_bbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbb_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbb_l_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_a\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     logits_b, part_latents_b \u001b[38;5;241m=\u001b[39m pvae(\n\u001b[1;32m     47\u001b[0m         latents\u001b[38;5;241m=\u001b[39ml_b, part_bbs\u001b[38;5;241m=\u001b[39mbb_b, part_labels\u001b[38;5;241m=\u001b[39mbb_l_b, batch_mask\u001b[38;5;241m=\u001b[39mmask_b\n\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m     kl_reg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/conda/envs/3D2VS_flexicubes/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/ibex/user/slimhy/PADS/code/models/partvae.py:165\u001b[0m, in \u001b[0;36mPartAwareAE.forward\u001b[0;34m(self, latents, part_bbs, part_labels, batch_mask)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, latents, part_bbs, part_labels, batch_mask):\n\u001b[1;32m    162\u001b[0m     part_latents, bb_coord_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(\n\u001b[1;32m    163\u001b[0m         latents, part_bbs, part_labels, batch_mask\n\u001b[1;32m    164\u001b[0m     )\n\u001b[0;32m--> 165\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart_latents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbb_coord_embeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits, part_latents\n",
      "File \u001b[0;32m/ibex/user/slimhy/PADS/code/models/partvae.py:147\u001b[0m, in \u001b[0;36mPartAwareAE.decode\u001b[0;34m(self, part_latents, bb_coord_embeds, batch_mask)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, part_latents, bb_coord_embeds, batch_mask):\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# Expand latents to full dimension\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_latents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart_latents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     bb_coord_embeds_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbb_coord_proj_out(bb_coord_embeds)\n\u001b[1;32m    149\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_decode(x, context\u001b[38;5;241m=\u001b[39mbb_coord_embeds_proj, mask\u001b[38;5;241m=\u001b[39mbatch_mask)\n",
      "File \u001b[0;32m~/conda/envs/3D2VS_flexicubes/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda/envs/3D2VS_flexicubes/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/conda/envs/3D2VS_flexicubes/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/ibex/user/slimhy/PADS/code/models/modules.py:36\u001b[0m, in \u001b[0;36mGEGLU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 36\u001b[0m     x, gates \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m*\u001b[39m F\u001b[38;5;241m.\u001b[39mgelu(gates)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from schedulefree import AdamWScheduleFree\n",
    "from models.partvae import PartAwareVAE, PartAwareAE\n",
    "\n",
    "\n",
    "def get_losses():\n",
    "    \"\"\"\n",
    "    Instantiate the losses.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        KLRecLoss(),\n",
    "        ScaleInvariantLoss(),\n",
    "        PartDropLoss(),\n",
    "    )\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "pvae = PartAwareAE(\n",
    "    dim=512,\n",
    "    latent_dim=128,\n",
    "    heads=8,\n",
    "    dim_head=64,\n",
    "    depth=2,\n",
    ").to(device)\n",
    "pvae = pvae.to(device)\n",
    "\n",
    "pvae.train(True)\n",
    "\n",
    "metric_logger = misc.MetricLogger(delimiter=\"  \")\n",
    "for epoch in enumerate(\n",
    "    metric_logger.log_every(range(300), 10)\n",
    "):\n",
    "    # Reset the metric logger\n",
    "    # metric_logger.reset()\n",
    "    # Initialize the optimizer\n",
    "    optimizer = AdamWScheduleFree(\n",
    "        pvae.parameters(), lr=1e-3, weight_decay=1e-5\n",
    "    )\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Instantiate the losses\n",
    "    kl_loss, scale_inv_loss, part_drop_loss = get_losses()\n",
    "\n",
    "    for data_step, data_tuple in enumerate(data_loader_train):\n",
    "        # Computing loss\n",
    "        loss = forward_pass(\n",
    "            pvae=pvae,\n",
    "            data_tuple=data_tuple,\n",
    "            kl_rec_loss=kl_loss,\n",
    "            scale_inv_loss=scale_inv_loss,\n",
    "            part_drop_loss=part_drop_loss,\n",
    "            pair_types=PairType.PART_DROP,\n",
    "        )\n",
    "        total_loss = (\n",
    "            0.005 * loss[\"kl_reg\"]\n",
    "            + 0.8 * loss[\"rec_loss\"]\n",
    "            + 0. * loss[\"inv_loss\"]\n",
    "        )\n",
    "\n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        # Log the losses\n",
    "        loss_update = {\n",
    "            \"train_loss\": float(total_loss.item()),\n",
    "            \"kl_reg\": float(loss[\"kl_reg\"].item()),\n",
    "            \"rec_loss\": float(loss[\"rec_loss\"].item()),\n",
    "            \"inv_loss\": float(loss[\"inv_loss\"].item()),\n",
    "        }\n",
    "        metric_logger.update(**loss_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_linear_assignment import batch_linear_assignment\n",
    "\n",
    "\n",
    "def debug_rec_loss(x, x_rec):\n",
    "    \"\"\"\n",
    "    Call the loss function.\n",
    "    \"\"\"\n",
    "    B, D, N = (\n",
    "        x.shape\n",
    "    )  # B: batch size, D: latent dimension (512), N: number of vectors (8)\n",
    "\n",
    "    # Reshape x and x_rec to (B, N, D) for easier processing\n",
    "    # x = set_a.transpose(1, 2)\n",
    "    # x_rec = set_b.transpose(1, 2)\n",
    "\n",
    "    # Compute the cost matrix using cdist\n",
    "    cost_matrix = torch.cdist(x, x_rec)\n",
    "\n",
    "    # Compute the linear assignment\n",
    "    assignment = batch_linear_assignment(cost_matrix)\n",
    "\n",
    "    # Compute the loss\n",
    "    total_loss = 0\n",
    "    for b in range(B):\n",
    "        x_matched = x[b, assignment[b, 0]]\n",
    "        x_rec_matched = x_rec[b, assignment[b, 1]]\n",
    "        loss = F.mse_loss(x_matched, x_rec_matched)\n",
    "        total_loss += loss\n",
    "\n",
    "    return total_loss / B\n",
    "\n",
    "# Define two sets of vectors\n",
    "B = 32\n",
    "set_A = torch.tensor([\n",
    "    [0, 0, 0, 0],\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 2, 2, 2],\n",
    "]).repeat(B, 1, 1).type(torch.float32)\n",
    "\n",
    "set_B = torch.tensor([\n",
    "    [0, 0, 0, 0],\n",
    "    [1, 1, 1, 1],\n",
    "    [2, 2, 2, 2],\n",
    "]).repeat(B, 1, 1).type(torch.float32)\n",
    "\n",
    "\n",
    "print(set_A.shape, set_B.shape)\n",
    "\n",
    "debug_loss(set_A, set_B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
