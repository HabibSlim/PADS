{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibex/user/slimhy/Shape2VecSet/code\n",
      "Jitting Chamfer 3D\n",
      "Loaded JIT 3D CUDA chamfer distance\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Chained evaluation of the models.\n",
    "\"\"\"\n",
    "%cd ..\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import util.misc as misc\n",
    "from util.misc import MetricLogger\n",
    "from util.datasets import build_shape_surface_occupancy_dataset\n",
    "\n",
    "import models.mlp_mapper as mlp_mapper\n",
    "\n",
    "from losses.chamfer import chamfer_loss\n",
    "\n",
    "# Silence torch warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\"Performing Chained Eval\", add_help=False)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=32,\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU\"\n",
    "        \"(effective batch size is batch_size * accum_iter * # gpus\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--text_model_name\",\n",
    "        type=str,\n",
    "        help=\"Text model name to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "        help=\"Name of autoencoder\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ae-latent-dim\",\n",
    "        type=int,\n",
    "        default=512 * 8,\n",
    "        help=\"AE latent dimension\",\n",
    "    )\n",
    "    parser.add_argument(\"--ae_pth\", help=\"Autoencoder checkpoint\")\n",
    "    parser.add_argument(\"--point_cloud_size\", default=2048, type=int, help=\"input size\")\n",
    "    parser.add_argument(\n",
    "        \"--fetch_keys\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_clip\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_embeds\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--intensity_loss\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Contrastive edit intensity loss using ground-truth labels.\",\n",
    "    )\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument(\n",
    "        \"--dataset\",\n",
    "        type=str,\n",
    "        choices=[\"graphedits\", \"graphedits_chained\"],\n",
    "        help=\"dataset name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        type=str,\n",
    "        help=\"dataset path\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_type\",\n",
    "        type=str,\n",
    "        help=\"dataset type\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_edge_level\",\n",
    "        default=None,\n",
    "        type=int,\n",
    "        help=\"maximum edge level to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--chain_length\",\n",
    "        default=None,\n",
    "        type=int,\n",
    "        help=\"length of chains to load\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\", default=\"cuda\", help=\"device to use for training / testing\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_workers\", default=60, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--pin_mem\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--alt_ae_embeds\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"Alternative autoencoder embeddings to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ft_bert\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Also fine-tune the BERT model\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model\",\n",
    "        type=str,\n",
    "        metavar=\"MODEL\",\n",
    "    )\n",
    "    parser.add_argument(\"--resume\", default=\"\", help=\"Resume from checkpoint\")\n",
    "    parser.add_argument(\n",
    "        \"--resume_full_weights\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Resume the full model weights with the EDM wrapper\",\n",
    "    )\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_header = \"\"\"\n",
    "\\\\begin{tabular}{@{}lcccccccccccccccccccccccccc@{}}\n",
    "    \\\\toprule\n",
    "    \\multicolumn{1}{c}{\\multirow{2}{*}{\\\\textbf{Model}}} & \\multicolumn{1}{c}{\\multirow{2}{*}{decoupled?}}\n",
    "    &  & \\multicolumn{6}{c}{$|\\mathcal{P}|$ = 10}\n",
    "    &  & \\multicolumn{6}{c}{$|\\mathcal{P}|$ = 15}\n",
    "    &  & \\multicolumn{6}{c}{$|\\mathcal{P}|$ = 20} \\\\\\\\ \\cmidrule(l){4-23}\n",
    "    \\multicolumn{1}{c}{}  & \\multicolumn{1}{c}{}\n",
    "    &\n",
    "    & $\\\\textsc{F}_{\\\\textsc{CD} - \\\\textsc{Rec}}$\n",
    "    & \\multicolumn{1}{c}{$\\\\textsc{A}_{\\\\textsc{CD} - \\\\textsc{Rec}}$}\n",
    "    & $\\\\textsc{F}_{\\\\textsc{CD} - \\\\textsc{Real}}$\n",
    "    & \\multicolumn{1}{c}{$\\\\textsc{A}_{\\\\textsc{CD} - \\\\textsc{Real}}$}\n",
    "    & \\multicolumn{1}{c}{$\\\\textsc{F}_{\\mathcal{L}_2}$}\n",
    "    & \\multicolumn{1}{c}{$\\\\textsc{A}_{\\mathcal{L}_2}$}\n",
    "    &\n",
    "    & $\\\\textsc{F}_{\\\\textsc{CD} - \\\\textsc{Rec}}$\n",
    "    & \\multicolumn{1}{c}{$\\\\textsc{A}_{\\\\textsc{CD} - \\\\textsc{Rec}}$}\n",
    "    & $\\\\textsc{F}_{\\\\textsc{CD} - \\\\textsc{Real}}$\n",
    "    & \\multicolumn{1}{c}{$\\\\textsc{A}_{\\\\textsc{CD} - \\\\textsc{Real}}$}\n",
    "    & \\multicolumn{1}{c}{$\\\\textsc{F}_{\\mathcal{L}_2}$}\n",
    "    & \\multicolumn{1}{c}{$\\\\textsc{A}_{\\mathcal{L}_2}$}\n",
    "    &\n",
    "    & $\\\\textsc{F}_{\\\\textsc{CD} - \\\\textsc{Rec}}$\n",
    "    & \\multicolumn{1}{c}{$\\\\textsc{A}_{\\\\textsc{CD} - \\\\textsc{Rec}}$}\n",
    "    & $\\\\textsc{F}_{\\\\textsc{CD} - \\\\textsc{Real}}$\n",
    "    & \\multicolumn{1}{c}{$\\\\textsc{A}_{\\\\textsc{CD} - \\\\textsc{Real}}$}\n",
    "    & \\multicolumn{1}{c}{$\\\\textsc{F}_{\\mathcal{L}_2}$}\n",
    "    & \\multicolumn{1}{c}{$\\\\textsc{A}_{\\mathcal{L}_2}$} \\\\\\\\ \\midrule\n",
    "\"\"\"\n",
    "table_entry = \"    & & %0.3f & \\multicolumn{1}{c}{%0.3f} & \\multicolumn{1}{c}{%0.3f} & \\multicolumn{1}{c}{%0.3f} & \\multicolumn{1}{c}{%0.3f} & \\multicolumn{1}{c}{%0.3f}\"\n",
    "table_sep = \"\\\\arrayrulecolor{black!30}\\midrule\\\\arrayrulecolor{black!100}\"\n",
    "table_footer = \"\"\"\n",
    "    \\\\bottomrule\n",
    "\\end{tabular}%\n",
    "\"\"\"\n",
    "table_is_decoupled = \"& \\multicolumn{1}{c}{\\%s}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforms import get_pc_ae_transform\n",
    "from eval.chain_sampler import ChainSampler\n",
    "from eval.metrics import l2_dist, chamfer_reconstructed, chamfer_real\n",
    "\n",
    "\n",
    "def init_exps(model_name, model_path, ae_model):\n",
    "    \"\"\"\n",
    "    Initialize the latent space mapper and args.\n",
    "    \"\"\"\n",
    "    # Set dummy arg string to debug the parser\n",
    "    call_string = \"\"\"--ae-latent-dim 256 \\\n",
    "        --text_model_name bert-base-uncased \\\n",
    "        --dataset graphedits_chained \\\n",
    "        --data_path /ibex/user/slimhy/ShapeWalk/ \\\n",
    "        --data_type release_chained \\\n",
    "        --num_workers 8 \\\n",
    "        --model %s \\\n",
    "        --resume %s \\\n",
    "        --resume_full_weights \\\n",
    "        --device cuda \\\n",
    "        --fetch_keys \\\n",
    "        --use_embeds \\\n",
    "        --alt_ae_embeds %s \\\n",
    "        --seed 0\"\"\" % (model_name, model_path, ae_model)\n",
    "\n",
    "    # Parse the arguments\n",
    "    args = get_args_parser()\n",
    "    args = args.parse_args(call_string.split())\n",
    "    args.use_clip = \"clip\" in args.text_model_name\n",
    "    device = torch.device(args.device)\n",
    "\n",
    "    model = mlp_mapper.__dict__[args.model](use_linear_proj=not args.use_clip)\n",
    "    model.to(device)\n",
    "\n",
    "    # Load the checkpoint\n",
    "    if args.resume:\n",
    "        checkpoint = torch.load(args.resume, map_location=\"cpu\")\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "\n",
    "    return args, model, device\n",
    "\n",
    "\n",
    "def get_loader(args, batch_size, chain_length):\n",
    "    \"\"\"\n",
    "    Get the data loader for chained evaluation.\n",
    "    \"\"\"\n",
    "    args.batch_size = batch_size\n",
    "    args.chain_length = chain_length\n",
    "\n",
    "    dataset_val = build_shape_surface_occupancy_dataset(\"val\", args=args)\n",
    "    chain_sampler = ChainSampler(\n",
    "        dataset_val, batch_size=args.batch_size, chain_length=args.chain_length\n",
    "    )\n",
    "    data_loader_val = torch.utils.data.DataLoader(\n",
    "        dataset_val,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        sampler=chain_sampler,\n",
    "    )\n",
    "\n",
    "    return data_loader_val\n",
    "\n",
    "\n",
    "def apply_edit(net, x_a, embed_ab):\n",
    "    \"\"\"\n",
    "    Apply the edit to the latent vector.\n",
    "    \"\"\"\n",
    "    # Reshape from (B, D, K) to (B, M)\n",
    "    x_a = x_a.flatten(1)\n",
    "    embed_ab = embed_ab.flatten(1)\n",
    "\n",
    "    # Concatenate the latent vector with the embedding\n",
    "    edit_vec = net(x_a, embed_ab)\n",
    "\n",
    "    # Add the edit vector to the latent vector\n",
    "    return edit_vec + x_a\n",
    "\n",
    "\n",
    "def apply_iterated_edits(model, ae_model, embeds_a, embeds_b, embeds_text):\n",
    "    \"\"\"\n",
    "    Apply the edits iteratively.\n",
    "    \"\"\"\n",
    "    # Move all the garbage to CUDA\n",
    "    embeds_a = embeds_a.cuda()\n",
    "    embeds_b = embeds_b.cuda()\n",
    "    embeds_text = embeds_text.cuda()\n",
    "\n",
    "    x_b_edited = apply_edit(model, embeds_a, embeds_text)\n",
    "    x_b = embeds_b\n",
    "    x_a = embeds_a\n",
    "\n",
    "    # Decode the batch\n",
    "    b_size = x_b.shape[0]\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        orig = ae_model.decoder(x_a).reshape([b_size, 4096, 3])\n",
    "        rec = ae_model.decoder(x_b_edited).reshape([b_size, 4096, 3])\n",
    "        rec_gt = ae_model.decoder(x_b).reshape([b_size, 4096, 3])\n",
    "\n",
    "    return (orig, rec, rec_gt), (x_a, x_b_edited, x_b)\n",
    "\n",
    "\n",
    "def get_metrics(args, model, ae_model, data_loader, drop_n, pc_t):\n",
    "    \"\"\"\n",
    "    Get the metrics for chained evaluation.\n",
    "    \"\"\"\n",
    "    metric_meter = MetricLogger()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        chain_count = 0\n",
    "        for batch_k, (chain_ids, edit_keys, node_a, node_b, text_embeds) in enumerate(\n",
    "            data_loader\n",
    "        ):\n",
    "            if batch_k == len(data_loader) - 1 - drop_n:\n",
    "                break\n",
    "            if chain_count == 0:\n",
    "                prev_node = node_a\n",
    "\n",
    "            # Apply the edits\n",
    "            (p_a, p_b_pred, p_b), (x_a, x_b_pred, x_b) = apply_iterated_edits(\n",
    "                model,\n",
    "                ae_model,\n",
    "                embeds_a=prev_node,\n",
    "                embeds_b=node_b,\n",
    "                embeds_text=text_embeds,\n",
    "            )\n",
    "\n",
    "            # Compute average pairwise L2 distance in feature space\n",
    "            l2_distance = l2_dist(x_b, x_b_pred)\n",
    "\n",
    "            # Compute average pairwise reconstructed CD\n",
    "            cd_dist_reco = chamfer_reconstructed(p_b, p_b_pred)\n",
    "\n",
    "            # Compute average pairwise real CD\n",
    "            cd_dist_real = chamfer_real(\n",
    "                p_edited=p_b_pred,\n",
    "                node_gt=edit_keys,\n",
    "                transform=pc_t,\n",
    "                data_path=args.data_path,\n",
    "                n_samples=12,\n",
    "            )\n",
    "\n",
    "            # Log all metrics\n",
    "            metric_meter.update(\n",
    "                avg_l2_dist=l2_distance.item(),\n",
    "                avg_cd_dist_reco=cd_dist_reco.item(),\n",
    "                avg_cd_dist_real=cd_dist_real.item(),\n",
    "            )\n",
    "\n",
    "            prev_node = x_b_pred\n",
    "\n",
    "            # Log final chain metrics\n",
    "            chain_count += 1\n",
    "            if chain_count == args.chain_length:\n",
    "                metric_meter.update(\n",
    "                    final_l2_dist=l2_distance.item(),\n",
    "                    final_cd_dist_reco=cd_dist_reco.item(),\n",
    "                    final_cd_dist_real=cd_dist_real.item(),\n",
    "                )\n",
    "                chain_count = 0\n",
    "\n",
    "    return metric_meter\n",
    "\n",
    "\n",
    "def run_exps(args, model, ae_model, device):\n",
    "    \"\"\"\n",
    "    Run the chained evaluations for different chain lengths.\n",
    "    \"\"\"\n",
    "    # Fix the seed for reproducibility\n",
    "    seed = args.seed + misc.get_rank()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    args.fetch_keys = True\n",
    "\n",
    "    # Get the point cloud transform\n",
    "    pc_t = get_pc_ae_transform(args)\n",
    "    # --------------------\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = model.eval()\n",
    "\n",
    "    all_metrics = {\n",
    "        \"final_cd_dist_reco\": [],\n",
    "        \"avg_cd_dist_reco\": [],\n",
    "        \"final_cd_dist_real\": [],\n",
    "        \"avg_cd_dist_real\": [],\n",
    "        \"final_l2_dist\": [],\n",
    "        \"avg_l2_dist\": [],\n",
    "    }\n",
    "    for chain_length, batch_size, drop_n in [[10, 8, 0], [15, 4, 3], [20, 3, 0]]:\n",
    "        data_loader_val = get_loader(\n",
    "            args, batch_size=batch_size, chain_length=chain_length\n",
    "        )\n",
    "        metric_meter = get_metrics(args, model, ae_model, data_loader_val, drop_n, pc_t)\n",
    "\n",
    "        # Print the results\n",
    "        for k, v in metric_meter.meters.items():\n",
    "            if \"cd\" in k:\n",
    "                all_metrics[k].append(v.global_avg * 10**4)\n",
    "            else:\n",
    "                all_metrics[k].append(v.global_avg)\n",
    "\n",
    "        # print(table_entry % (final_cd_dist, avg_cd_dist, final_l2_dist, avg_l2_dist))\n",
    "        print(table_entry % tuple(all_metrics[k][-1] for k in all_metrics.keys()))\n",
    "\n",
    "    full_results = { k: np.mean(v) for k, v in all_metrics.items() }\n",
    "    return full_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{tabular}{@{}lcccccccccccccccccccccccccc@{}}\n",
      "    \\toprule\n",
      "    \\multicolumn{1}{c}{\\multirow{2}{*}{\\textbf{Model}}} & \\multicolumn{1}{c}{\\multirow{2}{*}{decoupled?}}\n",
      "    &  & \\multicolumn{6}{c}{$|\\mathcal{P}|$ = 10}\n",
      "    &  & \\multicolumn{6}{c}{$|\\mathcal{P}|$ = 15}\n",
      "    &  & \\multicolumn{6}{c}{$|\\mathcal{P}|$ = 20} \\\\ \\cmidrule(l){4-23}\n",
      "    \\multicolumn{1}{c}{}  & \\multicolumn{1}{c}{}\n",
      "    &\n",
      "    & $\\textsc{F}_{\\textsc{CD} - \\textsc{Rec}}$\n",
      "    & \\multicolumn{1}{c}{$\\textsc{A}_{\\textsc{CD} - \\textsc{Rec}}$}\n",
      "    & $\\textsc{F}_{\\textsc{CD} - \\textsc{Real}}$\n",
      "    & \\multicolumn{1}{c}{$\\textsc{A}_{\\textsc{CD} - \\textsc{Real}}$}\n",
      "    & \\multicolumn{1}{c}{$\\textsc{F}_{\\mathcal{L}_2}$}\n",
      "    & \\multicolumn{1}{c}{$\\textsc{A}_{\\mathcal{L}_2}$}\n",
      "    &\n",
      "    & $\\textsc{F}_{\\textsc{CD} - \\textsc{Rec}}$\n",
      "    & \\multicolumn{1}{c}{$\\textsc{A}_{\\textsc{CD} - \\textsc{Rec}}$}\n",
      "    & $\\textsc{F}_{\\textsc{CD} - \\textsc{Real}}$\n",
      "    & \\multicolumn{1}{c}{$\\textsc{A}_{\\textsc{CD} - \\textsc{Real}}$}\n",
      "    & \\multicolumn{1}{c}{$\\textsc{F}_{\\mathcal{L}_2}$}\n",
      "    & \\multicolumn{1}{c}{$\\textsc{A}_{\\mathcal{L}_2}$}\n",
      "    &\n",
      "    & $\\textsc{F}_{\\textsc{CD} - \\textsc{Rec}}$\n",
      "    & \\multicolumn{1}{c}{$\\textsc{A}_{\\textsc{CD} - \\textsc{Rec}}$}\n",
      "    & $\\textsc{F}_{\\textsc{CD} - \\textsc{Real}}$\n",
      "    & \\multicolumn{1}{c}{$\\textsc{A}_{\\textsc{CD} - \\textsc{Real}}$}\n",
      "    & \\multicolumn{1}{c}{$\\textsc{F}_{\\mathcal{L}_2}$}\n",
      "    & \\multicolumn{1}{c}{$\\textsc{A}_{\\mathcal{L}_2}$} \\\\ \\midrule\n",
      "\n",
      "$\\textsc{DirectGen}_{\\textsc{Linear}}$\n",
      "& \\multicolumn{1}{c}{\\icono}\n",
      "    & & 3.120 & \\multicolumn{1}{c}{2.434} & \\multicolumn{1}{c}{4.568} & \\multicolumn{1}{c}{3.966} & \\multicolumn{1}{c}{2.969} & \\multicolumn{1}{c}{2.498}\n",
      "    & & 3.662 & \\multicolumn{1}{c}{3.103} & \\multicolumn{1}{c}{4.190} & \\multicolumn{1}{c}{4.638} & \\multicolumn{1}{c}{1.923} & \\multicolumn{1}{c}{1.747}\n",
      "    & & 2.637 & \\multicolumn{1}{c}{1.954} & \\multicolumn{1}{c}{3.405} & \\multicolumn{1}{c}{3.096} & \\multicolumn{1}{c}{1.556} & \\multicolumn{1}{c}{1.212}\n",
      "\\\\\n",
      "\n",
      "\\arrayrulecolor{black!30}\\midrule\\arrayrulecolor{black!100}\n",
      "\n",
      "$\\textsc{LateFusion}_{1024}$\n",
      "& \\multicolumn{1}{c}{\\icono}\n",
      "    & & 1.751 & \\multicolumn{1}{c}{1.431} & \\multicolumn{1}{c}{2.922} & \\multicolumn{1}{c}{2.688} & \\multicolumn{1}{c}{1.913} & \\multicolumn{1}{c}{1.707}\n",
      "    & & 2.150 & \\multicolumn{1}{c}{1.579} & \\multicolumn{1}{c}{2.900} & \\multicolumn{1}{c}{2.854} & \\multicolumn{1}{c}{1.366} & \\multicolumn{1}{c}{1.241}\n",
      "    & & 1.591 & \\multicolumn{1}{c}{0.944} & \\multicolumn{1}{c}{2.470} & \\multicolumn{1}{c}{2.136} & \\multicolumn{1}{c}{1.054} & \\multicolumn{1}{c}{0.805}\n",
      "\\\\\n",
      "\n",
      "$\\textsc{LateFusion}_{512}$\n",
      "& \\multicolumn{1}{c}{\\icono}\n",
      "    & & 1.802 & \\multicolumn{1}{c}{1.413} & \\multicolumn{1}{c}{2.957} & \\multicolumn{1}{c}{2.733} & \\multicolumn{1}{c}{2.018} & \\multicolumn{1}{c}{1.770}\n",
      "    & & 1.804 & \\multicolumn{1}{c}{1.469} & \\multicolumn{1}{c}{2.774} & \\multicolumn{1}{c}{2.685} & \\multicolumn{1}{c}{1.309} & \\multicolumn{1}{c}{1.221}\n",
      "    & & 1.414 & \\multicolumn{1}{c}{1.005} & \\multicolumn{1}{c}{2.241} & \\multicolumn{1}{c}{2.225} & \\multicolumn{1}{c}{1.059} & \\multicolumn{1}{c}{0.880}\n",
      "\\\\\n",
      "\n",
      "$\\textsc{LateFusion}_{256}$\n",
      "& \\multicolumn{1}{c}{\\icono}\n",
      "    & & 1.807 & \\multicolumn{1}{c}{1.486} & \\multicolumn{1}{c}{2.960} & \\multicolumn{1}{c}{2.862} & \\multicolumn{1}{c}{2.079} & \\multicolumn{1}{c}{1.810}\n",
      "    & & 2.034 & \\multicolumn{1}{c}{1.380} & \\multicolumn{1}{c}{2.832} & \\multicolumn{1}{c}{2.652} & \\multicolumn{1}{c}{1.342} & \\multicolumn{1}{c}{1.203}\n",
      "    & & 1.737 & \\multicolumn{1}{c}{1.018} & \\multicolumn{1}{c}{2.633} & \\multicolumn{1}{c}{2.259} & \\multicolumn{1}{c}{1.106} & \\multicolumn{1}{c}{0.838}\n",
      "\\\\\n",
      "\n",
      "$\\textsc{Ours}_{512 \\times 8}$\n",
      "& \\multicolumn{1}{c}{\\icono}\n",
      "    & & 2.240 & \\multicolumn{1}{c}{1.665} & \\multicolumn{1}{c}{3.576} & \\multicolumn{1}{c}{3.091} & \\multicolumn{1}{c}{2.311} & \\multicolumn{1}{c}{2.022}\n",
      "    & & 2.471 & \\multicolumn{1}{c}{1.664} & \\multicolumn{1}{c}{3.329} & \\multicolumn{1}{c}{2.887} & \\multicolumn{1}{c}{1.591} & \\multicolumn{1}{c}{1.351}\n",
      "    & & 1.571 & \\multicolumn{1}{c}{0.992} & \\multicolumn{1}{c}{2.489} & \\multicolumn{1}{c}{2.284} & \\multicolumn{1}{c}{1.207} & \\multicolumn{1}{c}{0.937}\n",
      "\\\\\n",
      "\n",
      "$\\textsc{Ours}_{512 \\times 4}$\n",
      "& \\multicolumn{1}{c}{\\icono}\n",
      "    & & 1.751 & \\multicolumn{1}{c}{1.494} & \\multicolumn{1}{c}{3.130} & \\multicolumn{1}{c}{2.782} & \\multicolumn{1}{c}{2.168} & \\multicolumn{1}{c}{1.884}\n",
      "    & & 2.378 & \\multicolumn{1}{c}{1.540} & \\multicolumn{1}{c}{3.069} & \\multicolumn{1}{c}{2.782} & \\multicolumn{1}{c}{1.432} & \\multicolumn{1}{c}{1.271}\n",
      "    & & 1.659 & \\multicolumn{1}{c}{1.087} & \\multicolumn{1}{c}{2.496} & \\multicolumn{1}{c}{2.347} & \\multicolumn{1}{c}{1.166} & \\multicolumn{1}{c}{0.898}\n",
      "\\\\\n",
      "\n",
      "\\arrayrulecolor{black!30}\\midrule\\arrayrulecolor{black!100}\n",
      "\n",
      "$\\textsc{LateFusion}_{1024}$\n",
      "& \\multicolumn{1}{c}{\\icoyes}\n",
      "    & & 1.773 & \\multicolumn{1}{c}{1.452} & \\multicolumn{1}{c}{2.995} & \\multicolumn{1}{c}{2.722} & \\multicolumn{1}{c}{2.002} & \\multicolumn{1}{c}{1.734}\n",
      "    & & 1.704 & \\multicolumn{1}{c}{1.290} & \\multicolumn{1}{c}{2.738} & \\multicolumn{1}{c}{2.598} & \\multicolumn{1}{c}{1.212} & \\multicolumn{1}{c}{1.184}\n",
      "    & & 1.502 & \\multicolumn{1}{c}{1.049} & \\multicolumn{1}{c}{2.183} & \\multicolumn{1}{c}{2.193} & \\multicolumn{1}{c}{0.999} & \\multicolumn{1}{c}{0.817}\n",
      "\\\\\n",
      "\n",
      "$\\textsc{LateFusion}_{512}$\n",
      "& \\multicolumn{1}{c}{\\icoyes}\n",
      "    & & 1.687 & \\multicolumn{1}{c}{1.430} & \\multicolumn{1}{c}{2.637} & \\multicolumn{1}{c}{2.627} & \\multicolumn{1}{c}{1.883} & \\multicolumn{1}{c}{1.672}\n",
      "    & & 1.978 & \\multicolumn{1}{c}{1.328} & \\multicolumn{1}{c}{3.048} & \\multicolumn{1}{c}{2.688} & \\multicolumn{1}{c}{1.300} & \\multicolumn{1}{c}{1.190}\n",
      "    & & 2.149 & \\multicolumn{1}{c}{1.307} & \\multicolumn{1}{c}{3.084} & \\multicolumn{1}{c}{2.620} & \\multicolumn{1}{c}{1.170} & \\multicolumn{1}{c}{0.900}\n",
      "\\\\\n",
      "\n",
      "$\\textsc{LateFusion}_{256}$\n",
      "& \\multicolumn{1}{c}{\\icoyes}\n",
      "    & & 2.057 & \\multicolumn{1}{c}{1.555} & \\multicolumn{1}{c}{3.006} & \\multicolumn{1}{c}{2.752} & \\multicolumn{1}{c}{2.043} & \\multicolumn{1}{c}{1.743}\n",
      "    & & 2.306 & \\multicolumn{1}{c}{1.630} & \\multicolumn{1}{c}{3.288} & \\multicolumn{1}{c}{2.915} & \\multicolumn{1}{c}{1.443} & \\multicolumn{1}{c}{1.305}\n",
      "    & & 2.397 & \\multicolumn{1}{c}{1.394} & \\multicolumn{1}{c}{3.328} & \\multicolumn{1}{c}{2.672} & \\multicolumn{1}{c}{1.170} & \\multicolumn{1}{c}{0.923}\n",
      "\\\\\n",
      "\n",
      "$\\textsc{Ours}_{512 \\times 8}$\n",
      "& \\multicolumn{1}{c}{\\icoyes}\n",
      "    & & 1.827 & \\multicolumn{1}{c}{1.358} & \\multicolumn{1}{c}{3.133} & \\multicolumn{1}{c}{2.787} & \\multicolumn{1}{c}{2.097} & \\multicolumn{1}{c}{1.809}\n",
      "    & & 1.982 & \\multicolumn{1}{c}{1.331} & \\multicolumn{1}{c}{2.868} & \\multicolumn{1}{c}{2.614} & \\multicolumn{1}{c}{1.359} & \\multicolumn{1}{c}{1.234}\n",
      "    & & 1.331 & \\multicolumn{1}{c}{0.865} & \\multicolumn{1}{c}{2.063} & \\multicolumn{1}{c}{2.160} & \\multicolumn{1}{c}{1.035} & \\multicolumn{1}{c}{0.826}\n",
      "\\\\\n",
      "\n",
      "$\\textsc{Ours}_{512 \\times 4}$\n",
      "& \\multicolumn{1}{c}{\\icoyes}\n",
      "    & & 1.647 & \\multicolumn{1}{c}{1.348} & \\multicolumn{1}{c}{2.935} & \\multicolumn{1}{c}{2.764} & \\multicolumn{1}{c}{1.961} & \\multicolumn{1}{c}{1.765}\n",
      "    & & 1.698 & \\multicolumn{1}{c}{1.240} & \\multicolumn{1}{c}{2.666} & \\multicolumn{1}{c}{2.518} & \\multicolumn{1}{c}{1.328} & \\multicolumn{1}{c}{1.211}\n",
      "    & & 1.450 & \\multicolumn{1}{c}{0.884} & \\multicolumn{1}{c}{2.176} & \\multicolumn{1}{c}{2.114} & \\multicolumn{1}{c}{1.053} & \\multicolumn{1}{c}{0.821}\n",
      "\\\\\n",
      "\n",
      "\n",
      "    \\bottomrule\n",
      "\\end{tabular}%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models.pc_ae import load_pretrained_pc_ae\n",
    "\n",
    "\n",
    "CKPT_ROOT = \"/ibex/user/slimhy/Shape2VecSet/output/graph_edit/dm/\"\n",
    "MODEL_MAP = [\n",
    "    {\n",
    "        \"model_name\": \"mlp_mapper_bert_l1__256\",\n",
    "        \"checkpoint\": \"mlp_mapper_bert_l1__256/checkpoint-50.pth\",\n",
    "        \"method_code\": r\"\"\"\\textsc{DirectGen}_{\\textsc{Linear}}\"\"\",\n",
    "        \"is_decoupled\": False,\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"mlp_mapper_bert_bneck_1024_pcae_cpl\",\n",
    "        \"checkpoint\": \"mlp_mapper_bert_bneck_1024_pcae__fine_chained_cpl/checkpoint-59.pth\",\n",
    "        \"method_code\": r\"\"\"\\textsc{LateFusion}_{1024}\"\"\",\n",
    "        \"is_decoupled\": False,\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"mlp_mapper_bert_bneck_512_pcae_cpl\",\n",
    "        \"checkpoint\": \"mlp_mapper_bert_bneck_512_pcae__fine_cpl__chained/checkpoint-59.pth\",\n",
    "        \"method_code\": r\"\"\"\\textsc{LateFusion}_{512}\"\"\",\n",
    "        \"is_decoupled\": False,\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"mlp_mapper_bert_bneck_256_pcae_cpl\",\n",
    "        \"checkpoint\": \"mlp_mapper_bert_bneck_256_pcae__fine_cpl__chained/checkpoint-59.pth\",\n",
    "        \"method_code\": r\"\"\"\\textsc{LateFusion}_{256}\"\"\",\n",
    "        \"is_decoupled\": False,\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"mlp_mapper_bert_l8_pcae_cpl\",\n",
    "        \"checkpoint\": \"mlp_mapper_bert_l8_pcae__fine_cpl__chained/checkpoint-59.pth\",\n",
    "        \"method_code\": r\"\"\"\\textsc{Ours}_{512 \\times 8}\"\"\",\n",
    "        \"is_decoupled\": False,\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"mlp_mapper_bert_l4_pcae_cpl\",\n",
    "        \"checkpoint\": \"mlp_mapper_bert_l4_pcae__fine_cpl__chained/checkpoint-59.pth\",\n",
    "        \"method_code\": r\"\"\"\\textsc{Ours}_{512 \\times 4}\"\"\",\n",
    "        \"is_decoupled\": False,\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"mlp_mapper_bert_bneck_1024_pcae\",\n",
    "        \"checkpoint\": \"mlp_mapper_bert_bneck_1024_pcae__fine_chained/checkpoint-59.pth\",\n",
    "        \"method_code\": r\"\"\"\\textsc{LateFusion}_{1024}\"\"\",\n",
    "        \"is_decoupled\": True,\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"mlp_mapper_bert_bneck_512_pcae\",\n",
    "        \"checkpoint\": \"mlp_mapper_bert_bneck_512_pcae__fine_chained/checkpoint-59.pth\",\n",
    "        \"method_code\": r\"\"\"\\textsc{LateFusion}_{512}\"\"\",\n",
    "        \"is_decoupled\": True,\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"mlp_mapper_bert_bneck_256_pcae\",\n",
    "        \"checkpoint\": \"mlp_mapper_bert_bneck_256_pcae__fine_chained/checkpoint-59.pth\",\n",
    "        \"method_code\": r\"\"\"\\textsc{LateFusion}_{256}\"\"\",\n",
    "        \"is_decoupled\": True,\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"mlp_mapper_bert_l8_pcae\",\n",
    "        \"checkpoint\": \"mlp_mapper_bert_l8_pcae__fine_chained/checkpoint-59.pth\",\n",
    "        \"method_code\": r\"\"\"\\textsc{Ours}_{512 \\times 8}\"\"\",\n",
    "        \"is_decoupled\": True,\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"mlp_mapper_bert_l4_pcae\",\n",
    "        \"checkpoint\": \"mlp_mapper_bert_l4_pcae__fine_chained/checkpoint-59.pth\",\n",
    "        \"method_code\": r\"\"\"\\textsc{Ours}_{512 \\times 4}\"\"\",\n",
    "        \"is_decoupled\": True,\n",
    "    },\n",
    "]\n",
    "AE_MODEl_NAME = \"pc_ae\"\n",
    "AE_MODEL_PATH = \"/ibex/user/slimhy/Shape2VecSet/ckpt/pc_ae/best_model.pt\"\n",
    "\n",
    "line_seps = [0, 5]\n",
    "ae_model = None\n",
    "all_results = {}\n",
    "print(table_header)\n",
    "for k, model_map in enumerate(MODEL_MAP):\n",
    "    args, model, device = init_exps(\n",
    "        model_map[\"model_name\"], CKPT_ROOT + model_map[\"checkpoint\"], AE_MODEl_NAME\n",
    "    )\n",
    "    # Instantiate autoencoder\n",
    "    if ae_model is None:\n",
    "        ae_model, _ = load_pretrained_pc_ae(AE_MODEL_PATH)\n",
    "        ae_model = ae_model.to(device)\n",
    "        ae_model = ae_model.eval()\n",
    "\n",
    "    print(\"$\" + model_map[\"method_code\"] + \"$\")\n",
    "    print(table_is_decoupled % (\"icoyes\" if model_map[\"is_decoupled\"] else \"icono\"))\n",
    "    full_results = run_exps(args, model, ae_model, device)\n",
    "    all_results[model_map[\"model_name\"]] = full_results\n",
    "    print(\"\\\\\\\\\")\n",
    "    print()\n",
    "    if k in line_seps:\n",
    "        print(table_sep)\n",
    "        print()\n",
    "\n",
    "print(table_footer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_header = r\"\"\"\n",
    "\\begin{tabular}{@{}lllccccccc@{}}\n",
    "    \\toprule\n",
    "    \\multicolumn{1}{c}{\\multirow{2}{*}{\\textbf{Model}}} & \\multicolumn{1}{c}{\\multirow{2}{*}{Decoupled magnitude}} & \\multicolumn{1}{c}{} & \\multicolumn{6}{c}{Averaged $\\ \\forall |\\mathcal{P}|$} \\\\  \\cmidrule(l){4-9} \n",
    "    \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{}\n",
    "    & & $\\textsc{F}_{\\textsc{CD}}$\n",
    "    & $\\textsc{A}_{\\textsc{CD}}$\n",
    "    & $\\textsc{F}_{\\textsc{CD} - \\textsc{Real}}$\n",
    "    & $\\textsc{A}_{\\textsc{CD} - \\textsc{Real}}$\n",
    "    & $\\textsc{F}_{\\mathcal{L}_2}$ & $\\textsc{A}_{\\mathcal{L}_2}$ \\\\ \\midrule\n",
    "\"\"\"\n",
    "table_entry = \"    & & %0.3f & %0.3f & %0.3f & %0.3f & %0.3f & %0.3f\"\n",
    "table_footer = r\"\"\"\\bottomrule\n",
    "\\end{tabular}%\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{tabular}{@{}lllccccccc@{}}\n",
      "    \\toprule\n",
      "    \\multicolumn{1}{c}{\\multirow{2}{*}{\\textbf{Model}}} & \\multicolumn{1}{c}{\\multirow{2}{*}{Decoupled magnitude}} & \\multicolumn{1}{c}{} & \\multicolumn{6}{c}{Averaged $\\ \\forall |\\mathcal{P}|$} \\\\  \\cmidrule(l){4-9} \n",
      "    \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{}\n",
      "    & & $\\textsc{F}_{\\textsc{CD}}$\n",
      "    & $\\textsc{A}_{\\textsc{CD}}$\n",
      "    & $\\textsc{F}_{\\textsc{CD} - \\textsc{Real}}$\n",
      "    & $\\textsc{A}_{\\textsc{CD} - \\textsc{Real}}$\n",
      "    & $\\textsc{F}_{\\mathcal{L}_2}$ & $\\textsc{A}_{\\mathcal{L}_2}$ \\\\ \\midrule\n",
      "\n",
      "$\\textsc{DirectGen}_{\\textsc{Linear}}$\n",
      "& \\multicolumn{1}{c}{\\icono}\n",
      "    & & 3.140 & 2.497 & 4.054 & 3.900 & 2.150 & 1.819\n",
      "\\\\\n",
      "\n",
      "\\arrayrulecolor{black!30}\\midrule\\arrayrulecolor{black!100}\n",
      "\n",
      "$\\textsc{LateFusion}_{1024}$\n",
      "& \\multicolumn{1}{c}{\\icono}\n",
      "    & & 1.831 & 1.318 & 2.764 & 2.559 & 1.444 & 1.251\n",
      "\\\\\n",
      "\n",
      "$\\textsc{LateFusion}_{512}$\n",
      "& \\multicolumn{1}{c}{\\icono}\n",
      "    & & 1.673 & 1.296 & 2.658 & 2.548 & 1.462 & 1.290\n",
      "\\\\\n",
      "\n",
      "$\\textsc{LateFusion}_{256}$\n",
      "& \\multicolumn{1}{c}{\\icono}\n",
      "    & & 1.859 & 1.295 & 2.808 & 2.591 & 1.509 & 1.283\n",
      "\\\\\n",
      "\n",
      "$\\textsc{Ours}_{512 \\times 8}$\n",
      "& \\multicolumn{1}{c}{\\icono}\n",
      "    & & 2.094 & 1.440 & 3.132 & 2.754 & 1.703 & 1.437\n",
      "\\\\\n",
      "\n",
      "$\\textsc{Ours}_{512 \\times 4}$\n",
      "& \\multicolumn{1}{c}{\\icono}\n",
      "    & & 1.929 & 1.373 & 2.898 & 2.637 & 1.589 & 1.351\n",
      "\\\\\n",
      "\n",
      "\\arrayrulecolor{black!30}\\midrule\\arrayrulecolor{black!100}\n",
      "\n",
      "$\\textsc{LateFusion}_{1024}$\n",
      "& \\multicolumn{1}{c}{\\icoyes}\n",
      "    & & 1.660 & 1.264 & 2.639 & 2.504 & 1.405 & 1.245\n",
      "\\\\\n",
      "\n",
      "$\\textsc{LateFusion}_{512}$\n",
      "& \\multicolumn{1}{c}{\\icoyes}\n",
      "    & & 1.938 & 1.355 & 2.923 & 2.645 & 1.451 & 1.254\n",
      "\\\\\n",
      "\n",
      "$\\textsc{LateFusion}_{256}$\n",
      "& \\multicolumn{1}{c}{\\icoyes}\n",
      "    & & 2.253 & 1.526 & 3.207 & 2.780 & 1.552 & 1.324\n",
      "\\\\\n",
      "\n",
      "$\\textsc{Ours}_{512 \\times 8}$\n",
      "& \\multicolumn{1}{c}{\\icoyes}\n",
      "    & & 1.714 & 1.185 & 2.688 & 2.520 & 1.497 & 1.290\n",
      "\\\\\n",
      "\n",
      "$\\textsc{Ours}_{512 \\times 4}$\n",
      "& \\multicolumn{1}{c}{\\icoyes}\n",
      "    & & 1.598 & 1.157 & 2.592 & 2.465 & 1.447 & 1.266\n",
      "\\\\\n",
      "\n",
      "\\bottomrule\n",
      "\\end{tabular}%\n"
     ]
    }
   ],
   "source": [
    "print(table_header)\n",
    "line_seps = [0, 5]\n",
    "for k, model_map in enumerate(MODEL_MAP):\n",
    "    results_entry = all_results[model_map[\"model_name\"]]\n",
    "    print(\"$\" + model_map[\"method_code\"] + \"$\")\n",
    "    print(table_is_decoupled % (\"icoyes\" if model_map[\"is_decoupled\"] else \"icono\"))\n",
    "    print(\n",
    "        table_entry\n",
    "        % (\n",
    "            results_entry[\"final_cd_dist_reco\"],\n",
    "            results_entry[\"avg_cd_dist_reco\"],\n",
    "            results_entry[\"final_cd_dist_real\"],\n",
    "            results_entry[\"avg_cd_dist_real\"],\n",
    "            results_entry[\"final_l2_dist\"],\n",
    "            results_entry[\"avg_l2_dist\"],\n",
    "        )\n",
    "    )\n",
    "    print(\"\\\\\\\\\")\n",
    "    print()\n",
    "    if k in line_seps:\n",
    "        print(table_sep)\n",
    "        print()\n",
    "print(table_footer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shape2vecset",
   "language": "python",
   "name": "shape2vecset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
